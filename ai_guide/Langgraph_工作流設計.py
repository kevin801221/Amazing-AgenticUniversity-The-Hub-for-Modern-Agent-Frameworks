"""
LangGraph æ¢æ¬¾æ¯”å°å·¥ä½œæµ
æ¯å€‹ç¯€é»å°ˆç²¾å–®ä¸€ä»»å‹™ï¼Œå¯è¦–åŒ–æª¢é©—éç¨‹
"""

from typing import Dict, List, Optional, TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolExecutor
import operator
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
import json
import sqlite3
from dataclasses import dataclass
from datetime import datetime

# å®šç¾©å·¥ä½œæµç‹€æ…‹
class ClauseWorkflowState(TypedDict):
    # è¼¸å…¥æ–‡ä»¶
    new_case_document: str
    historical_documents: List[str]
    
    # è™•ç†çµæœ (æ¯å€‹ç¯€é»çš„è¼¸å‡º)
    extracted_clauses: Optional[List[Dict]]
    historical_clauses: Optional[List[Dict]]
    matched_pairs: Optional[List[Dict]]
    difference_analysis: Optional[List[Dict]]
    recommendations: Optional[List[Dict]]
    final_report: Optional[str]
    
    # æ§åˆ¶æµç¨‹
    current_step: str
    errors: List[str]
    human_feedback: Optional[Dict]
    
    # èŠå¤©æ­·å² (ç”¨æ–¼å¯è¦–åŒ–)
    messages: Annotated[List[BaseMessage], operator.add]

@dataclass
class ClauseDatabase:
    """ç°¡å–®çš„æ¢æ¬¾è³‡æ–™åº«"""
    db_path: str = "clauses.db"
    
    def __post_init__(self):
        self.init_database()
    
    def init_database(self):
        """åˆå§‹åŒ–è³‡æ–™åº«çµæ§‹"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # æ¡ˆä»¶è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS cases (
                id INTEGER PRIMARY KEY,
                case_name TEXT NOT NULL,
                case_type TEXT NOT NULL,
                client_name TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # æ¢æ¬¾è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS clauses (
                id INTEGER PRIMARY KEY,
                case_id INTEGER,
                category TEXT NOT NULL,
                original_text TEXT NOT NULL,
                standardized_text TEXT,
                parameters JSON,
                risk_level TEXT,
                FOREIGN KEY (case_id) REFERENCES cases (id)
            )
        """)
        
        # æ¯”å°æ­·å²è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS comparisons (
                id INTEGER PRIMARY KEY,
                new_case_id INTEGER,
                reference_case_id INTEGER,
                clause_category TEXT,
                similarity_score REAL,
                difference_type TEXT,
                action_taken TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (new_case_id) REFERENCES cases (id),
                FOREIGN KEY (reference_case_id) REFERENCES cases (id)
            )
        """)
        
        conn.commit()
        conn.close()
    
    def save_case(self, case_name: str, case_type: str, client_name: str) -> int:
        """å„²å­˜æ¡ˆä»¶åŸºæœ¬è³‡è¨Š"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO cases (case_name, case_type, client_name)
            VALUES (?, ?, ?)
        """, (case_name, case_type, client_name))
        
        case_id = cursor.lastrowid
        conn.commit()
        conn.close()
        return case_id
    
    def save_clauses(self, case_id: int, clauses: List[Dict]):
        """å„²å­˜æ¢æ¬¾"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        for clause in clauses:
            cursor.execute("""
                INSERT INTO clauses 
                (case_id, category, original_text, standardized_text, parameters, risk_level)
                VALUES (?, ?, ?, ?, ?, ?)
            """, (
                case_id,
                clause.get('category'),
                clause.get('original_text'),
                clause.get('standardized_text'),
                json.dumps(clause.get('parameters', {})),
                clause.get('risk_level')
            ))
        
        conn.commit()
        conn.close()
    
    def get_historical_cases(self, case_type: str = None) -> List[Dict]:
        """å–å¾—æ­·å²æ¡ˆä»¶"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        if case_type:
            cursor.execute("""
                SELECT c.*, cl.category, cl.original_text, cl.standardized_text, 
                       cl.parameters, cl.risk_level
                FROM cases c
                LEFT JOIN clauses cl ON c.id = cl.case_id
                WHERE c.case_type = ?
                ORDER BY c.created_at DESC
            """, (case_type,))
        else:
            cursor.execute("""
                SELECT c.*, cl.category, cl.original_text, cl.standardized_text,
                       cl.parameters, cl.risk_level  
                FROM cases c
                LEFT JOIN clauses cl ON c.id = cl.case_id
                ORDER BY c.created_at DESC
            """)
        
        results = cursor.fetchall()
        conn.close()
        
        # çµ„ç¹”æ•¸æ“šçµæ§‹
        cases = {}
        for row in results:
            case_id = row[0]
            if case_id not in cases:
                cases[case_id] = {
                    'id': case_id,
                    'case_name': row[1],
                    'case_type': row[2], 
                    'client_name': row[3],
                    'created_at': row[4],
                    'clauses': []
                }
            
            if row[5]:  # å¦‚æœæœ‰æ¢æ¬¾
                cases[case_id]['clauses'].append({
                    'category': row[5],
                    'original_text': row[6],
                    'standardized_text': row[7],
                    'parameters': json.loads(row[8]) if row[8] else {},
                    'risk_level': row[9]
                })
        
        return list(cases.values())

class ClauseWorkflow:
    def __init__(self, gemini_api_key: str):
        self.llm = ChatGoogleGenerativeAI(
            model="gemini-1.5-pro",
            google_api_key=gemini_api_key,
            temperature=0.1
        )
        self.db = ClauseDatabase()
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """å»ºæ§‹ LangGraph å·¥ä½œæµ"""
        workflow = StateGraph(ClauseWorkflowState)
        
        # æ·»åŠ ç¯€é»
        workflow.add_node("extract_new_clauses", self.extract_new_clauses)
        workflow.add_node("load_historical_clauses", self.load_historical_clauses)
        workflow.add_node("match_similar_clauses", self.match_similar_clauses)
        workflow.add_node("analyze_differences", self.analyze_differences)
        workflow.add_node("generate_recommendations", self.generate_recommendations)
        workflow.add_node("human_review", self.human_review)
        workflow.add_node("generate_final_report", self.generate_final_report)
        workflow.add_node("save_results", self.save_results)
        
        # å®šç¾©æµç¨‹
        workflow.set_entry_point("extract_new_clauses")
        
        workflow.add_edge("extract_new_clauses", "load_historical_clauses")
        workflow.add_edge("load_historical_clauses", "match_similar_clauses")  
        workflow.add_edge("match_similar_clauses", "analyze_differences")
        workflow.add_edge("analyze_differences", "generate_recommendations")
        workflow.add_edge("generate_recommendations", "human_review")
        
        # æ¢ä»¶åˆ†æ”¯ï¼šæ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
        workflow.add_conditional_edges(
            "human_review",
            self.should_continue_or_revise,
            {
                "continue": "generate_final_report",
                "revise": "analyze_differences",  # å›åˆ°å·®ç•°åˆ†æ
                "end": END
            }
        )
        
        workflow.add_edge("generate_final_report", "save_results")
        workflow.add_edge("save_results", END)
        
        return workflow.compile()
    
    def extract_new_clauses(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»1ï¼šæå–æ–°æ¡ˆä»¶æ¢æ¬¾"""
        print("ğŸ” åŸ·è¡Œç¯€é»ï¼šæå–æ–°æ¡ˆä»¶æ¢æ¬¾")
        
        prompt = f"""
        ä½ æ˜¯éŠ€è¡Œæ³•å‹™æ¢æ¬¾æå–å°ˆå®¶ã€‚è«‹å¾ä»¥ä¸‹æ–‡ä»¶ä¸­æå–æ‰€æœ‰æ¨™æº–åŒ–æ¢æ¬¾ã€‚
        
        æ–‡ä»¶å…§å®¹ï¼š
        {state['new_case_document']}
        
        è«‹ä»¥JSONæ ¼å¼å›å‚³ï¼ŒåŒ…å«ï¼š
        - category: æ¢æ¬¾é¡åˆ¥ (æˆä¿¡ç¨®é¡åŠé¡åº¦/åˆ©è²»ç‡/æœŸé™/é‚„æœ¬ä»˜æ¯/é€£å¸¶ä¿è­‰äºº/æ“”ä¿å“/ç‰¹ç´„æ¢ä»¶)
        - original_text: åŸå§‹æ¢æ¬¾æ–‡å­—
        - standardized_text: æ¨™æº–åŒ–å¾Œçš„æ¢æ¬¾æ–‡å­—
        - parameters: æå–çš„åƒæ•¸ (é‡‘é¡ã€åˆ©ç‡ã€æœŸé™ç­‰)
        - risk_level: é¢¨éšªç­‰ç´š (low/medium/high)
        
        ç¯„ä¾‹æ ¼å¼ï¼š
        {{
          "clauses": [
            {{
              "category": "æˆä¿¡ç¨®é¡åŠé¡åº¦",
              "original_text": "çŸ­æœŸè²¸æ¬¾é¡åº¦æ–°è‡ºå¹£500,000ä»Ÿå…ƒæ•´ï¼Œå¾—å¾ªç’°å‹•ç”¨",
              "standardized_text": "çŸ­æœŸè²¸æ¬¾é¡åº¦æ–°è‡ºå¹£{{amount}}ä»Ÿå…ƒæ•´ï¼Œ{{circulation}}",
              "parameters": {{"amount": "500,000", "circulation": "å¾—å¾ªç’°å‹•ç”¨"}},
              "risk_level": "medium"
            }}
          ]
        }}
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        
        try:
            # è§£æJSONå›æ‡‰
            content = response.content
            json_start = content.find('{')
            json_end = content.rfind('}') + 1
            json_str = content[json_start:json_end]
            
            result = json.loads(json_str)
            extracted_clauses = result.get('clauses', [])
            
            print(f"âœ… æå–äº† {len(extracted_clauses)} å€‹æ¢æ¬¾")
            
        except Exception as e:
            print(f"âŒ æå–å¤±æ•—ï¼š{e}")
            extracted_clauses = []
            state['errors'].append(f"æ¢æ¬¾æå–å¤±æ•—ï¼š{e}")
        
        state['extracted_clauses'] = extracted_clauses
        state['current_step'] = "extract_new_clauses"
        state['messages'].append(AIMessage(content=f"æå–äº† {len(extracted_clauses)} å€‹æ–°æ¢æ¬¾"))
        
        return state
    
    def load_historical_clauses(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»2ï¼šè¼‰å…¥æ­·å²æ¡ˆä»¶æ¢æ¬¾"""
        print("ğŸ“š åŸ·è¡Œç¯€é»ï¼šè¼‰å…¥æ­·å²æ¡ˆä»¶æ¢æ¬¾")
        
        # å¾è³‡æ–™åº«è¼‰å…¥æ­·å²æ¡ˆä»¶
        historical_cases = self.db.get_historical_cases()
        
        # æ‰å¹³åŒ–æ‰€æœ‰æ­·å²æ¢æ¬¾
        historical_clauses = []
        for case in historical_cases:
            for clause in case['clauses']:
                clause['source_case'] = case['case_name']
                clause['source_client'] = case['client_name']
                historical_clauses.append(clause)
        
        print(f"âœ… è¼‰å…¥äº† {len(historical_clauses)} å€‹æ­·å²æ¢æ¬¾")
        
        state['historical_clauses'] = historical_clauses
        state['current_step'] = "load_historical_clauses"
        state['messages'].append(AIMessage(content=f"è¼‰å…¥äº† {len(historical_clauses)} å€‹æ­·å²æ¢æ¬¾"))
        
        return state
    
    def match_similar_clauses(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»3ï¼šé…å°ç›¸ä¼¼æ¢æ¬¾"""
        print("ğŸ”— åŸ·è¡Œç¯€é»ï¼šé…å°ç›¸ä¼¼æ¢æ¬¾")
        
        new_clauses = state['extracted_clauses']
        historical_clauses = state['historical_clauses']
        
        matched_pairs = []
        
        for new_clause in new_clauses:
            # æ‰¾å‡ºåŒé¡åˆ¥çš„æ­·å²æ¢æ¬¾
            same_category_clauses = [
                hc for hc in historical_clauses 
                if hc['category'] == new_clause['category']
            ]
            
            if same_category_clauses:
                # ä½¿ç”¨LLMåˆ¤æ–·æœ€ç›¸ä¼¼çš„æ¢æ¬¾
                best_match = self._find_best_match(new_clause, same_category_clauses)
                
                matched_pairs.append({
                    'new_clause': new_clause,
                    'historical_clause': best_match,
                    'category': new_clause['category']
                })
            else:
                # æ²’æœ‰æ­·å²å°æ‡‰æ¢æ¬¾
                matched_pairs.append({
                    'new_clause': new_clause,
                    'historical_clause': None,
                    'category': new_clause['category']
                })
        
        # æª¢æŸ¥æ­·å²æ¢æ¬¾ä¸­æ–°æ¡ˆä»¶ç¼ºå°‘çš„
        new_categories = {clause['category'] for clause in new_clauses}
        historical_categories = {clause['category'] for clause in historical_clauses}
        
        missing_categories = historical_categories - new_categories
        for category in missing_categories:
            # æ‰¾åˆ°è©²é¡åˆ¥æœ€å¸¸è¦‹çš„æ­·å²æ¢æ¬¾
            category_clauses = [hc for hc in historical_clauses if hc['category'] == category]
            if category_clauses:
                most_common = category_clauses[0]  # ç°¡åŒ–ï¼šå–ç¬¬ä¸€å€‹
                matched_pairs.append({
                    'new_clause': None,
                    'historical_clause': most_common,
                    'category': category
                })
        
        print(f"âœ… é…å°äº† {len(matched_pairs)} çµ„æ¢æ¬¾")
        
        state['matched_pairs'] = matched_pairs
        state['current_step'] = "match_similar_clauses"
        state['messages'].append(AIMessage(content=f"é…å°äº† {len(matched_pairs)} çµ„æ¢æ¬¾"))
        
        return state
    
    def analyze_differences(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»4ï¼šåˆ†æå·®ç•°"""
        print("ğŸ” åŸ·è¡Œç¯€é»ï¼šåˆ†æå·®ç•°")
        
        matched_pairs = state['matched_pairs']
        difference_analysis = []
        
        for pair in matched_pairs:
            analysis = self._analyze_clause_difference(pair)
            difference_analysis.append(analysis)
        
        print(f"âœ… åˆ†æäº† {len(difference_analysis)} çµ„å·®ç•°")
        
        state['difference_analysis'] = difference_analysis
        state['current_step'] = "analyze_differences"
        state['messages'].append(AIMessage(content=f"å®Œæˆ {len(difference_analysis)} çµ„å·®ç•°åˆ†æ"))
        
        return state
    
    def generate_recommendations(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»5ï¼šç”Ÿæˆå»ºè­°"""
        print("ğŸ’¡ åŸ·è¡Œç¯€é»ï¼šç”Ÿæˆå»ºè­°")
        
        difference_analysis = state['difference_analysis']
        recommendations = []
        
        for analysis in difference_analysis:
            recommendation = self._generate_recommendation(analysis)
            recommendations.append(recommendation)
        
        print(f"âœ… ç”Ÿæˆäº† {len(recommendations)} å€‹å»ºè­°")
        
        state['recommendations'] = recommendations
        state['current_step'] = "generate_recommendations"
        state['messages'].append(AIMessage(content=f"ç”Ÿæˆäº† {len(recommendations)} å€‹å»ºè­°"))
        
        return state
    
    def human_review(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»6ï¼šäººå·¥å¯©æ ¸é»"""
        print("ğŸ‘¤ åŸ·è¡Œç¯€é»ï¼šäººå·¥å¯©æ ¸")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰é«˜é¢¨éšªæˆ–éœ€è¦äººå·¥å¯©æ ¸çš„é …ç›®
        recommendations = state['recommendations']
        
        high_risk_items = [
            rec for rec in recommendations 
            if rec.get('requires_human_review', False) or rec.get('risk_level') == 'high'
        ]
        
        if high_risk_items:
            print(f"âš ï¸ ç™¼ç¾ {len(high_risk_items)} å€‹éœ€è¦äººå·¥å¯©æ ¸çš„é …ç›®")
            
            # ç”Ÿæˆäººå·¥å¯©æ ¸æ‘˜è¦
            review_summary = self._generate_review_summary(high_risk_items)
            
            state['human_feedback'] = {
                'requires_review': True,
                'high_risk_items': high_risk_items,
                'review_summary': review_summary
            }
        else:
            print("âœ… æ‰€æœ‰é …ç›®é€šéè‡ªå‹•å¯©æ ¸")
            state['human_feedback'] = {'requires_review': False}
        
        state['current_step'] = "human_review"
        state['messages'].append(AIMessage(content="äººå·¥å¯©æ ¸æª¢æŸ¥å®Œæˆ"))
        
        return state
    
    def should_continue_or_revise(self, state: ClauseWorkflowState) -> str:
        """æ¢ä»¶åˆ†æ”¯ï¼šæ±ºå®šæ˜¯å¦ç¹¼çºŒæˆ–éœ€è¦ä¿®æ­£"""
        human_feedback = state.get('human_feedback', {})
        
        if human_feedback.get('requires_review', False):
            return "continue"  # æœ‰é¢¨éšªé …ç›®ï¼Œä½†ç¹¼çºŒåˆ°å ±å‘Šç”Ÿæˆ
        else:
            return "continue"  # æ²’æœ‰å•é¡Œï¼Œç¹¼çºŒ
    
    def generate_final_report(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»7ï¼šç”Ÿæˆæœ€çµ‚å ±å‘Š"""
        print("ğŸ“Š åŸ·è¡Œç¯€é»ï¼šç”Ÿæˆæœ€çµ‚å ±å‘Š")
        
        # æ•´åˆæ‰€æœ‰åˆ†æçµæœç”Ÿæˆå ±å‘Š
        report = self._generate_comprehensive_report(state)
        
        state['final_report'] = report
        state['current_step'] = "generate_final_report"
        state['messages'].append(AIMessage(content="æœ€çµ‚å ±å‘Šç”Ÿæˆå®Œæˆ"))
        
        return state
    
    def save_results(self, state: ClauseWorkflowState) -> ClauseWorkflowState:
        """ç¯€é»8ï¼šå„²å­˜çµæœ"""
        print("ğŸ’¾ åŸ·è¡Œç¯€é»ï¼šå„²å­˜çµæœ")
        
        # å„²å­˜æ–°æ¡ˆä»¶åˆ°è³‡æ–™åº«
        case_id = self.db.save_case(
            case_name=f"æ–°æ¡ˆä»¶_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
            case_type="å¾…åˆ†é¡",
            client_name="å¾…å¡«å…¥"
        )
        
        # å„²å­˜æå–çš„æ¢æ¬¾
        if state['extracted_clauses']:
            self.db.save_clauses(case_id, state['extracted_clauses'])
        
        print(f"âœ… çµæœå·²å„²å­˜ï¼Œæ¡ˆä»¶IDï¼š{case_id}")
        
        state['current_step'] = "save_results"
        state['messages'].append(AIMessage(content=f"çµæœå·²å„²å­˜ï¼Œæ¡ˆä»¶IDï¼š{case_id}"))
        
        return state
    
    # è¼”åŠ©æ–¹æ³•
    def _find_best_match(self, new_clause: Dict, candidates: List[Dict]) -> Dict:
        """æ‰¾å‡ºæœ€ç›¸ä¼¼çš„æ­·å²æ¢æ¬¾"""
        # ç°¡åŒ–ç‰ˆï¼šä½¿ç”¨æ–‡å­—é•·åº¦ç›¸ä¼¼åº¦
        new_text = new_clause['original_text']
        
        best_match = candidates[0]
        best_score = 0
        
        for candidate in candidates:
            # ç°¡å–®çš„ç›¸ä¼¼åº¦è¨ˆç®—ï¼ˆå¯¦éš›å¯ä»¥ç”¨æ›´è¤‡é›œçš„NLPæ–¹æ³•ï¼‰
            candidate_text = candidate['original_text']
            score = len(set(new_text.split()) & set(candidate_text.split())) / max(len(new_text.split()), len(candidate_text.split()))
            
            if score > best_score:
                best_score = score
                best_match = candidate
        
        return best_match
    
    def _analyze_clause_difference(self, pair: Dict) -> Dict:
        """åˆ†æå–®çµ„æ¢æ¬¾å·®ç•°"""
        new_clause = pair['new_clause']
        historical_clause = pair['historical_clause']
        category = pair['category']
        
        if new_clause is None:
            return {
                'category': category,
                'status': 'missing_in_new',
                'analysis': 'æ–°æ¡ˆä»¶ç¼ºå°‘æ­¤é¡æ¢æ¬¾',
                'risk_level': 'medium',
                'differences': [],
                'possible_reasons': ['æ¥­å‹™ç°¡åŒ–', 'é¢¨éšªé™ä½', 'éºæ¼']
            }
        
        if historical_clause is None:
            return {
                'category': category,
                'status': 'new_addition',
                'analysis': 'æ–°æ¡ˆä»¶æ–°å¢æ­¤é¡æ¢æ¬¾',
                'risk_level': 'medium',
                'differences': [],
                'possible_reasons': ['æ¥­å‹™æ“´å±•', 'é¢¨éšªæ§åˆ¶', 'æ³•è¦è¦æ±‚']
            }
        
        # æ¯”è¼ƒåƒæ•¸å·®ç•°
        new_params = new_clause.get('parameters', {})
        hist_params = historical_clause.get('parameters', {})
        
        differences = []
        for key in set(new_params.keys()) | set(hist_params.keys()):
            if new_params.get(key) != hist_params.get(key):
                differences.append({
                    'parameter': key,
                    'old_value': hist_params.get(key),
                    'new_value': new_params.get(key)
                })
        
        if not differences:
            status = 'identical'
            risk_level = 'low'
        elif len(differences) <= 2:
            status = 'minor_differences'
            risk_level = 'medium'
        else:
            status = 'major_differences'
            risk_level = 'high'
        
        return {
            'category': category,
            'status': status,
            'analysis': f'ç™¼ç¾ {len(differences)} å€‹åƒæ•¸å·®ç•°',
            'risk_level': risk_level,
            'differences': differences,
            'possible_reasons': self._infer_change_reasons(differences)
        }
    
    def _infer_change_reasons(self, differences: List[Dict]) -> List[str]:
        """æ¨æ–·è®ŠåŒ–åŸå› """
        reasons = []
        
        for diff in differences:
            param = diff['parameter']
            if param == 'amount':
                reasons.append('æˆä¿¡é¡åº¦èª¿æ•´')
            elif param == 'rate':
                reasons.append('åˆ©ç‡æ”¿ç­–è®ŠåŒ–')
            elif param == 'period':
                reasons.append('æœŸé™è¦æ±‚è®ŠåŒ–')
            else:
                reasons.append('æ¥­å‹™æ¢ä»¶èª¿æ•´')
        
        return list(set(reasons))
    
    def _generate_recommendation(self, analysis: Dict) -> Dict:
        """ç‚ºå–®å€‹åˆ†æç”Ÿæˆå»ºè­°"""
        category = analysis['category']
        status = analysis['status']
        risk_level = analysis['risk_level']
        
        if status == 'identical':
            return {
                'category': category,
                'action': 'keep_current',
                'reasoning': 'æ¢æ¬¾èˆ‡æ­·å²æ¡ˆä»¶ç›¸åŒï¼Œå»ºè­°ä¿æŒ',
                'requires_human_review': False,
                'risk_level': risk_level
            }
        
        elif status == 'missing_in_new':
            return {
                'category': category,
                'action': 'consider_adding',
                'reasoning': 'æ–°æ¡ˆä»¶ç¼ºå°‘æ­¤æ¢æ¬¾ï¼Œå»ºè­°è©•ä¼°æ˜¯å¦éœ€è¦æ·»åŠ ',
                'requires_human_review': True,
                'risk_level': 'medium'
            }
        
        elif status == 'new_addition':
            return {
                'category': category,
                'action': 'review_necessity',
                'reasoning': 'æ–°å¢æ¢æ¬¾ï¼Œå»ºè­°ç¢ºèªå…¶å¿…è¦æ€§å’Œåˆè¦æ€§',
                'requires_human_review': True,
                'risk_level': 'medium'
            }
        
        else:  # minor_differences or major_differences
            return {
                'category': category,
                'action': 'review_changes',
                'reasoning': f'ç™¼ç¾æ¢æ¬¾å·®ç•°ï¼ˆ{status}ï¼‰ï¼Œå»ºè­°æª¢è¨è®Šæ›´åŸå› ',
                'requires_human_review': risk_level in ['high', 'medium'],
                'risk_level': risk_level
            }
    
    def _generate_review_summary(self, high_risk_items: List[Dict]) -> str:
        """ç”Ÿæˆäººå·¥å¯©æ ¸æ‘˜è¦"""
        summary = "éœ€è¦äººå·¥å¯©æ ¸çš„é …ç›®ï¼š\n\n"
        
        for i, item in enumerate(high_risk_items, 1):
            summary += f"{i}. {item['category']}\n"
            summary += f"   å»ºè­°è¡Œå‹•ï¼š{item['action']}\n"
            summary += f"   åŸå› ï¼š{item['reasoning']}\n"
            summary += f"   é¢¨éšªç­‰ç´šï¼š{item['risk_level']}\n\n"
        
        return summary
    
    def _generate_comprehensive_report(self, state: ClauseWorkflowState) -> str:
        """ç”Ÿæˆç¶œåˆå ±å‘Š"""
        extracted_clauses = state.get('extracted_clauses', [])
        recommendations = state.get('recommendations', [])
        
        report = f"""
# æ¢æ¬¾æ¯”å°åˆ†æå ±å‘Š

## åŸ·è¡Œæ‘˜è¦
- åˆ†ææ™‚é–“ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æå–æ¢æ¬¾æ•¸ï¼š{len(extracted_clauses)}
- ç”Ÿæˆå»ºè­°æ•¸ï¼š{len(recommendations)}

## æ¢æ¬¾åˆ†æçµæœ

### å¯ç›´æ¥ä½¿ç”¨çš„æ¢æ¬¾
{self._format_recommendations_by_action(recommendations, 'keep_current')}

### éœ€è¦æª¢è¨çš„æ¢æ¬¾  
{self._format_recommendations_by_action(recommendations, 'review_changes')}

### å»ºè­°æ–°å¢çš„æ¢æ¬¾
{self._format_recommendations_by_action(recommendations, 'consider_adding')}

### éœ€è¦ç¢ºèªçš„æ–°å¢æ¢æ¬¾
{self._format_recommendations_by_action(recommendations, 'review_necessity')}

## ç¸½çµå»ºè­°
åŸºæ–¼ä»¥ä¸Šåˆ†æï¼Œå»ºè­°æ³•å‹™äººå“¡é‡é»é—œæ³¨éœ€è¦æª¢è¨å’Œç¢ºèªçš„æ¢æ¬¾ï¼Œå…¶é¤˜æ¢æ¬¾å¯æŒ‰å»ºè­°è™•ç†ã€‚
"""
        return report
    
    def _format_recommendations_by_action(self, recommendations: List[Dict], action: str) -> str:
        """æŒ‰è¡Œå‹•é¡å‹æ ¼å¼åŒ–å»ºè­°"""
        filtered = [rec for rec in recommendations if rec.get('action') == action]
        
        if not filtered:
            return "- ç„¡\n"
        
        result = ""
        for rec in filtered:
            result += f"- {rec['category']}: {rec['reasoning']}\n"
        
        return result
    
    def run_workflow(self, new_document: str, historical_documents: List[str] = None) -> Dict:
        """åŸ·è¡Œå®Œæ•´å·¥ä½œæµ"""
        initial_state = {
            'new_case_document': new_document,
            'historical_documents': historical_documents or [],
            'extracted_clauses': None,
            'historical_clauses': None,
            'matched_pairs': None,
            'difference_analysis': None,
            'recommendations': None,
            'final_report': None,
            'current_step': '',
            'errors': [],
            'human_feedback': None,
            'messages': []
        }
        
        print("ğŸš€ é–‹å§‹åŸ·è¡Œæ¢æ¬¾æ¯”å°å·¥ä½œæµ...")
        
        try:
            final_state = self.graph.invoke(initial_state)
            print("âœ… å·¥ä½œæµåŸ·è¡Œå®Œæˆï¼")
            return final_state
        except Exception as e:
            print(f"âŒ å·¥ä½œæµåŸ·è¡Œå¤±æ•—ï¼š{e}")
            return {'error': str(e)}

# ä½¿ç”¨ç¯„ä¾‹
def main():
    # åˆå§‹åŒ–å·¥ä½œæµ
    workflow = ClauseWorkflow(gemini_api_key="YOUR_API_KEY")
    
    # æ¸¬è©¦æ–‡ä»¶
    new_document = """
    å‡±åŸºå•†æ¥­éŠ€è¡Œæ‰¹è¦†æ›¸
    
    ä¸€ã€æ ¸å‡†æ¢ä»¶
    (äºŒ)æˆä¿¡ç¨®é¡åŠé¡åº¦ï¼šçŸ­æœŸè²¸æ¬¾é¡åº¦æ–°è‡ºå¹£300,000ä»Ÿå…ƒæ•´ï¼Œå¾—å¾ªç’°å‹•ç”¨ã€‚
    (ä¸‰)åˆ©(è²»)ç‡ï¼šæŒ‰åƒè€ƒåˆ©ç‡æˆ–æœ¬è¡Œè³‡é‡‘æˆæœ¬åŠ å¹´åˆ©ç‡0.80ï¼…è¨ˆæ¯ã€‚ç¨…å…§å«ã€‚
    (å››)æœŸé™ï¼šè‡ªç°½ç´„æ—¥èµ·ç®—1å¹´ã€‚
    (äº”)é‚„æœ¬ä»˜æ¯è¾¦æ³•ï¼šæœ¬é‡‘å±†æœŸæ¸…å„Ÿï¼Œåˆ©æ¯æŒ‰æœˆè¨ˆæ”¶ã€‚
    (å…­)é€£å¸¶ä¿è­‰äººï¼šå¼µä¸‰ã€‚
    (ä¸ƒ)æ“”ä¿å“ï¼šç„¡ã€‚
    """
    
    # åŸ·è¡Œå·¥ä½œæµ
    result = workflow.run_workflow(new_document)
    
    if 'error' not in result:
        print("\n" + "="*50)
        print("æœ€çµ‚å ±å‘Šï¼š")
        print(result.get('final_report', 'ç„¡å ±å‘Š'))
        print("="*50)
    
    return result

if __name__ == "__main__":
    main()