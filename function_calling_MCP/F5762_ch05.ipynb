{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgttHM1PIMSk"
      },
      "source": [
        "# ç¬¬ 5 ç«  Agent çš„åŸºç¤â€“ç”¨ Function Calling å¹« AI é•·æ‰‹è…³"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-RlMrECIQac"
      },
      "source": [
        "## å‰ç½®å·¥ä½œ\n",
        "\n",
        "è«‹å…ˆåŸ·è¡Œä»¥ä¸‹é€™å¹¾å€‹å„²å­˜æ ¼ï¼Œä¾¿æ–¼å¾ŒçºŒæ¸¬è©¦ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38jBEPsRaWH2"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "from rich.pretty import pprint\n",
        "from pydantic import BaseModel, Field, ConfigDict\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import openai\n",
        "import sys\n",
        "import os\n",
        "import pickle\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoDsvbeBaqaL"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvi9uaZR9iJd"
      },
      "outputs": [],
      "source": [
        "def upload_file(file_path):\n",
        "    try:\n",
        "        if (file_path.startswith('http://')\n",
        "            or file_path.startswith('https://')):\n",
        "            response = requests.get(file_path)\n",
        "            filename = response.headers.get(\n",
        "                'content-disposition',\n",
        "                None\n",
        "            )\n",
        "            if filename:\n",
        "                filename = filename.split('filename=')[-1]\n",
        "                filename = filename.strip('\\'\"')\n",
        "            else:\n",
        "                filename = file_path.split('/')[-1]\n",
        "            response = client.files.create(\n",
        "                file=(filename, response.content),\n",
        "                purpose='user_data'\n",
        "            )\n",
        "        else:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                response = client.files.create(\n",
        "                    file=file,\n",
        "                    purpose='user_data'\n",
        "                )\n",
        "    except:\n",
        "        return None\n",
        "    return response.id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseComand:\n",
        "    def __init__(self, command, tool_name, icon, verbose=False):\n",
        "        self.command = command      # æŒ‡ä»¤\n",
        "        self.tool_name = tool_name  # å·¥å…·åç¨±\n",
        "        self.icon = icon            # å·¥å…·åœ–ç¤ºå­—å…ƒ\n",
        "        self.verbose = verbose      # å•Ÿç”¨è©³ç´°è¼¸å‡º\n",
        "        self.extra_args = {}        # è¦é¡å¤–é€çµ¦æ¨¡å‹çš„åƒæ•¸\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        # ä¸æ˜¯æ­£ç¢ºçš„æŒ‡ä»¤é–‹é ­ï¼ˆç©ºå­—ä¸²æœƒæ˜¯ Trueï¼‰\n",
        "        if not cmd.startswith(self.command):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        return None # é è¨­ä¸è™•ç†äº¤çµ¦ä¸‹ä¸€å€‹æŒ‡ä»¤è™•ç†å™¨"
      ],
      "metadata": {
        "id": "-mDRSmw6_vly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import unquote\n",
        "\n",
        "class WebSearchCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/w',\n",
        "            'web_search_preview',\n",
        "            'ğŸŒ',\n",
        "            verbose\n",
        "        )\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True\n",
        "\n",
        "    def show_search_results(self, response):\n",
        "        if response.output[0].type != \"web_search_call\":\n",
        "            return\n",
        "        content = response.output[1].content[0]\n",
        "        for i, annotaion in enumerate(\n",
        "            content.annotations, start=1\n",
        "        ):\n",
        "            print(f'{i}. {annotaion.title}')\n",
        "            print(f'   {unquote(annotaion.url)}')\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "JgXxEfcoAOWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FileSearchCommand(BaseComand):\n",
        "    def __init__(self, vector_store_id=None, verbose=False):\n",
        "        super().__init__(\n",
        "            '/f',\n",
        "            'file_search',\n",
        "            'ğŸ”',\n",
        "            verbose\n",
        "        )\n",
        "        self.vector_store_id = vector_store_id\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if len(cmd) < 4: # /f[.]ï¼Œä¸æ˜¯å†’è™ŸåŠ æª”å/ç¶²å€\n",
        "            if self.vector_store_id == None:\n",
        "                print('è«‹å…ˆä½¿ç”¨ /f:[è·¯å¾‘|ç¶²å€]ä¸Šå‚³æª”æ¡ˆ')\n",
        "                return True # æ²’æœ‰å‘é‡è³‡æ–™åº«ç„¡æ³•åˆ‡æ›\n",
        "            turn_on = (idx == -1) # åˆ‡æ›é–‹/é—œæª”æ¡ˆæª¢ç´¢\n",
        "        else: # /f:æª”å|ç¶²å€ï¼Œä¸Šå‚³æª”æ¡ˆä¸¦é–‹å•Ÿæª¢ç´¢åŠŸèƒ½\n",
        "            turn_on = True\n",
        "            file_path = cmd[3:]\n",
        "            file_id= upload_file(file_path)\n",
        "            if not file_id:\n",
        "                print(f'ç„¡æ³•ä¸Šå‚³æª”æ¡ˆï¼š{file_path}')\n",
        "                return True\n",
        "            if self.vector_store_id == None:\n",
        "                vector_store = client.vector_stores.create(\n",
        "                    name=\"temp\",\n",
        "                    file_ids=[file_id],\n",
        "                )\n",
        "                self.vector_store_id = vector_store.id\n",
        "            else:\n",
        "                client.vector_stores.files.create(\n",
        "                    self.vector_store_id,\n",
        "                    file_id=file_id\n",
        "                )\n",
        "        if turn_on:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'vector_store_ids': [self.vector_store_id]\n",
        "            })\n",
        "            self.extra_args = {\n",
        "                'include': ['file_search_call.results']\n",
        "            }\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "            self.extra_args = {}\n",
        "        return True\n",
        "\n",
        "    def remove_vector_store(self, chat):\n",
        "        if self.vector_store_id == None: return\n",
        "        idx = chat.find_tool_index('file_search')\n",
        "        if idx: chat.tools.pop(idx)\n",
        "        response = client.vector_stores.files.list(\n",
        "            self.vector_store_id\n",
        "        )\n",
        "        for vector_file in response.data:\n",
        "            client.files.delete(vector_file.id)\n",
        "        client.vector_stores.delete(self.vector_store_id)\n",
        "\n",
        "    def show_file_search_results(self, response):\n",
        "        if response.output[0].type != 'file_search_call':\n",
        "            return\n",
        "        results = response.output[0].results\n",
        "        if not results: return\n",
        "        for i, result in enumerate(results, start=1):\n",
        "            display(Markdown('---'))\n",
        "            print(f'{i}. {result.filename}({result.score})')\n",
        "            display(Markdown('---'))\n",
        "            display(Markdown(result.text))\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_file_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "MB5meaUaBdK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYGBb4BFRtt0"
      },
      "source": [
        "## 5-1 èªè­˜ function calling æ©Ÿåˆ¶"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNlGRADVRvnn"
      },
      "source": [
        "## 5-2 æä¾›å®¢è£½æœå°‹åŠŸèƒ½"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w6fD04SXlvE"
      },
      "source": [
        "### æä¾› Google æœå°‹çš„å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vw5jVOPpYRIC"
      },
      "outputs": [],
      "source": [
        "!pip -q install googlesearch-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU6zOqkcYWzb"
      },
      "outputs": [],
      "source": [
        "from googlesearch import search\n",
        "for url in search('é«˜ä¸­æ’çƒè¯è³½'):\n",
        "    print(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90RvjK1zmgNc"
      },
      "source": [
        "- `lang` åƒæ•¸ä½¿ç”¨[é€™è£¡](https://developers.google.com/custom-search/docs/json_api_reference#supported-interface-languages)çš„å€¼ã€‚\n",
        "- `region` åƒæ•¸å¯ç”¨é€™è£¡æŸ¥åˆ°çš„[åœ‹åˆ¥ç¢¼](https://developers.google.com/custom-search/docs/json_api_reference#country-codes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnBedpbDYgNr"
      },
      "outputs": [],
      "source": [
        "for i, result in enumerate(\n",
        "    search(\n",
        "        'é«˜ä¸­æ’çƒè¯è³½',\n",
        "        advanced=True, # é€²éšæ¨¡å¼å¯å–å¾—æ¨™é¡Œã€æ‘˜è¦èˆ‡ç¶²å€\n",
        "        num_results=3, # æœå°‹ç­†æ•¸\n",
        "        lang='zh-TW',  # é™å®šèªè¨€\n",
        "        region='tw',   # é™å®šå€åŸŸ\n",
        "        unique=True    # ç¯©é™¤é‡è¤‡é€£çµ\n",
        "    ),\n",
        "    start=1\n",
        "):\n",
        "    print(f'{i}. {result.title}')\n",
        "    print(result.description)\n",
        "    print(result.url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAGkH58xblXO"
      },
      "source": [
        "ç”¨ JSON æ•´ç†æœå°‹çµæœç¶“éæ¸¬è©¦æ•ˆæœä¼¼ä¹æ²’æœ‰ Markdown å¥½ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24HWcFOHZBrv"
      },
      "outputs": [],
      "source": [
        "def google_res(keyword, num_results=5):\n",
        "    content = \"\"\n",
        "    num_results = max(num_results, 5) # æœ€å°‘ 5 ç­†\n",
        "    for result in search( # ä¸€ä¸€ä¸²æ¥æœå°‹çµæœ\n",
        "        keyword,\n",
        "        advanced=True,\n",
        "        num_results=num_results,\n",
        "        lang='zh-TW'\n",
        "    ):\n",
        "        # ä½¿ç”¨ markdown æ ¼å¼æ•´ç†æœå°‹çµæœ\n",
        "        content += (f\"- [{result.title}]({result.url})\\n\"\n",
        "                    f\"    {result.description}\\n\")\n",
        "    return content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrBW1XCraSng"
      },
      "outputs": [],
      "source": [
        "display(Markdown(google_res('é«˜ä¸­æ’çƒè¯è³½å† è»')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt6pqPS_v4vV"
      },
      "source": [
        "### ä½¿ç”¨ JSON Schema æè¿°å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsdKX-WNaTGN"
      },
      "outputs": [],
      "source": [
        "# æè¿° google_res å·¥å…·å‡½å¼çš„åƒæ•¸\n",
        "class GoogleRes(BaseModel):\n",
        "    keyword: str = Field(description='è¦æœå°‹çš„é—œéµå­—')\n",
        "    num_results: int = Field(\n",
        "        description='æœå°‹çµæœæ•¸ç›®ï¼Œä¸æä¾›é è¨­ 5 ç­†'\n",
        "    )\n",
        "\n",
        "# å¯¦éš›è¦é€çµ¦æ¨¡å‹æè¿°åƒæ•¸çš„å…§å®¹ (å­—å…¸)\n",
        "pprint(GoogleRes.model_json_schema())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MAdvconb__G"
      },
      "outputs": [],
      "source": [
        "tools = [{\n",
        "    \"type\":\"function\",\n",
        "    \"name\": \"google_res\",                  # å‡½å¼åç¨±\n",
        "    \"description\": \"å–å¾— Google æœå°‹çµæœ\", # å‡½å¼èªªæ˜\n",
        "    \"parameters\": GoogleRes.model_json_schema(), # åƒæ•¸è¦æ ¼\n",
        "}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td2nBJoBv0BU"
      },
      "source": [
        "### ä½¿ç”¨ function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJHrcYEMcerB"
      },
      "outputs": [],
      "source": [
        "query = \"é«˜ä¸­æ’çƒè¯è³½å† è»\" # æ¥è‘—è¦è©¢å•çš„å•é¡Œ\n",
        "\n",
        "response = client.responses.create(\n",
        "    model = \"gpt-4.1-nano\",\n",
        "    input = query,\n",
        "    tools = tools,\n",
        "    parallel_tool_calls=False, # é™åˆ¶åªèƒ½å«ç”¨ä¸€æ¬¡\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bj5_jNtcn6s"
      },
      "outputs": [],
      "source": [
        "pprint(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AunfH0W1cyJo"
      },
      "outputs": [],
      "source": [
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5aR-p3gTIYB"
      },
      "source": [
        "### ä¾æ“šæ¨¡å‹æŒ‡ç¤ºå«ç”¨å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FbhrycEc09R"
      },
      "outputs": [],
      "source": [
        "# å–å¾—å»ºè­°å«ç”¨å‡½å¼çš„è³‡è¨Š\n",
        "if response.output[0].type == 'function_call':\n",
        "    tool_call = response.output[0]\n",
        "    tool_info = f'{tool_call.name}(**{tool_call.arguments})'\n",
        "    print(tool_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VqKFS5ZecJO"
      },
      "outputs": [],
      "source": [
        "response1 = client.responses.create(\n",
        "    model='gpt-4.1-nano',\n",
        "    input=[\n",
        "        {\"role\": \"user\", \"content\": query},\n",
        "        # å‚³å› AI å‚³çµ¦æˆ‘å€‘çš„ function calling æŒ‡ç¤º\n",
        "        tool_call,\n",
        "        {   # å»ºç«‹å¯å‚³å›å‡½å¼åŸ·è¡Œçµæœçš„å­—å…¸\n",
        "            \"type\": \"function_call_output\", # å·¥å…·åŸ·è¡Œçµæœé¡å‹\n",
        "            \"call_id\": tool_call.call_id, # å«ç”¨å‡½å¼çš„è­˜åˆ¥ç¢¼\n",
        "            \"output\": eval(tool_info) # å«ç”¨å‡½å¼å–å¾—çµæœ\n",
        "        }\n",
        "    ],\n",
        "    tools=tools\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quiD_EuPfJEe"
      },
      "outputs": [],
      "source": [
        "print(response1.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKza0BsqTqKf"
      },
      "source": [
        "#### åˆ©ç”¨ä¸²æ¥å›æ‡‰çš„æ–¹å¼ä½¿ç”¨ function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ-OmDy-ToxC"
      },
      "outputs": [],
      "source": [
        "response2 = client.responses.create(\n",
        "    model='gpt-4.1-nano',\n",
        "    input=[\n",
        "        # ä¸ç”¨é‡å‚³æç¤ºå…§å®¹\n",
        "        # {\"role\": \"user\", \"content\": query},\n",
        "        # å‚³å› AI å‚³çµ¦æˆ‘å€‘çš„ function calling æŒ‡ç¤º\n",
        "        # tool_call,\n",
        "        {   # å»ºç«‹å¯å‚³å›å‡½å¼åŸ·è¡Œçµæœçš„å­—å…¸\n",
        "            \"type\": \"function_call_output\", # ä»¥å·¥å…·è§’è‰²é€å‡ºå›è¦†\n",
        "            \"call_id\": tool_call.call_id, # å«ç”¨å‡½å¼çš„è­˜åˆ¥ç¢¼\n",
        "            \"output\": eval(tool_info) # å«ç”¨å‡½å¼å–å¾—çµæœ\n",
        "        }\n",
        "    ],\n",
        "    tools=tools,\n",
        "    previous_response_id=response.id\n",
        ")\n",
        "\n",
        "print(response2.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response1.usage.input_tokens)\n",
        "pprint(response2.usage.input_tokens)"
      ],
      "metadata": {
        "id": "GU5vbqDbzPx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va1sI8aQ5K3C"
      },
      "source": [
        "### å»ºç«‹æ–¹ä¾¿é€²è¡Œ function calling çš„è¼”åŠ©å‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg8IAOZbfNXK"
      },
      "outputs": [],
      "source": [
        "# å«ç”¨å–®ä¸€å‡½å¼ä¸¦ä¸”å°‡å‡½å¼åŸ·è¡Œçµæœçµ„æˆè¨Šæ¯å¾Œå‚³å›\n",
        "def make_tool_msg(tool_call):\n",
        "    tool_info = f'{tool_call.name}(**{tool_call.arguments})'\n",
        "    result = eval(tool_info)\n",
        "    return {   # å»ºç«‹å¯å‚³å›å‡½å¼åŸ·è¡Œçµæœçš„å­—å…¸\n",
        "        \"type\": \"function_call_output\", # ä»¥å·¥å…·è§’è‰²é€å‡ºå›è¦†\n",
        "        \"call_id\": tool_call.call_id, # å«ç”¨å‡½å¼çš„è­˜åˆ¥ç¢¼\n",
        "        \"output\": result # å‡½å¼å‚³å›å€¼\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C98fdbThhRHj"
      },
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    input=query,\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "# å–å¾—å»ºè­°å«ç”¨å‡½å¼çš„è³‡è¨Š\n",
        "if response.output[0].type == 'function_call':\n",
        "    tool_call = response.output[0]\n",
        "    response = client.responses.create(\n",
        "        model='gpt-4.1-mini',\n",
        "        input=[\n",
        "            {\"role\":\"user\", \"content\":query},\n",
        "            # å‚³å› AI å‚³çµ¦æˆ‘å€‘çš„ function calling æŒ‡ç¤º\n",
        "            tool_call,\n",
        "            # å†åŠ ä¸ŠåŒ…å«å‡½å¼åŸ·è¡Œçµæœçš„å­—å…¸\n",
        "            make_tool_msg(tool_call)\n",
        "        ],\n",
        "        tools=tools\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YM294kPhbV0"
      },
      "outputs": [],
      "source": [
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_Gh-zRO8ix4"
      },
      "source": [
        "### åŒæ™‚å«ç”¨å¤šå€‹å‡½å¼ï¼ˆparallel function callingï¼‰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlBjQ3SFhgFS"
      },
      "outputs": [],
      "source": [
        "query = \"2025 å¥§æ–¯å¡æœ€ä½³ç”·ä¸»è§’èˆ‡ 2024 å¥§æ–¯å¡æœ€ä½³å¥³ä¸»è§’å„æ˜¯èª°ï¼Ÿ\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fw8HXQfjiFNs"
      },
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model = \"gpt-4.1-mini\",\n",
        "    input = query,\n",
        "    tools = tools,\n",
        ")\n",
        "\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2IAijvgiKnP"
      },
      "outputs": [],
      "source": [
        "def call_tools(tool_calls):\n",
        "    msgs = []\n",
        "    for tool_call in tool_calls:\n",
        "        if tool_call.type == 'function_call':\n",
        "            msgs.append(make_tool_msg(tool_call))\n",
        "    return msgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTCUQTjXiWhP"
      },
      "outputs": [],
      "source": [
        "tool_calls = response.output\n",
        "\n",
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    input=[{\"role\": \"user\", \"content\": query}]\n",
        "        # å‚³å› AI å‚³çµ¦æˆ‘å€‘çš„ function calling æŒ‡ç¤º\n",
        "        + tool_calls\n",
        "        # æˆ‘å€‘åŸ·è¡Œå‡½å¼çš„çµæœ\n",
        "        + call_tools(tool_calls)\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMrcjnhoaMB6"
      },
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model = \"gpt-4.1-mini\",\n",
        "    input = query,\n",
        "    tools = tools,\n",
        "    parallel_tool_calls=False\n",
        ")\n",
        "\n",
        "pprint(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCN1jbtRFjhP"
      },
      "source": [
        "### ä¸²æµæ¨¡å¼ä¸‹çš„ function calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwZbAW01i7UP"
      },
      "outputs": [],
      "source": [
        "response = client.responses.create(\n",
        "    model = \"gpt-4.1-mini\",\n",
        "    input = query,\n",
        "    tools = tools,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "    pprint(chunk)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8tq94B_eMk0"
      },
      "source": [
        "## 5-3 å¹«ç°¡æ˜“èŠå¤©æ‡‰ç”¨ç¨‹å¼åŠ å…¥ function calling åŠŸèƒ½"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è¨­è¨ˆè™•ç†è‡ªè¨‚å‡½å¼å·¥å…·çš„é¡åˆ¥"
      ],
      "metadata": {
        "id": "9e_-06Si0g4h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def make_tool_msg(tool_call):\n",
        "é€™è£¡æœ‰æ›´æ–°ç¨‹å¼ç¢¼ï¼ŒåŸæœ¬åˆç‰ˆï¼ˆ2025/6ï¼‰æ›¸ä¸Šçš„ `make_tool_msg` æ–¹æ³•çš„ç¨‹å¼ç¢¼å¦‚ä¸‹ï¼š\n",
        "\n",
        "```python\n",
        "    # å«ç”¨å–®ä¸€å‡½å¼ä¸¦ä¸”å°‡å‡½å¼åŸ·è¡Œçµæœçµ„æˆè¨Šæ¯å¾Œå‚³å›\n",
        "    def make_tool_msg(self, tool_call):\n",
        "        tool_info = f'{tool_call.name}(**{tool_call.arguments})'\n",
        "        if self.verbose: print(f'å«ç”¨ï¼š{tool_info}')\n",
        "        result = eval(tool_info)\n",
        "        return {   # å»ºç«‹å¯å‚³å›å‡½å¼åŸ·è¡Œçµæœçš„å­—å…¸\n",
        "            \"type\": \"function_call_output\", # ä»¥å·¥å…·è§’è‰²é€å‡ºå›è¦†\n",
        "            \"call_id\": tool_call.call_id, # å«ç”¨å‡½å¼çš„è­˜åˆ¥ç¢¼\n",
        "            \"output\": result # å‡½å¼å‚³å›å€¼\n",
        "        }\n",
        "```\n",
        "\n",
        "ä½†ç”±æ–¼ `tool_call.arguments` æ˜¯ JSONï¼Œå…¶ä¸­åƒæ˜¯ `true/false` å¤§å°å¯«èˆ‡ Python ä¸åŒï¼Œè‹¥ç›´æ¥ä»¥å­—ä¸²å‚³å…¥ `eval` æœƒå‡ºéŒ¯ï¼Œé›–ç„¶æœ¬ç« ä¸æœƒå‡ºç¾æœ‰å•é¡Œçš„ç‹€æ³ï¼Œä½†åœ¨å…¶ä»–æ‡‰ç”¨æ™‚å°±å¯èƒ½æœƒé‡åˆ°ï¼Œå› æ­¤åº•ä¸‹ 29ï½31 è¡Œæ”¹ç‚ºå…ˆè½‰æˆ Python å­—å…¸çš„æ–¹å¼ï¼š"
      ],
      "metadata": {
        "id": "HzmoEfqtzb3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FunctionCallingCommand(BaseComand):\n",
        "    def __init__(self, tools=None, verbose=False):\n",
        "        super().__init__(\n",
        "            '/t',\n",
        "            'function',\n",
        "            '',\n",
        "            verbose\n",
        "        )\n",
        "        self.tools = tools or []\n",
        "        self.enabled = False\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        if not self.enabled: # åŠ å…¥è‡ªè¨‚å‡½å¼å·¥å…·\n",
        "            chat.tools.extend(self.tools)\n",
        "        else: # ç§»é™¤è‡ªè¨‚å·¥å…·å‡½å¼\n",
        "            chat.tools = [\n",
        "                tool for tool in chat.tools\n",
        "                if tool['type'] != self.tool_name\n",
        "            ]\n",
        "        self.enabled = not self.enabled\n",
        "        return True\n",
        "\n",
        "    # å«ç”¨å–®ä¸€å‡½å¼ä¸¦ä¸”å°‡å‡½å¼åŸ·è¡Œçµæœçµ„æˆè¨Šæ¯å¾Œå‚³å›\n",
        "    def make_tool_msg(self, tool_call):\n",
        "        tool_info = f'{tool_call.name}(**{tool_call.arguments})'\n",
        "        if self.verbose: print(f'å«ç”¨ï¼š{tool_info}')\n",
        "        func = eval(tool_call.name)\n",
        "        args = json.loads(tool_call.arguments)\n",
        "        result = func(**args)\n",
        "        return {   # å»ºç«‹å¯å‚³å›å‡½å¼åŸ·è¡Œçµæœçš„å­—å…¸\n",
        "            \"type\": \"function_call_output\", # ä»¥å·¥å…·è§’è‰²é€å‡ºå›è¦†\n",
        "            \"call_id\": tool_call.call_id, # å«ç”¨å‡½å¼çš„è­˜åˆ¥ç¢¼\n",
        "            \"output\": result # å‡½å¼å‚³å›å€¼\n",
        "        }\n",
        "\n",
        "    def call_tools(self, tool_calls):\n",
        "        msgs = []\n",
        "        for tool_call in tool_calls:\n",
        "            if tool_call.type == 'function_call':\n",
        "                msgs.append(self.make_tool_msg(tool_call))\n",
        "        return msgs if msgs else None\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.enabled: return None\n",
        "        if event.type != 'response.completed':\n",
        "            return None\n",
        "        # å‘¼å«å‡½å¼\n",
        "        tool_calls = event.response.output\n",
        "        tool_results = self.call_tools(tool_calls)\n",
        "        if tool_results: return tool_calls + tool_results\n",
        "        return None"
      ],
      "metadata": {
        "id": "p0pra51NMW4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¿®æ”¹ Chat é¡åˆ¥æ­é… function calling é‹ä½œ"
      ],
      "metadata": {
        "id": "bn3BE4AP05it"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, **kwargs):\n",
        "        self._client = client\n",
        "        self._last_id = kwargs.pop('last_id', None)\n",
        "        # é™åˆ¶å·¥å…·åŸ·è¡Œåœˆæ•¸ï¼Œé¿å…ç„¡çª®ç›¡å«ç”¨å·¥å…·\n",
        "        self._max_tools_rounds = kwargs.pop('max_tools_rounds', 4)\n",
        "        self.tools = [] # é è¨­æ²’æœ‰ä½¿ç”¨å·¥å…·\n",
        "        self._commands = kwargs.pop('commands', [])\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', 'ä½¿ç”¨ç¹é«”ä¸­æ–‡')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        tool_results = [] # å‡½å¼å«ç”¨çš„ç›¸é—œè³‡è¨Š\n",
        "        for command in self._commands:\n",
        "            kwargs.update(command.extra_args)\n",
        "        try:\n",
        "            messages = [{'role': 'user', 'content': msg}]\n",
        "            for _ in range(self._max_tools_rounds):\n",
        "                # æ–¹ä¾¿ç¨å¾Œä¸²æ¥å‡½å¼å«ç”¨è³‡è¨Š\n",
        "                if tool_results: # ä¸²æ¥å«ç”¨å‡½å¼çš„è³‡è¨Š\n",
        "                    messages += tool_results\n",
        "                response = self._client.responses.create(\n",
        "                    instructions=instructions,\n",
        "                    model=model,\n",
        "                    input=messages,\n",
        "                    stream=True, # éƒ½ä»¥ä¸²æµæ–¹å¼è™•ç†ï¼Œç°¡åŒ–ç¨‹å¼é‚è¼¯\n",
        "                    previous_response_id=self._last_id, # ä¸²æ¥å›æ‡‰\n",
        "                    **kwargs\n",
        "                )\n",
        "                for event in response:\n",
        "                    for command in self._commands:\n",
        "                        result = command.handle_event(\n",
        "                            self, stream, event\n",
        "                        )\n",
        "                        if result: break\n",
        "                    tool_results = []\n",
        "                    if isinstance(result, list):\n",
        "                        # å·¥å…·è¦é€å›çµ¦æ¨¡å‹çš„è¨Šæ¯ä¸²åˆ—\n",
        "                        tool_results = result\n",
        "                        break\n",
        "                    if event.type == 'response.output_text.delta':\n",
        "                        if stream: yield event.delta\n",
        "                    elif event.type == (\n",
        "                        'response.output_text.done'\n",
        "                    ):\n",
        "                        # éä¸²æµæ¨¡å¼è¦å‚³å›å®Œæ•´å…§å®¹\n",
        "                        if not stream:\n",
        "                            yield event.text\n",
        "                    elif event.type == 'response.completed':\n",
        "                        # æ›´æ–°æœ€å¾Œå›æ‡‰çš„è­˜åˆ¥ç¢¼\n",
        "                        self._last_id = event.response.id\n",
        "                if not tool_results:\n",
        "                    # æ²’æœ‰è¦é€å›çµ¦æ¨¡å‹çš„è¨Šæ¯\n",
        "                    # è¡¨ç¤ºå·²ç¶“æˆåŠŸç”Ÿæˆå…§å®¹\n",
        "                    break\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def find_tool_index(self, tool_type):\n",
        "        for i, tool in enumerate(self.tools):\n",
        "            if tool['type'] == tool_type: return i\n",
        "        return -1\n",
        "\n",
        "    def _get_prompt(self):\n",
        "        prompt = ''\n",
        "        for command in self._commands:\n",
        "            idx = self.find_tool_index(command.tool_name)\n",
        "            if idx != -1:\n",
        "                prompt += f'{command.icon}'\n",
        "        user_tools_count = len(self.tools) - len(prompt)\n",
        "        prompt += f'(ğŸ› ï¸{user_tools_count})>>> '\n",
        "        return prompt\n",
        "\n",
        "    def _process_command(self, cmd):\n",
        "        for command in self._commands:\n",
        "            if command.handle_command(self, cmd):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"ç›´æ¥æŒ‰ â†µ å¯çµæŸå°è©±\")\n",
        "        while True:\n",
        "            user_msg = input(self._get_prompt())\n",
        "            if not user_msg.strip(): break # ç›´æ¥ â†µ å°±çµæŸ\n",
        "            if self._process_command(user_msg):\n",
        "                continue # æŒ‡ä»¤ä¸éœ€å›è¦†ï¼Œå›é ­è®“ä½¿ç”¨è€…è¼¸å…¥\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(\n",
        "                user_msg,\n",
        "                tools=self.tools, # å‚³å…¥è¦ä½¿ç”¨çš„å·¥å…·\n",
        "                **kwargs\n",
        "            ):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(\n",
        "                {\n",
        "                    'last_id': self._last_id,\n",
        "                    'tools': self.tools,\n",
        "                    'commands': self._commands\n",
        "                },\n",
        "                f\n",
        "            )\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self._last_id = data['last_id']\n",
        "            self.tools = data['tools']\n",
        "            self._commands = data['commands']\n",
        "\n",
        "    def show_thread(self):\n",
        "        if not self._last_id: return\n",
        "        inputs = client.responses.input_items.list(self._last_id)\n",
        "        response = client.responses.retrieve(self._last_id)\n",
        "        for item in inputs.data[::-1]:\n",
        "            # ç•¥éå‡½å¼å«ç”¨æŒ‡ç¤ºç­‰éè¨Šæ¯å…§å®¹\n",
        "            if item.type != 'message': continue\n",
        "            prompt = \">>> \" if item.role == 'user' else ''\n",
        "            for content in item.content:\n",
        "                print(f'{prompt}{content.text}')\n",
        "        print(response.output_text)\n",
        "\n",
        "    def delete_thread(self):\n",
        "        if not self._last_id: return\n",
        "        last_id = self._last_id\n",
        "        while last_id:\n",
        "            response = client.responses.retrieve(last_id)\n",
        "            last_id, curr_id = (\n",
        "                response.previous_response_id,\n",
        "                last_id\n",
        "            )\n",
        "            client.responses.delete(curr_id)\n",
        "        self._last_id = None"
      ],
      "metadata": {
        "id": "Hj0B2O9rWb8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvItOflxeShT"
      },
      "source": [
        "### æ¸¬è©¦ä½¿ç”¨è‡ªè¨‚å·¥å…·å‡½å¼èŠå¤©"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¯ç”¨ä¾†æ¸¬è©¦ä¸Šå‚³ PDF çš„è€³æ©Ÿèªªæ˜æ›¸æª”æ¡ˆç¶²å€ï¼š\n",
        "\n",
        "```\n",
        "https://coolermaster.egnyte.com/dd/BtL7gG2IW6/\n",
        "```"
      ],
      "metadata": {
        "id": "i5o3fG-bJbjV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAPPYlrvsqEx"
      },
      "outputs": [],
      "source": [
        "file_search_command = FileSearchCommand()\n",
        "\n",
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[\n",
        "        FunctionCallingCommand(tools=tools),\n",
        "        file_search_command\n",
        "    ]\n",
        ")\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTBI8hMYaNDP"
      },
      "outputs": [],
      "source": [
        "chat.delete_thread()\n",
        "file_search_command.remove_vector_store(chat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1NonU7ieVsg"
      },
      "source": [
        "### æª¢è¦–å‡½å¼å«ç”¨çš„æŒ‡ç¤º"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNUL8G-vGYC9"
      },
      "outputs": [],
      "source": [
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[\n",
        "        FunctionCallingCommand(tools=tools, verbose=True),\n",
        "        FileSearchCommand(),\n",
        "        WebSearchCommand()\n",
        "    ]\n",
        ")\n",
        "\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### å¼·åˆ¶ä½¿ç”¨å…§å»ºå·¥å…·"
      ],
      "metadata": {
        "id": "9AbF2XGC1HSR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zoy5JQC2kDZD"
      },
      "outputs": [],
      "source": [
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        "    tool_choice={'type': 'web_search_preview'}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¸å…è¨±å–®å›å«ç”¨å¤šå€‹å‡½å¼"
      ],
      "metadata": {
        "id": "lgicOFOl1K2v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoHRlB0RlZvK"
      },
      "outputs": [],
      "source": [
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        "    parallel_tool_calls=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO6oymNqqDZc"
      },
      "source": [
        "ç§»é™¤å‰›å‰›å»ºç«‹çš„è¨è«–ä¸²ä»¥åŠå‘é‡å„²å­˜å€ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwoXYPHFCm7H"
      },
      "outputs": [],
      "source": [
        "FileSearchCommand.remove_vector_store(chat)\n",
        "chat.delete_thread()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GLUU6X4rcUb"
      },
      "source": [
        "## 5-4 è®“ AI é•·å‡ºæ‰‹è…³æ‰“é€ æ™ºæ…§ CLI æŒ‡ä»¤ä»‹é¢"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJmP2QCQrfd5"
      },
      "source": [
        "### åŸ·è¡Œ shell æŒ‡ä»¤çš„è‡ªè¨‚å‡½å¼å·¥å…·\n",
        "\n",
        "- [Warp çµ‚ç«¯æ©Ÿè»Ÿé«”](https://on.warp.dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOgrwLIMIa-I"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def shell_helper(comment, shell_command):\n",
        "    # å•Ÿå‹•å­è¡Œç¨‹\n",
        "    process = subprocess.Popen(\n",
        "        shell_command,\n",
        "        shell=True,             # åœ¨ shell ä¸­åŸ·è¡Œ\n",
        "        stdout=subprocess.PIPE, # æ“·å–æ¨™æº–è¼¸å‡º\n",
        "        stderr=subprocess.PIPE, # æ“·å–éŒ¯èª¤è¼¸å‡º\n",
        "        text=True               # ä»¥æ–‡å­—å½¢å¼è¿”å›\n",
        "    )\n",
        "\n",
        "    result = 'åŸ·è¡Œçµæœï¼š\\n\\n```\\n'\n",
        "\n",
        "    # å³æ™‚è®€å–è¼¸å‡º\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        # å¦‚æœæ²’æœ‰è¼¸å‡ºä¸”è¡Œç¨‹çµæŸ\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            result += output\n",
        "\n",
        "    result += \"```\"\n",
        "\n",
        "    # æª¢æŸ¥éŒ¯èª¤è¼¸å‡º\n",
        "    error = process.stderr.read()\n",
        "    if error:\n",
        "        result += f\"\\n\\néŒ¯èª¤: {error}\"\n",
        "\n",
        "    # ç­‰å¾…è¡Œç¨‹çµæŸä¸¦å–å¾—è¿”å›ç¢¼\n",
        "    return_code = process.wait()\n",
        "    result += f\"\\n\\nå‘½ä»¤åŸ·è¡Œå®Œæˆï¼Œè¿”å›ç¢¼: {return_code}\\n\\n\"\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2QYrL0r5Ckk"
      },
      "outputs": [],
      "source": [
        "display(Markdown(\n",
        "    shell_helper('åˆ—å‡ºæª”æ¡ˆ', 'ls sample_data')\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh6unBA6rdon"
      },
      "source": [
        "### æä¾›æ¨¡å‹è‡ªè¨‚çš„ shell æŒ‡ä»¤åŸ·è¡Œå‡½å¼"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1y925nfu5SwY"
      },
      "outputs": [],
      "source": [
        "class ShellHelper(BaseModel):\n",
        "    comment: str = Field(\n",
        "        description='åˆ¤æ–·è¦åŸ·è¡ŒæŒ‡å®šçš„ shell æŒ‡ä»¤çš„åŸå› '\n",
        "    )\n",
        "    shell_command: str = Field(\n",
        "        description='è¦åŸ·è¡Œçš„ shell æŒ‡ä»¤'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUG-ySye5pVk"
      },
      "outputs": [],
      "source": [
        "shell_helper_tool = {\n",
        "    'type': 'function',\n",
        "    \"name\": \"shell_helper\",\n",
        "    \"description\": \"æˆ‘å¯ä»¥åŸ·è¡Œ shell æŒ‡ä»¤æ“æ§é›»è…¦\",\n",
        "    \"parameters\": ShellHelper.model_json_schema(),\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o7w5G9vrgYc"
      },
      "source": [
        "### æ¸¬è©¦ç”¨èªªçš„å°±å¯ä»¥æ“æ§é›»è…¦çš„æ¨‚è¶£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrrEGC7g5ylm"
      },
      "outputs": [],
      "source": [
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[FunctionCallingCommand(\n",
        "        tools=[shell_helper_tool],\n",
        "        verbose=True\n",
        "    )]\n",
        ")\n",
        "\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2HgXbMurjrM"
      },
      "source": [
        "### è™•ç† IPython ç‰¹æœ‰çš„å•é¡Œ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V21E4HHurmAA"
      },
      "source": [
        "- [IPython çš„å¥‡ç‰¹ feature](https://dev.to/codemee/ipython-de-qi-te-feature-2fn8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE3bFcIa67I3"
      },
      "outputs": [],
      "source": [
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "en0ul5SBTIGL"
      },
      "outputs": [],
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, **kwargs):\n",
        "        self._client = client\n",
        "        self._last_id = kwargs.pop('last_id', None)\n",
        "        # é™åˆ¶å·¥å…·åŸ·è¡Œåœˆæ•¸ï¼Œé¿å…ç„¡çª®ç›¡å«ç”¨å·¥å…·\n",
        "        self._max_tools_rounds = kwargs.pop('max_tools_rounds', 4)\n",
        "        self.tools = [] # é è¨­æ²’æœ‰ä½¿ç”¨å·¥å…·\n",
        "        self._commands = kwargs.pop('commands', [])\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', 'ä½¿ç”¨ç¹é«”ä¸­æ–‡')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        tool_results = [] # å‡½å¼å«ç”¨çš„ç›¸é—œè³‡è¨Š\n",
        "        for command in self._commands:\n",
        "            kwargs.update(command.extra_args)\n",
        "        try:\n",
        "            messages = [{'role': 'user', 'content': msg}]\n",
        "            for _ in range(self._max_tools_rounds):\n",
        "                # æ–¹ä¾¿ç¨å¾Œä¸²æ¥å‡½å¼å«ç”¨è³‡è¨Š\n",
        "                if tool_results: # ä¸²æ¥å«ç”¨å‡½å¼çš„è³‡è¨Š\n",
        "                    messages += tool_results\n",
        "                response = self._client.responses.create(\n",
        "                    instructions=instructions,\n",
        "                    model=model,\n",
        "                    input=messages,\n",
        "                    stream=True, # éƒ½ä»¥ä¸²æµæ–¹å¼è™•ç†ï¼Œç°¡åŒ–ç¨‹å¼é‚è¼¯\n",
        "                    previous_response_id=self._last_id, # ä¸²æ¥å›æ‡‰\n",
        "                    **kwargs\n",
        "                )\n",
        "                for event in response:\n",
        "                    for command in self._commands:\n",
        "                        result = command.handle_event(\n",
        "                            self, stream, event\n",
        "                        )\n",
        "                        if result: break\n",
        "                    tool_results = []\n",
        "                    if isinstance(result, list):\n",
        "                        # å·¥å…·è¦é€å›çµ¦æ¨¡å‹çš„è¨Šæ¯ä¸²åˆ—\n",
        "                        tool_results = result\n",
        "                        break\n",
        "                    if event.type == 'response.output_text.delta':\n",
        "                        if stream: yield event.delta\n",
        "                    elif event.type == (\n",
        "                        'response.output_text.done'\n",
        "                    ):\n",
        "                        # éä¸²æµæ¨¡å¼è¦å‚³å›å®Œæ•´å…§å®¹\n",
        "                        if not stream:\n",
        "                            yield event.text\n",
        "                    elif event.type == 'response.completed':\n",
        "                        # æ›´æ–°æœ€å¾Œå›æ‡‰çš„è­˜åˆ¥ç¢¼\n",
        "                        self._last_id = event.response.id\n",
        "                if not tool_results:\n",
        "                    # æ²’æœ‰è¦é€å›çµ¦æ¨¡å‹çš„è¨Šæ¯\n",
        "                    # è¡¨ç¤ºå·²ç¶“æˆåŠŸç”Ÿæˆå…§å®¹\n",
        "                    break\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def find_tool_index(self, tool_type):\n",
        "        for i, tool in enumerate(self.tools):\n",
        "            if tool['type'] == tool_type: return i\n",
        "        return -1\n",
        "\n",
        "    def _get_prompt(self):\n",
        "        prompt = ''\n",
        "        for command in self._commands:\n",
        "            idx = self.find_tool_index(command.tool_name)\n",
        "            if idx != -1:\n",
        "                prompt += f'{command.icon}'\n",
        "        user_tools_count = len(self.tools) - len(prompt)\n",
        "        prompt += f'(ğŸ› ï¸{user_tools_count})>>> '\n",
        "        return prompt\n",
        "\n",
        "    def _process_command(self, cmd):\n",
        "        for command in self._commands:\n",
        "            if command.handle_command(self, cmd):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"ç›´æ¥æŒ‰ â†µ å¯çµæŸå°è©±\")\n",
        "        while True:\n",
        "            user_msg = input(self._get_prompt())\n",
        "            if not user_msg.strip(): break # ç›´æ¥ â†µ å°±çµæŸ\n",
        "            if self._process_command(user_msg):\n",
        "                continue # æŒ‡ä»¤ä¸éœ€å›è¦†ï¼Œå›é ­è®“ä½¿ç”¨è€…è¼¸å…¥\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(\n",
        "                user_msg,\n",
        "                tools=self.tools, # å‚³å…¥è¦ä½¿ç”¨çš„å·¥å…·\n",
        "                **kwargs\n",
        "            ):\n",
        "                text += reply\n",
        "                if os.path.exists(text):\n",
        "                    display_handle.update(Markdown(f' text'))\n",
        "                else:\n",
        "                    display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(\n",
        "                {\n",
        "                    'last_id': self._last_id,\n",
        "                    'tools': self.tools,\n",
        "                    'commands': self._commands\n",
        "                },\n",
        "                f\n",
        "            )\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self._last_id = data['last_id']\n",
        "            self.tools = data['tools']\n",
        "            self._commands = data['commands']\n",
        "\n",
        "    def show_thread(self):\n",
        "        if not self._last_id: return\n",
        "        inputs = client.responses.input_items.list(self._last_id)\n",
        "        response = client.responses.retrieve(self._last_id)\n",
        "        for item in inputs.data[::-1]:\n",
        "            # ç•¥éå‡½å¼å«ç”¨æŒ‡ç¤ºç­‰éè¨Šæ¯å…§å®¹\n",
        "            if item.type != 'message': continue\n",
        "            prompt = \">>> \" if item.role == 'user' else ''\n",
        "            for content in item.content:\n",
        "                print(f'{prompt}{content.text}')\n",
        "        print(response.output_text)\n",
        "\n",
        "    def delete_thread(self):\n",
        "        if not self._last_id: return\n",
        "        last_id = self._last_id\n",
        "        while last_id:\n",
        "            response = client.responses.retrieve(last_id)\n",
        "            last_id, curr_id = (\n",
        "                response.previous_response_id,\n",
        "                last_id\n",
        "            )\n",
        "            client.responses.delete(curr_id)\n",
        "        self._last_id = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_sThwFiwtJXZ"
      },
      "outputs": [],
      "source": [
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[FunctionCallingCommand(\n",
        "        tools=[shell_helper_tool],\n",
        "        verbose=True\n",
        "    )]\n",
        ")\n",
        "\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xmhE5XzEJiM"
      },
      "source": [
        "### è¨­ç«‹é˜²è­·æ©Ÿåˆ¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1F9144yoyUFK"
      },
      "outputs": [],
      "source": [
        "class SafeCommandChecker(BaseModel):\n",
        "    model_config = ConfigDict(extra='forbid')\n",
        "    safe: bool = Field(\n",
        "        description='æ˜¯å¦å®‰å…¨'\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CWCn_zm2gsR"
      },
      "outputs": [],
      "source": [
        "s = SafeCommandChecker.model_validate_json('{\"safe\": true}')\n",
        "s.safe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8uVEEmgx2Nk"
      },
      "outputs": [],
      "source": [
        "def is_safe_command(shell_command):\n",
        "    client = openai.OpenAI(\n",
        "        api_key=userdata.get('OPENAI_API_KEY')\n",
        "    )\n",
        "    json_schema = SafeCommandChecker.model_json_schema()\n",
        "    response = client.responses.create(\n",
        "        model = \"gpt-4.1-mini\",\n",
        "        instructions=\"åˆ¤æ–·ä»¥ä¸‹ shell æŒ‡ä»¤æ˜¯å¦å®‰å…¨\",\n",
        "        input = (\n",
        "            \"åŸ·è¡Œä»¥ä¸‹ shell æŒ‡ä»¤æ˜¯å¦å®‰å…¨ï¼Ÿn\\n\"\n",
        "            \"```\\n\"\n",
        "            f\"{shell_command}\\n\"\n",
        "            \"```\"\n",
        "        ),\n",
        "        text = {\n",
        "            \"format\": {\n",
        "                \"type\": \"json_schema\",\n",
        "                \"name\": json_schema[\"title\"],\n",
        "                \"schema\": json_schema\n",
        "            }\n",
        "        },\n",
        "        store=False\n",
        "    )\n",
        "    return SafeCommandChecker.model_validate_json(\n",
        "        response.output_text\n",
        "    ).safe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjPBoYM84Zms"
      },
      "outputs": [],
      "source": [
        "print(is_safe_command('rm -f /*'))\n",
        "print(is_safe_command('rm sample_data/test.txt'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeRHwMD5xpxO"
      },
      "outputs": [],
      "source": [
        "def shell_helper(comment, shell_command):\n",
        "\n",
        "    if not is_safe_command(shell_command):\n",
        "        return 'æŒ‡ä»¤ä¸å®‰å…¨ï¼Œç„¡æ³•åŸ·è¡Œ'\n",
        "\n",
        "    # å•Ÿå‹•å­è¡Œç¨‹\n",
        "    process = subprocess.Popen(\n",
        "        shell_command,\n",
        "        shell=True,             # åœ¨ shell ä¸­åŸ·è¡Œ\n",
        "        stdout=subprocess.PIPE, # æ“·å–æ¨™æº–è¼¸å‡º\n",
        "        stderr=subprocess.PIPE, # æ“·å–éŒ¯èª¤è¼¸å‡º\n",
        "        text=True               # ä»¥æ–‡å­—å½¢å¼è¿”å›\n",
        "    )\n",
        "\n",
        "    result = 'åŸ·è¡Œçµæœï¼š\\n\\n```\\n'\n",
        "\n",
        "    # å³æ™‚è®€å–è¼¸å‡º\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        # å¦‚æœæ²’æœ‰è¼¸å‡ºä¸”è¡Œç¨‹çµæŸ\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            result += output\n",
        "\n",
        "    result += \"```\"\n",
        "\n",
        "    # æª¢æŸ¥éŒ¯èª¤è¼¸å‡º\n",
        "    error = process.stderr.read()\n",
        "    if error:\n",
        "        result += f\"\\n\\néŒ¯èª¤: {error}\"\n",
        "\n",
        "    # ç­‰å¾…è¡Œç¨‹çµæŸä¸¦å–å¾—è¿”å›ç¢¼\n",
        "    return_code = process.wait()\n",
        "    result += f\"\\n\\nå‘½ä»¤åŸ·è¡Œå®Œæˆï¼Œè¿”å›ç¢¼: {return_code}\\n\\n\"\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MnkLFIX1odv"
      },
      "outputs": [],
      "source": [
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[FunctionCallingCommand(\n",
        "        tools=[shell_helper_tool],\n",
        "        verbose=True\n",
        "    )]\n",
        ")\n",
        "\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}