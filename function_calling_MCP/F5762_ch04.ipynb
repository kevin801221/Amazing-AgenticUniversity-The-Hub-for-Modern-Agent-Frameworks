{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ç¬¬ 4 ç«  RAG çš„åŸºç¤â€“ç”¨æœå°‹èˆ‡æª¢ç´¢å¹« AI é•·çŸ¥è­˜"
      ],
      "metadata": {
        "id": "ajjqxLJBpWZh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cxw0fJ--_S7W"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from IPython.display import display, Markdown\n",
        "from rich.pretty import pprint\n",
        "import openai\n",
        "import sys\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "tAIagOOG_YRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-1 ä½¿ç”¨å…§å»ºæœå°‹å·¥å…·å¹« AI èµ°éå…¨ä¸–ç•Œ"
      ],
      "metadata": {
        "id": "e2sTsX1qpfUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\", # gpt-4.1-nano ä¸æ”¯æ´æœå°‹\n",
        "    input=\"2024å¹´åäºŒå¼·ä¸–ç•Œæ£’çƒè³½å† è»æ˜¯å“ªä¸€éšŠï¼Ÿ\"\n",
        ")\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "J-bCm4AV2CFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä½¿ç”¨ç¶²é æœå°‹çš„åƒ¹æ ¼å¯åƒè€ƒ[é€™è£¡](https://platform.openai.com/docs/pricing#web-search)ã€‚é›–ç„¶æœå°‹å…§å®¹ä¸æœƒç®—å…¥ tokens æ•¸é‡è¨ˆè²»ï¼Œä½†æœå°‹æ˜¯ä¾æ¬¡è¨ˆè²»ï¼Œæ²’æœ‰å¾ˆä¾¿å®œå–”ï¼Œè‡ªå·±ä½¿ç”¨ [Google Custom Search JSON API](https://developers.google.com/custom-search/v1/overview#pricing) å¯èƒ½é‚„ä¾¿å®œä¸€äº›ã€‚\n",
        "\n",
        "gpt-4o ä»¥åŠ gpt-4.1 å®¶æ—å¯ç”¨ï¼Œä¸å« gpt-4.1-nanoï¼Œä¹‹å‰æ¸¬è©¦ gpt-4o-mini æœå°‹æ•ˆæœä¸ä½³"
      ],
      "metadata": {
        "id": "Bj2BzuYLTgbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### å•Ÿç”¨å…§å»ºçš„æœå°‹åŠŸèƒ½"
      ],
      "metadata": {
        "id": "rgPrGy3kyW1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\", # gpt-4.1-nano ä¸æ”¯æ´æœå°‹\n",
        "    input=\"åäºŒå¼·ä¸–ç•Œæ£’çƒè³½å† è»æ˜¯å“ªä¸€éšŠï¼Ÿ\",\n",
        "    tools=[{\"type\": \"web_search_preview\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "Nxw04lX7Ti47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "IPython çš„ Markdown å¥½åƒè§£è­¯å›è¦†ä¸­çš„æ ¼å¼æœƒå‡ºéŒ¯ï¼Ÿ"
      ],
      "metadata": {
        "id": "dZlcwfjdXSwv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "Oub9u9_R6q1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "1YuuEMhBUiPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response)"
      ],
      "metadata": {
        "id": "X8hnNzEtUg2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "çœ‹ä¸å‡ºä¾†æœå°‹çš„é—œéµå­—æ˜¯ä»€éº¼ï¼Ÿ"
      ],
      "metadata": {
        "id": "v-HWFAKmwEoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import unquote\n",
        "\n",
        "def show_search_results(response):\n",
        "    if response.output[0].type != \"web_search_call\": return\n",
        "    content = response.output[1].content[0]\n",
        "    for i, annotaion in enumerate(content.annotations, start=1):\n",
        "        print(f'{i}. {annotaion.title}')\n",
        "        print(f'   {unquote(annotaion.url)}')\n",
        "\n",
        "show_search_results(response)"
      ],
      "metadata": {
        "id": "1Y2VJsoYV0MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response.usage)"
      ],
      "metadata": {
        "id": "ESg17dh4kte1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è¨­å®šæœå°‹åœ°å€"
      ],
      "metadata": {
        "id": "gR0expBNpmFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    input='æ¨è–¦å¥½åƒçš„ç¾©å¤§åˆ©é¤å»³',\n",
        "    tools=[{\"type\": \"web_search_preview\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "fpKuuPD7jtdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "KxaVAW03mpRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response.tools[0].user_location)"
      ],
      "metadata": {
        "id": "JLygcErLmwaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [ISO åœ‹åˆ¥ç¢¼](https://zh.wikipedia.org/zh-tw/ISO_3166-1)\n",
        "- [IANA æ™‚å€](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)"
      ],
      "metadata": {
        "id": "Fu3CuPwZS9JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    input='æ¨è–¦å¥½åƒçš„ç¾©å¤§åˆ©é¤å»³',\n",
        "    tools=[\n",
        "        {\n",
        "            \"type\": \"web_search_preview\",\n",
        "            \"user_location\": {\n",
        "                \"type\": \"approximate\", # å›ºå®šå…§å®¹\n",
        "                \"country\": \"TW\", # ISO åœ‹åˆ¥ç¢¼\n",
        "                \"timezone\": \"Asia/Taipei\", # IANA æ™‚å€\n",
        "                \"region\": \"å°åŒ—\", # è‡ªç”±å¡«å¯«\n",
        "                \"city\": \"å°åŒ—\"    # è‡ªç”±å¡«å¯«\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "Aa4piBOEnDC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "brIZp4ZcnmnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è¨­å®šæä¾›çµ¦æ¨¡å‹çš„æœå°‹è³‡æ–™é‡"
      ],
      "metadata": {
        "id": "mo7f_WSxpqqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    input=\"åäºŒå¼·ä¸–ç•Œæ£’çƒè³½å† è»æ˜¯å“ªä¸€éšŠï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"web_search_preview\",\n",
        "        # low, mediumï¼ˆdefaultï¼‰, high\n",
        "        \"search_context_size\": \"high\"\n",
        "    }],\n",
        ")\n",
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "kYMh1JyKnpsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_search_results(response)"
      ],
      "metadata": {
        "id": "wdSJyURPkAuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response.usage)"
      ],
      "metadata": {
        "id": "h_lFdJbfkEhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¸²æµæ–¹å¼ä½¿ç”¨å·¥å…·"
      ],
      "metadata": {
        "id": "j0w5Snxwrp7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-mini\",\n",
        "    input=\"åäºŒå¼·ä¸–ç•Œæ£’çƒè³½å† è»æ˜¯å“ªä¸€éšŠï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"web_search_preview\",\n",
        "    }],\n",
        "    stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "tvrPybq6BaqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in response:\n",
        "    pprint(chunk)"
      ],
      "metadata": {
        "id": "SjblfuphBjx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœå°‹çµæœåœ¨ type ç‚º response.output_text.annotation.added çš„äº‹ä»¶ä¸­"
      ],
      "metadata": {
        "id": "2p_RxOABnNii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-2 å¹«ç°¡æ˜“èŠå¤©ç¨‹å¼åŠ ä¸Šæœå°‹åŠŸèƒ½"
      ],
      "metadata": {
        "id": "LjVpLllJtmxi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è¨­è¨ˆè™•ç†æŒ‡ä»¤çš„é¡åˆ¥"
      ],
      "metadata": {
        "id": "nNQKASOyZ7Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseComand:\n",
        "    def __init__(self, command, tool_name, icon):\n",
        "        self.command = command      # æŒ‡ä»¤\n",
        "        self.tool_name = tool_name  # å·¥å…·åç¨±\n",
        "        self.icon = icon            # å·¥å…·åœ–ç¤ºå­—å…ƒ\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        # ä¸æ˜¯æ­£ç¢ºçš„æŒ‡ä»¤é–‹é ­ï¼ˆç©ºå­—ä¸²æœƒæ˜¯ Trueï¼‰\n",
        "        if not cmd.startswith(self.command):\n",
        "            return False\n",
        "        return True"
      ],
      "metadata": {
        "id": "2VUIpvRNZ_JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¿®æ”¹ Chat é¡åˆ¥"
      ],
      "metadata": {
        "id": "TDZw8XKYy4fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, **kwargs):\n",
        "        self._client = client\n",
        "        self._last_id = kwargs.pop('last_id', None)\n",
        "        self.tools = [] # é è¨­æ²’æœ‰ä½¿ç”¨å·¥å…·\n",
        "        self._commands = kwargs.pop('commands', [])\n",
        "\n",
        "    def find_tool_index(self, tool_type):\n",
        "        for i, tool in enumerate(self.tools):\n",
        "            if tool['type'] == tool_type: return i\n",
        "        return -1\n",
        "\n",
        "    def _get_prompt(self):\n",
        "        prompt = ''\n",
        "        for command in self._commands:\n",
        "            idx = self.find_tool_index(command.tool_name)\n",
        "            if idx != -1:\n",
        "                prompt += f'{command.icon}'\n",
        "        prompt = f'({prompt})>>> ' if prompt else '>>> '\n",
        "        return prompt\n",
        "\n",
        "    def _process_command(self, cmd):\n",
        "        for command in self._commands:\n",
        "            if command.handle_command(self, cmd):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', 'ä½¿ç”¨ç¹é«”ä¸­æ–‡')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=msg,\n",
        "                stream=True, # éƒ½ä»¥ä¸²æµæ–¹å¼è™•ç†ï¼Œç°¡åŒ–ç¨‹å¼é‚è¼¯\n",
        "                previous_response_id=self._last_id, # ä¸²æ¥å›æ‡‰\n",
        "                **kwargs\n",
        "            )\n",
        "            for event in response:\n",
        "                if event.type == 'response.output_text.delta':\n",
        "                    if stream: # ä¸²æµæ¨¡å¼ç”Ÿæˆç‰‡æ®µå…§å®¹\n",
        "                        yield event.delta\n",
        "                elif event.type == 'response.completed':\n",
        "                    self._last_id = event.response.id # è¨˜éŒ„è­˜åˆ¥ç¢¼\n",
        "                    if not stream: # éä¸²æµç”Ÿæˆå®Œæ•´å…§å®¹\n",
        "                        yield event.response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"ç›´æ¥æŒ‰ â†µ å¯çµæŸå°è©±\")\n",
        "        while True:\n",
        "            user_msg = input(self._get_prompt())\n",
        "            if not user_msg.strip(): break # ç›´æ¥ â†µ å°±çµæŸ\n",
        "            if self._process_command(user_msg):\n",
        "                continue # æŒ‡ä»¤ä¸éœ€å›è¦†ï¼Œå›é ­è®“ä½¿ç”¨è€…è¼¸å…¥\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(\n",
        "                user_msg,\n",
        "                tools=self.tools, # å‚³å…¥è¦ä½¿ç”¨çš„å·¥å…·\n",
        "                **kwargs\n",
        "            ):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(\n",
        "                {\n",
        "                    'last_id': self._last_id,\n",
        "                    'tools': self.tools,\n",
        "                    'commands': self._commands\n",
        "                },\n",
        "                f\n",
        "            )\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self._last_id = data['last_id']\n",
        "            self.tools = data['tools']\n",
        "            self._commands = data['commands']\n",
        "\n",
        "    def show_thread(self):\n",
        "        if not self._last_id: return\n",
        "        inputs = client.responses.input_items.list(self._last_id)\n",
        "        response = client.responses.retrieve(self._last_id)\n",
        "        for item in inputs.data[::-1]:\n",
        "            prompt = \">>> \" if item.role == 'user' else ''\n",
        "            for content in item.content:\n",
        "                print(f'{prompt}{content.text}')\n",
        "        print(response.output_text)\n",
        "\n",
        "    def delete_thread(self):\n",
        "        if not self._last_id: return\n",
        "        last_id = self._last_id\n",
        "        while last_id:\n",
        "            response = client.responses.retrieve(last_id)\n",
        "            last_id, curr_id = (\n",
        "                response.previous_response_id,\n",
        "                last_id\n",
        "            )\n",
        "            client.responses.delete(curr_id)\n",
        "        self._last_id = None"
      ],
      "metadata": {
        "id": "DaocavtKlc6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### å»ºç«‹è™•ç†å…§å»ºæœå°‹å·¥å…·æŒ‡ä»¤çš„é¡åˆ¥\n"
      ],
      "metadata": {
        "id": "Q9LcAjcfe0Hv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WebSearchCommand(BaseComand):\n",
        "    def __init__(self):\n",
        "        super().__init__(\n",
        "            '/w',\n",
        "            'web_search_preview',\n",
        "            'ğŸŒ'\n",
        "        )\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True"
      ],
      "metadata": {
        "id": "2ot8wM7nezYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat = Chat(client, commands=[WebSearchCommand()])\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True\n",
        ")\n",
        "chat.save('chat.pkl')"
      ],
      "metadata": {
        "id": "OKUCR1vSua34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1 = Chat(client)\n",
        "chat1.load('chat.pkl')\n",
        "chat1.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "WEYmlzDxVh8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat1.delete_thread()"
      ],
      "metadata": {
        "id": "yemUKpA7cMxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-3 ä½¿ç”¨å…§å»ºæª”æ¡ˆæª¢ç´¢ RAG å·¥å…·"
      ],
      "metadata": {
        "id": "M2tAoeHrvjBA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RAG ç°¡ä»‹"
      ],
      "metadata": {
        "id": "6v9F__DcNaQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¸Šå‚³æª”æ¡ˆé€²è¡Œ RAG"
      ],
      "metadata": {
        "id": "Yif6Dlv8NcDv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ã€Šå€‹äººè³‡æ–™ä¿è­·æ³•ã€‹ç¶²å€ï¼šhttps://reurl.cc/g6661X\n",
        "- ã€Šé€šè¨Šä¿éšœåŠç›£å¯Ÿæ³•ã€‹ç¶²å€ï¼šhttps://reurl.cc/5davLv"
      ],
      "metadata": {
        "id": "6DzIyNcDww77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä½¿ç”¨å…§å»ºçš„æª”æ¡ˆæª¢ç´¢å·¥å…·"
      ],
      "metadata": {
        "id": "qmukiUx3NlU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store_id = \"vs_68245fe8eff081919422d080954e2225\""
      ],
      "metadata": {
        "id": "SYk9l1yUEZLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"åœ¨ä¾¿åˆ©å•†åº—è¨˜ä¸‹é¡§å®¢å ±çš„æœƒå“¡é›»è©±è™Ÿç¢¼æ‰“çµ¦ä»–æœ‰çŠ¯æ³•å—ï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [vector_store_id]\n",
        "    }]\n",
        ")\n",
        "\n",
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "3xl1sXNxszve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response)"
      ],
      "metadata": {
        "id": "Uo_c-H84Bn-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=[\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': [\n",
        "                {\n",
        "                    'type': 'input_file',\n",
        "                    'file_id': \"file-WhDZWsm4T5T8PaWFdcPnvt\"\n",
        "                },\n",
        "                {\n",
        "                    'type': 'input_text',\n",
        "                    'text': 'åœ¨ä¾¿åˆ©å•†åº—è¨˜ä¸‹é¡§å®¢å ±çš„æœƒå“¡'\\\n",
        "                            'é›»è©±è™Ÿç¢¼æ‰“çµ¦ä»–æœ‰çŠ¯æ³•å—ï¼Ÿ'\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "\n",
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "JxpyaeSUyS8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response.usage)"
      ],
      "metadata": {
        "id": "Y8HCPEw_ygSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æŸ¥çœ‹æª¢ç´¢çµæœ"
      ],
      "metadata": {
        "id": "ddpPtbcio-Oz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"åœ¨ä¾¿åˆ©å•†åº—è¨˜ä¸‹é¡§å®¢å ±çš„æœƒå“¡é›»è©±è™Ÿç¢¼æ‰“çµ¦ä»–æœ‰çŠ¯æ³•å—ï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [vector_store_id],\n",
        "    }],\n",
        "    include=[\"file_search_call.results\"]\n",
        ")\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "DKRr_1N5vwd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_file_search_results(response):\n",
        "    if response.output[0].type != 'file_search_call': return\n",
        "    results = response.output[0].results\n",
        "    if not results: return # å«ç”¨ API æ™‚æ²’æœ‰æŒ‡å®š include åƒæ•¸\n",
        "    for i, result in enumerate(results, start=1):\n",
        "        display(Markdown('---'))\n",
        "        print(f'{i}. {result.filename}({result.score})')\n",
        "        display(Markdown('---'))\n",
        "        display(Markdown(result.text))\n",
        "\n",
        "show_file_search_results(response)"
      ],
      "metadata": {
        "id": "cd23DSxa2_HO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"åœ¨ä¾¿åˆ©å•†åº—è¨˜ä¸‹é¡§å®¢å ±çš„æœƒå“¡é›»è©±è™Ÿç¢¼æ‰“çµ¦ä»–æœ‰çŠ¯æ³•å—ï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [vector_store_id],\n",
        "    }],\n",
        "    include=[\"file_search_call.results\"],\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for event in response:\n",
        "    pprint(event)"
      ],
      "metadata": {
        "id": "3xHSEInC2iaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### é™åˆ¶æª¢ç´¢ç­†æ•¸"
      ],
      "metadata": {
        "id": "kxm48D9XpSq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"åœ¨ä¾¿åˆ©å•†åº—è¨˜ä¸‹é¡§å®¢å ±çš„æœƒå“¡é›»è©±è™Ÿç¢¼æ‰“çµ¦ä»–æœ‰çŠ¯æ³•å—ï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [vector_store_id],\n",
        "        \"max_num_results\": 3\n",
        "    }],\n",
        "    include=[\"file_search_call.results\"]\n",
        ")\n",
        "\n",
        "show_file_search_results(response)"
      ],
      "metadata": {
        "id": "3--_xTVA5BDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.output_text))"
      ],
      "metadata": {
        "id": "H7BajFV6C8Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response.usage)"
      ],
      "metadata": {
        "id": "ZjWk0OyKMFLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### é™åˆ¶ç›¸ä¼¼åº¦"
      ],
      "metadata": {
        "id": "zUA2596DpfIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"åœ¨ä¾¿åˆ©å•†åº—è¨˜ä¸‹é¡§å®¢å ±çš„æœƒå“¡é›»è©±è™Ÿç¢¼æ‰“çµ¦ä»–æœ‰çŠ¯æ³•å—ï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [vector_store_id],\n",
        "        \"ranking_options\": {\n",
        "            \"score_threshold\": 0.5\n",
        "        }\n",
        "    }],\n",
        "    include=[\"file_search_call.results\"]\n",
        ")\n",
        "\n",
        "for result in response.output[0].results:\n",
        "    print(result.score)"
      ],
      "metadata": {
        "id": "qs6-RdySOFi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_file_search_results(response)"
      ],
      "metadata": {
        "id": "R5tuRmRBbbLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æª”æ¡ˆæª¢ç´¢å·¥å…·çš„è¨ˆè²»æ–¹å¼"
      ],
      "metadata": {
        "id": "9IjuYcC6Qf4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-4 åˆ©ç”¨ç¨‹å¼ç¢¼å‹•æ…‹ç®¡ç†è¦æª¢ç´¢çš„æª”æ¡ˆ"
      ],
      "metadata": {
        "id": "4yjCz4ynQixk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ç„¡ç·šéµç›¤ä½¿ç”¨æ‰‹å†Š\n",
        "file1_url = \"https://coolermaster.egnyte.com/dd/4pPb6Srybx/\"\n",
        "# é›»ç«¶è€³æ©Ÿä½¿ç”¨æ‰‹å†Š\n",
        "file2_url = \"https://coolermaster.egnyte.com/dd/BtL7gG2IW6/\""
      ],
      "metadata": {
        "id": "3cp9h7YCREK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Files API è£¡é¢ file åƒæ•¸å¯ä»¥æ˜¯å­—ä¸²ã€ä½å…ƒçµ„åºçµ„ã€æˆ–æ˜¯é–‹å•Ÿæª”æ¡ˆå¾—åˆ°çš„ç‰©ä»¶ï¼Œä½ å¯ä»¥ç”¨ BytesIO ä¾†æ¨¡æ“¬æª”æ¡ˆç‰©ä»¶ï¼Œé€™æ¨£åšçš„å¥½è™•å°±æ˜¯å¯ä»¥åŠ ä¸Šæª”åï¼Œåƒæ˜¯ï¼š\n",
        "\n",
        "```python\n",
        "file = BytesIO(response.content)\n",
        "file.name = fialename\n",
        "```\n",
        "\n",
        "Files API æä¾›ä¸€å€‹ç°¡ä¾¿çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¯ä»¥ç”¨ (æª”åï¼Œæª”æ¡ˆå…§å®¹) è‡ªå‹•å¹«ä½ å»ºç«‹ BytesIO ç‰©ä»¶ã€‚\n"
      ],
      "metadata": {
        "id": "zRKporoZhF4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### å‹•æ…‹ä¸Šå‚³æª”æ¡ˆ"
      ],
      "metadata": {
        "id": "qWcInLIyrz9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from io import BytesIO\n",
        "\n",
        "def upload_file(file_path):\n",
        "    try:\n",
        "        if (file_path.startswith('http://')\n",
        "            or file_path.startswith('https://')):\n",
        "            response = requests.get(file_path)\n",
        "            filename = response.headers.get(\n",
        "                'content-disposition',\n",
        "                None\n",
        "            )\n",
        "            if filename:\n",
        "                filename = filename.split('filename=')[-1]\n",
        "                filename = filename.strip('\\'\"')\n",
        "            else:\n",
        "                filename = file_path.split('/')[-1]\n",
        "            response = client.files.create(\n",
        "                file=(filename, response.content),\n",
        "                purpose='user_data'\n",
        "            )\n",
        "        else:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                response = client.files.create(\n",
        "                    file=file,\n",
        "                    purpose='user_data'\n",
        "                )\n",
        "    except:\n",
        "        return None\n",
        "    return response.id"
      ],
      "metadata": {
        "id": "FBdtALv4DAyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file1_id = upload_file(file1_url)\n",
        "print(file1_id)"
      ],
      "metadata": {
        "id": "DunzLalkNikE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### å»ºç«‹å‘é‡å„²å­˜å€åŒæ™‚åŠ å…¥æª”æ¡ˆ"
      ],
      "metadata": {
        "id": "VnfU-UDJruOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = client.vector_stores.create(\n",
        "    name=\"é›»è…¦å°ˆå®¶\",\n",
        "    file_ids=[file1_id],\n",
        "    chunking_strategy={\n",
        "        'type': 'static', # é è¨­æ˜¯ 'auto'\n",
        "        'static': {\n",
        "            'chunk_overlap_tokens': 400,\n",
        "            'max_chunk_size_tokens': 800\n",
        "        }\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "yrM0AFYyLCCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vector_store.id)"
      ],
      "metadata": {
        "id": "gD6K9GoZLD3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"æˆ‘çš„éµç›¤è¦å¦‚ä½•é€éè—ç‰™é€£ç·šï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [vector_store.id],\n",
        "        \"max_num_results\": 3\n",
        "    }],\n",
        "    include=[\"file_search_call.results\"]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "PTtNsOWoN7Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### å‹•æ…‹åŠ å…¥æª”æ¡ˆåˆ°å‘é‡è³‡æ–™åº«"
      ],
      "metadata": {
        "id": "zXGXNfhjrhwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client.vector_stores.files.create(\n",
        "    vector_store_id=vector_store.id,\n",
        "    file_id=upload_file(file2_url)\n",
        ")"
      ],
      "metadata": {
        "id": "IklCMGLMjBGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model=\"gpt-4.1-nano\",\n",
        "    input=\"æˆ‘è€³æ©Ÿä¸Šçš„éº¥å…‹é¢¨å¯ä»¥æ‹†æ‰å—ï¼Ÿ\",\n",
        "    tools=[{\n",
        "        \"type\": \"file_search\",\n",
        "        \"vector_store_ids\": [vector_store.id],\n",
        "        \"max_num_results\": 3\n",
        "    }],\n",
        "    include=[\"file_search_call.results\"]\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "x4_EAdYeq2Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### é¡¯ç¤ºå‘é‡è³‡æ–™åº«å…§çš„æª”æ¡ˆ"
      ],
      "metadata": {
        "id": "kpb7UmJSqtjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.vector_stores.files.list(vector_store.id)\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "Idc9W-nXFr5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, vector_file in enumerate(response.data):\n",
        "    file = client.files.retrieve(vector_file.id)\n",
        "    print(f'{i + 1}:{file.filename}')\n",
        "    print(f'  {vector_file.id}')"
      ],
      "metadata": {
        "id": "6rylKAo2Hcen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ç§»é™¤å‘é‡å„²å­˜å€"
      ],
      "metadata": {
        "id": "tKbLlJr2qigS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_vector_store(vector_store_id):\n",
        "    response = client.vector_stores.files.list(vector_store_id)\n",
        "    for vector_file in response.data:\n",
        "        client.files.delete(vector_file.id)\n",
        "    client.vector_stores.delete(vector_store_id)"
      ],
      "metadata": {
        "id": "dvWvgaeuHrb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_vector_store(vector_store.id)"
      ],
      "metadata": {
        "id": "cduzDi5YlIHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-5 å¹«ç°¡æ˜“èŠå¤©ç¨‹å¼åŠ ä¸Šæª”æ¡ˆæª¢ç´¢åŠŸèƒ½"
      ],
      "metadata": {
        "id": "ag5kqGmenLGK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è¨­è¨ˆè™•ç†æª”æ¡ˆæª¢ç´¢æŒ‡ä»¤çš„é¡åˆ¥"
      ],
      "metadata": {
        "id": "vrBtERN72zlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FileSearchCommand(BaseComand):\n",
        "    def __init__(self, vector_store_id=None):\n",
        "        super().__init__(\n",
        "            '/f',\n",
        "            'file_search',\n",
        "            'ğŸ”'\n",
        "        )\n",
        "        self.vector_store_id = vector_store_id\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if len(cmd) < 4: # /f[.]ï¼Œä¸æ˜¯å†’è™ŸåŠ æª”å/ç¶²å€\n",
        "            if self.vector_store_id == None:\n",
        "                print('è«‹å…ˆä½¿ç”¨ /f:[è·¯å¾‘|ç¶²å€]ä¸Šå‚³æª”æ¡ˆ')\n",
        "                return True # æ²’æœ‰å‘é‡è³‡æ–™åº«ç„¡æ³•åˆ‡æ›\n",
        "            turn_on = (idx == -1) # åˆ‡æ›é–‹/é—œæª”æ¡ˆæª¢ç´¢\n",
        "        else: # /f:æª”å|ç¶²å€ï¼Œä¸Šå‚³æª”æ¡ˆä¸¦é–‹å•Ÿæª¢ç´¢åŠŸèƒ½\n",
        "            turn_on = True\n",
        "            file_path = cmd[3:]\n",
        "            file_id= upload_file(file_path)\n",
        "            if not file_id:\n",
        "                print(f'ç„¡æ³•ä¸Šå‚³æª”æ¡ˆï¼š{file_path}')\n",
        "                return True\n",
        "            if self.vector_store_id == None:\n",
        "                vector_store = client.vector_stores.create(\n",
        "                    name=\"temp\",\n",
        "                    file_ids=[file_id],\n",
        "                )\n",
        "                self.vector_store_id = vector_store.id\n",
        "            else:\n",
        "                client.vector_stores.files.create(\n",
        "                    self.vector_store_id,\n",
        "                    file_id=file_id\n",
        "                )\n",
        "        if turn_on:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'vector_store_ids': [self.vector_store_id]\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True\n",
        "\n",
        "    def remove_vector_store(self, chat):\n",
        "        if self.vector_store_id == None: return\n",
        "        idx = chat.find_tool_index('file_search')\n",
        "        if idx: chat.tools.pop(idx)\n",
        "        response = client.vector_stores.files.list(\n",
        "            self.vector_store_id\n",
        "        )\n",
        "        for vector_file in response.data:\n",
        "            client.files.delete(vector_file.id)\n",
        "        client.vector_stores.delete(self.vector_store_id)"
      ],
      "metadata": {
        "id": "Znd5ev4v3DZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ¸¬è©¦å…·å‚™ç¶²é æœå°‹èˆ‡æª”æ¡ˆæª¢ç´¢åŠŸèƒ½çš„èŠå¤©ç¨‹å¼"
      ],
      "metadata": {
        "id": "HOC36VBXz6GJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ç„¡ç·šéµç›¤ä½¿ç”¨æ‰‹å†Šï¼š\n",
        "    https://coolermaster.egnyte.com/dd/4pPb6Srybx/\n",
        "- é›»ç«¶è€³æ©Ÿä½¿ç”¨æ‰‹å†Šï¼š\n",
        "    https://coolermaster.egnyte.com/dd/BtL7gG2IW6/"
      ],
      "metadata": {
        "id": "Rjd4HxcqSa9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "å¤šå·¥å…·æƒ…æ³ä¸‹ï¼Œéƒ½æœƒæœ‰åé‡æª¢ç´¢æª”æ¡ˆçš„å‚¾å‘ï¼Œä½†æ˜¯gpt-4.1-mini æ˜é¡¯æ¯” gpt-4o-mini å¥½ä¸€äº›ï¼Œgpt-4.1 ä¼¼ä¹ä¹Ÿæ²’æœ‰æ¯”è¼ƒå²å®³ï¼š"
      ],
      "metadata": {
        "id": "IT6aTl03XRH_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_search_comand = FileSearchCommand()\n",
        "\n",
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[\n",
        "        file_search_comand,\n",
        "        WebSearchCommand()\n",
        "    ],\n",
        ")\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True\n",
        ")\n",
        "chat.save('test.db')"
      ],
      "metadata": {
        "id": "Vb3MmqkQX37G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat2 = Chat(client)\n",
        "chat2.load('test.db')\n",
        "chat2.tools"
      ],
      "metadata": {
        "id": "EAcgk1qpWwab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat2.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True\n",
        ")"
      ],
      "metadata": {
        "id": "BJ3mmoNdba0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_search_comand.remove_vector_store(chat2)"
      ],
      "metadata": {
        "id": "d2Fbc_FNbg42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### åŠ ä¸Šå¯ä»¥æª¢è¦–å·¥å…·åŸ·è¡Œçµæœçš„åŠŸèƒ½"
      ],
      "metadata": {
        "id": "dTAC8jYk_UDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseComand:\n",
        "    def __init__(self, command, tool_name, icon, verbose=False):\n",
        "        self.command = command      # æŒ‡ä»¤\n",
        "        self.tool_name = tool_name  # å·¥å…·åç¨±\n",
        "        self.icon = icon            # å·¥å…·åœ–ç¤ºå­—å…ƒ\n",
        "        self.verbose = verbose      # å•Ÿç”¨è©³ç´°è¼¸å‡º\n",
        "        self.extra_args = {}        # è¦é¡å¤–é€çµ¦æ¨¡å‹çš„åƒæ•¸\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        # ä¸æ˜¯æ­£ç¢ºçš„æŒ‡ä»¤é–‹é ­ï¼ˆç©ºå­—ä¸²æœƒæ˜¯ Trueï¼‰\n",
        "        if not cmd.startswith(self.command):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        return None # é è¨­ä¸è™•ç†äº¤çµ¦ä¸‹ä¸€å€‹æŒ‡ä»¤è™•ç†å™¨"
      ],
      "metadata": {
        "id": "-mDRSmw6_vly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class WebSearchCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/w',\n",
        "            'web_search_preview',\n",
        "            'ğŸŒ',\n",
        "            verbose\n",
        "        )\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True\n",
        "\n",
        "    def show_search_results(self, response):\n",
        "        if response.output[0].type != \"web_search_call\":\n",
        "            return\n",
        "        content = response.output[1].content[0]\n",
        "        for i, annotaion in enumerate(\n",
        "            content.annotations, start=1\n",
        "        ):\n",
        "            print(f'{i}. {annotaion.title}')\n",
        "            print(f'   {unquote(annotaion.url)}')\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "JgXxEfcoAOWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FileSearchCommand(BaseComand):\n",
        "    def __init__(self, vector_store_id=None, verbose=False):\n",
        "        super().__init__(\n",
        "            '/f',\n",
        "            'file_search',\n",
        "            'ğŸ”',\n",
        "            verbose\n",
        "        )\n",
        "        self.vector_store_id = vector_store_id\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if len(cmd) < 4: # /f[.]ï¼Œä¸æ˜¯å†’è™ŸåŠ æª”å/ç¶²å€\n",
        "            if self.vector_store_id == None:\n",
        "                print('è«‹å…ˆä½¿ç”¨ /f:[è·¯å¾‘|ç¶²å€]ä¸Šå‚³æª”æ¡ˆ')\n",
        "                return True # æ²’æœ‰å‘é‡è³‡æ–™åº«ç„¡æ³•åˆ‡æ›\n",
        "            turn_on = (idx == -1) # åˆ‡æ›é–‹/é—œæª”æ¡ˆæª¢ç´¢\n",
        "        else: # /f:æª”å|ç¶²å€ï¼Œä¸Šå‚³æª”æ¡ˆä¸¦é–‹å•Ÿæª¢ç´¢åŠŸèƒ½\n",
        "            turn_on = True\n",
        "            file_path = cmd[3:]\n",
        "            file_id= upload_file(file_path)\n",
        "            if not file_id:\n",
        "                print(f'ç„¡æ³•ä¸Šå‚³æª”æ¡ˆï¼š{file_path}')\n",
        "                return True\n",
        "            if self.vector_store_id == None:\n",
        "                vector_store = client.vector_stores.create(\n",
        "                    name=\"temp\",\n",
        "                    file_ids=[file_id],\n",
        "                )\n",
        "                self.vector_store_id = vector_store.id\n",
        "            else:\n",
        "                client.vector_stores.files.create(\n",
        "                    self.vector_store_id,\n",
        "                    file_id=file_id\n",
        "                )\n",
        "        if turn_on:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'vector_store_ids': [self.vector_store_id]\n",
        "            })\n",
        "            self.extra_args = {\n",
        "                'include': ['file_search_call.results']\n",
        "            }\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "            self.extra_args = {}\n",
        "        return True\n",
        "\n",
        "    def remove_vector_store(self, chat):\n",
        "        if self.vector_store_id == None: return\n",
        "        idx = chat.find_tool_index('file_search')\n",
        "        if idx: chat.tools.pop(idx)\n",
        "        response = client.vector_stores.files.list(\n",
        "            self.vector_store_id\n",
        "        )\n",
        "        for vector_file in response.data:\n",
        "            client.files.delete(vector_file.id)\n",
        "        client.vector_stores.delete(self.vector_store_id)\n",
        "\n",
        "    def show_file_search_results(self, response):\n",
        "        if response.output[0].type != 'file_search_call':\n",
        "            return\n",
        "        results = response.output[0].results\n",
        "        if not results: return\n",
        "        for i, result in enumerate(results, start=1):\n",
        "            display(Markdown('---'))\n",
        "            print(f'{i}. {result.filename}({result.score})')\n",
        "            display(Markdown('---'))\n",
        "            display(Markdown(result.text))\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_file_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "MB5meaUaBdK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, **kwargs):\n",
        "        self._client = client\n",
        "        self._last_id = kwargs.pop('last_id', None)\n",
        "        self.tools = [] # é è¨­æ²’æœ‰ä½¿ç”¨å·¥å…·\n",
        "        self._commands = kwargs.pop('commands', [])\n",
        "\n",
        "    def find_tool_index(self, tool_type):\n",
        "        for i, tool in enumerate(self.tools):\n",
        "            if tool['type'] == tool_type: return i\n",
        "        return -1\n",
        "\n",
        "    def _get_prompt(self):\n",
        "        prompt = ''\n",
        "        for command in self._commands:\n",
        "            idx = self.find_tool_index(command.tool_name)\n",
        "            if idx != -1:\n",
        "                prompt += f'{command.icon}'\n",
        "        prompt = f'({prompt})>>> ' if prompt else '>>> '\n",
        "        return prompt\n",
        "\n",
        "    def _process_command(self, cmd):\n",
        "        for command in self._commands:\n",
        "            if command.handle_command(self, cmd):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', 'ä½¿ç”¨ç¹é«”ä¸­æ–‡')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        for command in self._commands:\n",
        "            kwargs.update(command.extra_args)\n",
        "        try:\n",
        "            response = self._client.responses.create(\n",
        "                instructions=instructions,\n",
        "                model=model,\n",
        "                input=msg,\n",
        "                stream=True, # éƒ½ä»¥ä¸²æµæ–¹å¼è™•ç†ï¼Œç°¡åŒ–ç¨‹å¼é‚è¼¯\n",
        "                previous_response_id=self._last_id, # ä¸²æ¥å›æ‡‰\n",
        "                **kwargs\n",
        "            )\n",
        "            for event in response:\n",
        "                for command in self._commands:\n",
        "                    result = command.handle_event(\n",
        "                        self, stream, event\n",
        "                    )\n",
        "                    if result: break\n",
        "                if event.type == 'response.output_text.delta':\n",
        "                    if stream: # ä¸²æµæ¨¡å¼ç”Ÿæˆç‰‡æ®µå…§å®¹\n",
        "                        yield event.delta\n",
        "                elif event.type == 'response.completed':\n",
        "                    self._last_id = event.response.id # è¨˜éŒ„è­˜åˆ¥ç¢¼\n",
        "                    if not stream: # éä¸²æµç”Ÿæˆå®Œæ•´å…§å®¹\n",
        "                        yield event.response.output_text\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"ç›´æ¥æŒ‰ â†µ å¯çµæŸå°è©±\")\n",
        "        while True:\n",
        "            user_msg = input(self._get_prompt())\n",
        "            if not user_msg.strip(): break # ç›´æ¥ â†µ å°±çµæŸ\n",
        "            if self._process_command(user_msg):\n",
        "                continue # æŒ‡ä»¤ä¸éœ€å›è¦†ï¼Œå›é ­è®“ä½¿ç”¨è€…è¼¸å…¥\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            for reply in self.get_reply_text(\n",
        "                user_msg,\n",
        "                tools=self.tools, # å‚³å…¥è¦ä½¿ç”¨çš„å·¥å…·\n",
        "                **kwargs\n",
        "            ):\n",
        "                text += reply\n",
        "                display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(\n",
        "                {\n",
        "                    'last_id': self._last_id,\n",
        "                    'tools': self.tools,\n",
        "                    'commands': self._commands\n",
        "                },\n",
        "                f\n",
        "            )\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self._last_id = data['last_id']\n",
        "            self.tools = data['tools']\n",
        "            self._commands = data['commands']\n",
        "\n",
        "    def show_thread(self):\n",
        "        if not self._last_id: return\n",
        "        inputs = client.responses.input_items.list(self._last_id)\n",
        "        response = client.responses.retrieve(self._last_id)\n",
        "        for item in inputs.data[::-1]:\n",
        "            prompt = \">>> \" if item.role == 'user' else ''\n",
        "            for content in item.content:\n",
        "                print(f'{prompt}{content.text}')\n",
        "        print(response.output_text)\n",
        "\n",
        "    def delete_thread(self):\n",
        "        if not self._last_id: return\n",
        "        last_id = self._last_id\n",
        "        while last_id:\n",
        "            response = client.responses.retrieve(last_id)\n",
        "            last_id, curr_id = (\n",
        "                response.previous_response_id,\n",
        "                last_id\n",
        "            )\n",
        "            client.responses.delete(curr_id)\n",
        "        self._last_id = None"
      ],
      "metadata": {
        "id": "q5SOj1KJFr6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_search_comand = FileSearchCommand(verbose=False)\n",
        "\n",
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[\n",
        "        file_search_comand,\n",
        "        WebSearchCommand(verbose=True)\n",
        "    ]\n",
        ")\n",
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        ")"
      ],
      "metadata": {
        "id": "cCsVV2w-8O0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.delete_thread()\n",
        "file_search_comand.remove_vector_store(chat)"
      ],
      "metadata": {
        "id": "w0c0BCsn8hph"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}