{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgttHM1PIMSk"
      },
      "source": [
        "# ç¬¬ 6 ç«  æœƒå¯«ç¨‹å¼èˆ‡ç”Ÿåœ–çš„å…§å»ºå·¥å…·"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-RlMrECIQac"
      },
      "source": [
        "## å‰ç½®å·¥ä½œ\n",
        "\n",
        "è«‹å…ˆåŸ·è¡Œä»¥ä¸‹é€™å¹¾å€‹å„²å­˜æ ¼ï¼Œä¾¿æ–¼å¾ŒçºŒæ¸¬è©¦ï¼š"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38jBEPsRaWH2"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "from rich.pretty import pprint\n",
        "from pydantic import BaseModel, Field, ConfigDict\n",
        "from io import BytesIO\n",
        "import requests\n",
        "import openai\n",
        "import sys\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoDsvbeBaqaL"
      },
      "outputs": [],
      "source": [
        "client = openai.OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvi9uaZR9iJd"
      },
      "outputs": [],
      "source": [
        "def upload_file(file_path):\n",
        "    try:\n",
        "        if (file_path.startswith('http://')\n",
        "            or file_path.startswith('https://')):\n",
        "            response = requests.get(file_path)\n",
        "            filename = response.headers.get(\n",
        "                'content-disposition',\n",
        "                None\n",
        "            )\n",
        "            if filename:\n",
        "                filename = filename.split('filename=')[-1]\n",
        "                filename = filename.strip('\\'\"')\n",
        "            else:\n",
        "                filename = file_path.split('/')[-1]\n",
        "            response = client.files.create(\n",
        "                file=(filename, response.content),\n",
        "                purpose='user_data'\n",
        "            )\n",
        "        else:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                response = client.files.create(\n",
        "                    file=file,\n",
        "                    purpose='user_data'\n",
        "                )\n",
        "    except:\n",
        "        return None\n",
        "    return response.id"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseComand:\n",
        "    def __init__(self, command, tool_name, icon, verbose=False):\n",
        "        self.command = command      # æŒ‡ä»¤\n",
        "        self.tool_name = tool_name  # å·¥å…·åç¨±\n",
        "        self.icon = icon            # å·¥å…·åœ–ç¤ºå­—å…ƒ\n",
        "        self.verbose = verbose      # å•Ÿç”¨è©³ç´°è¼¸å‡º\n",
        "        self.extra_args = {}        # è¦é¡å¤–é€çµ¦æ¨¡å‹çš„åƒæ•¸\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        # ä¸æ˜¯æ­£ç¢ºçš„æŒ‡ä»¤é–‹é ­ï¼ˆç©ºå­—ä¸²æœƒæ˜¯ Trueï¼‰\n",
        "        if not cmd.startswith(self.command):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        return None # é è¨­ä¸è™•ç†äº¤çµ¦ä¸‹ä¸€å€‹æŒ‡ä»¤è™•ç†å™¨"
      ],
      "metadata": {
        "id": "-mDRSmw6_vly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import unquote\n",
        "\n",
        "class WebSearchCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/w',\n",
        "            'web_search_preview',\n",
        "            'ğŸŒ',\n",
        "            verbose\n",
        "        )\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True\n",
        "\n",
        "    def show_search_results(self, response):\n",
        "        if response.output[0].type != \"web_search_call\":\n",
        "            return\n",
        "        content = response.output[1].content[0]\n",
        "        for i, annotaion in enumerate(\n",
        "            content.annotations, start=1\n",
        "        ):\n",
        "            print(f'{i}. {annotaion.title}')\n",
        "            print(f'   {unquote(annotaion.url)}')\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "JgXxEfcoAOWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FileSearchCommand(BaseComand):\n",
        "    def __init__(self, vector_store_id=None, verbose=False):\n",
        "        super().__init__(\n",
        "            '/f',\n",
        "            'file_search',\n",
        "            'ğŸ”',\n",
        "            verbose\n",
        "        )\n",
        "        self.vector_store_id = vector_store_id\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if len(cmd) < 4: # /f[.]ï¼Œä¸æ˜¯å†’è™ŸåŠ æª”å/ç¶²å€\n",
        "            if self.vector_store_id == None:\n",
        "                print('è«‹å…ˆä½¿ç”¨ /f:[è·¯å¾‘|ç¶²å€]ä¸Šå‚³æª”æ¡ˆ')\n",
        "                return True # æ²’æœ‰å‘é‡è³‡æ–™åº«ç„¡æ³•åˆ‡æ›\n",
        "            turn_on = (idx == -1) # åˆ‡æ›é–‹/é—œæª”æ¡ˆæª¢ç´¢\n",
        "        else: # /f:æª”å|ç¶²å€ï¼Œä¸Šå‚³æª”æ¡ˆä¸¦é–‹å•Ÿæª¢ç´¢åŠŸèƒ½\n",
        "            turn_on = True\n",
        "            file_path = cmd[3:]\n",
        "            file_id= upload_file(file_path)\n",
        "            if not file_id:\n",
        "                print(f'ç„¡æ³•ä¸Šå‚³æª”æ¡ˆï¼š{file_path}')\n",
        "                return True\n",
        "            if self.vector_store_id == None:\n",
        "                vector_store = client.vector_stores.create(\n",
        "                    name=\"temp\",\n",
        "                    file_ids=[file_id],\n",
        "                )\n",
        "                self.vector_store_id = vector_store.id\n",
        "            else:\n",
        "                client.vector_stores.files.create(\n",
        "                    self.vector_store_id,\n",
        "                    file_id=file_id\n",
        "                )\n",
        "        if turn_on:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'vector_store_ids': [self.vector_store_id]\n",
        "            })\n",
        "            self.extra_args = {\n",
        "                'include': ['file_search_call.results']\n",
        "            }\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "            self.extra_args = {}\n",
        "        return True\n",
        "\n",
        "    def remove_vector_store(self, chat):\n",
        "        if self.vector_store_id == None: return\n",
        "        idx = chat.find_tool_index('file_search')\n",
        "        if idx: chat.tools.pop(idx)\n",
        "        response = client.vector_stores.files.list(\n",
        "            self.vector_store_id\n",
        "        )\n",
        "        for vector_file in response.data:\n",
        "            client.files.delete(vector_file.id)\n",
        "        client.vector_stores.delete(self.vector_store_id)\n",
        "\n",
        "    def show_file_search_results(self, response):\n",
        "        if response.output[0].type != 'file_search_call':\n",
        "            return\n",
        "        results = response.output[0].results\n",
        "        if not results: return\n",
        "        for i, result in enumerate(results, start=1):\n",
        "            display(Markdown('---'))\n",
        "            print(f'{i}. {result.filename}({result.score})')\n",
        "            display(Markdown('---'))\n",
        "            display(Markdown(result.text))\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.verbose: return None\n",
        "        if event.type == 'response.completed':\n",
        "            self.show_file_search_results(event.response)\n",
        "        return None"
      ],
      "metadata": {
        "id": "MB5meaUaBdK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FunctionCallingCommand(BaseComand):\n",
        "    def __init__(self, tools=None, verbose=False):\n",
        "        super().__init__(\n",
        "            '/t',\n",
        "            'function',\n",
        "            '',\n",
        "            verbose\n",
        "        )\n",
        "        self.tools = tools or []\n",
        "        self.enabled = False\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        if not self.enabled: # åŠ å…¥è‡ªè¨‚å‡½å¼å·¥å…·\n",
        "            chat.tools.extend(self.tools)\n",
        "        else: # ç§»é™¤è‡ªè¨‚å·¥å…·å‡½å¼\n",
        "            chat.tools = [\n",
        "                tool for tool in chat.tools\n",
        "                if tool['type'] != self.tool_name\n",
        "            ]\n",
        "        self.enabled = not self.enabled\n",
        "        return True\n",
        "\n",
        "    # å«ç”¨å–®ä¸€å‡½å¼ä¸¦ä¸”å°‡å‡½å¼åŸ·è¡Œçµæœçµ„æˆè¨Šæ¯å¾Œå‚³å›\n",
        "    def make_tool_msg(self, tool_call):\n",
        "        tool_info = f'{tool_call.name}(**{tool_call.arguments})'\n",
        "        if self.verbose: print(f'å«ç”¨ï¼š{tool_info}')\n",
        "        func = eval(tool_call.name)\n",
        "        args = json.loads(tool_call.arguments)\n",
        "        result = func(**args)\n",
        "        return {   # å»ºç«‹å¯å‚³å›å‡½å¼åŸ·è¡Œçµæœçš„å­—å…¸\n",
        "            \"type\": \"function_call_output\", # ä»¥å·¥å…·è§’è‰²é€å‡ºå›è¦†\n",
        "            \"call_id\": tool_call.call_id, # å«ç”¨å‡½å¼çš„è­˜åˆ¥ç¢¼\n",
        "            \"output\": result # å‡½å¼å‚³å›å€¼\n",
        "        }\n",
        "\n",
        "    def call_tools(self, tool_calls):\n",
        "        msgs = []\n",
        "        for tool_call in tool_calls:\n",
        "            if tool_call.type == 'function_call':\n",
        "                msgs.append(self.make_tool_msg(tool_call))\n",
        "        return msgs if msgs else None\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if not self.enabled: return None\n",
        "        if event.type != 'response.completed':\n",
        "            return None\n",
        "        # å‘¼å«å‡½å¼\n",
        "        tool_calls = event.response.output\n",
        "        tool_results = self.call_tools(tool_calls)\n",
        "        if tool_results: return tool_calls + tool_results\n",
        "        return None"
      ],
      "metadata": {
        "id": "VkuullTVAAG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def shell_helper(comment, shell_command):\n",
        "    # å•Ÿå‹•å­è¡Œç¨‹\n",
        "    process = subprocess.Popen(\n",
        "        shell_command,\n",
        "        shell=True,             # åœ¨ shell ä¸­åŸ·è¡Œ\n",
        "        stdout=subprocess.PIPE, # æ“·å–æ¨™æº–è¼¸å‡º\n",
        "        stderr=subprocess.PIPE, # æ“·å–éŒ¯èª¤è¼¸å‡º\n",
        "        text=True               # ä»¥æ–‡å­—å½¢å¼è¿”å›\n",
        "    )\n",
        "\n",
        "    result = 'åŸ·è¡Œçµæœï¼š\\n\\n```\\n'\n",
        "\n",
        "    # å³æ™‚è®€å–è¼¸å‡º\n",
        "    while True:\n",
        "        output = process.stdout.readline()\n",
        "        # å¦‚æœæ²’æœ‰è¼¸å‡ºä¸”è¡Œç¨‹çµæŸ\n",
        "        if output == '' and process.poll() is not None:\n",
        "            break\n",
        "        if output:\n",
        "            result += output\n",
        "\n",
        "    result += \"```\"\n",
        "\n",
        "    # æª¢æŸ¥éŒ¯èª¤è¼¸å‡º\n",
        "    error = process.stderr.read()\n",
        "    if error:\n",
        "        result += f\"\\n\\néŒ¯èª¤: {error}\"\n",
        "\n",
        "    # ç­‰å¾…è¡Œç¨‹çµæŸä¸¦å–å¾—è¿”å›ç¢¼\n",
        "    return_code = process.wait()\n",
        "    result += f\"\\n\\nå‘½ä»¤åŸ·è¡Œå®Œæˆï¼Œè¿”å›ç¢¼: {return_code}\\n\\n\"\n",
        "    return result"
      ],
      "metadata": {
        "id": "jEuSaHvKQSxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ShellHelper(BaseModel):\n",
        "    comment: str = Field(\n",
        "        description='åˆ¤æ–·è¦åŸ·è¡ŒæŒ‡å®šçš„ shell æŒ‡ä»¤çš„åŸå› '\n",
        "    )\n",
        "    shell_command: str = Field(\n",
        "        description='è¦åŸ·è¡Œçš„ shell æŒ‡ä»¤'\n",
        "    )"
      ],
      "metadata": {
        "id": "lCrbkSLbQWTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shell_helper_tool = {\n",
        "    'type': 'function',\n",
        "    \"name\": \"shell_helper\",\n",
        "    \"description\": \"æˆ‘å¯ä»¥åŸ·è¡Œ shell æŒ‡ä»¤æ“æ§é›»è…¦\",\n",
        "    \"parameters\": ShellHelper.model_json_schema(),\n",
        "}"
      ],
      "metadata": {
        "id": "EeupCaumQYh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-1 ä½¿ç”¨å…§å»ºå·¥å…·åŸ·è¡Œ shell æŒ‡ä»¤"
      ],
      "metadata": {
        "id": "Au4pknJHaHbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='codex-mini-latest',\n",
        "    tools=[{'type': 'local_shell'}],\n",
        "    instructions='ä½¿ç”¨ç¹é«”ä¸­æ–‡',\n",
        "    input= 'æˆ‘åœ¨å“ªå€‹è·¯å¾‘ä¸‹'\n",
        ")\n",
        "\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "AzTuyVUSV_CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for output in response.output:\n",
        "    if output.type != 'local_shell_call':\n",
        "        continue\n",
        "    action = output.action\n",
        "    call_id = output.call_id"
      ],
      "metadata": {
        "id": "JKLubwLiYnZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "result = subprocess.run(\n",
        "    action.command,\n",
        "    capture_output=True\n",
        ")"
      ],
      "metadata": {
        "id": "JM3pHUKBZAbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_md = (\n",
        "    f'åŸ·è¡Œçµæœ\\n\\n```\\n'\n",
        "    f'{result.stdout.decode(\"utf8\")}\\n'\n",
        "    f'```\\n\\néŒ¯èª¤è¨Šæ¯\\n\\n```\\n'\n",
        "    f'{result.stderr.decode(\"utf8\")}\\n'\n",
        "    f'```\\n\\nçµæŸç¢¼ï¼š{result.returncode}'\n",
        ")\n",
        "print(output_md)"
      ],
      "metadata": {
        "id": "TAcv3QqeZPok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='codex-mini-latest',\n",
        "    tools=[{'type': 'local_shell'}],\n",
        "    instructions='ä½¿ç”¨ç¹é«”ä¸­æ–‡',\n",
        "    input= [{\n",
        "        \"type\": \"local_shell_call_output\",\n",
        "        \"call_id\": call_id,\n",
        "        \"output\": output_md\n",
        "    }],\n",
        "    previous_response_id=response.id\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "-oROO70MbfsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-2 Code Interpreter å…§å»ºå·¥å…·"
      ],
      "metadata": {
        "id": "v9Sdqucde1VV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [code interpreter æ–‡ä»¶](https://platform.openai.com/docs/guides/tools-code-interpreter)"
      ],
      "metadata": {
        "id": "XjgsQTlD6nwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è‡ªå‹•å»ºç«‹å®¹å™¨åœ¨ Jupyter ä¸­åŸ·è¡Œç¨‹å¼ï¼š"
      ],
      "metadata": {
        "id": "QijQcNo92UMA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- å®¹å™¨æœƒåœ¨æœªä½¿ç”¨å¾Œ 20 åˆ†é˜å¤±æ•ˆï¼Œå®¹å™¨å…§çš„æ‰€æœ‰è³‡æ–™éƒ½æœƒæ¶ˆå¤±ã€‚\n",
        "- ä¸åŒæ¬¡ä½¿ç”¨ code interpreter å·¥å…·å¯èƒ½æœƒæ²¿ç”¨æ—¢æœ‰çš„å®¹å™¨ã€‚\n",
        "- code interpreter çš„è¨ˆè²»å°±æ˜¯æ¯é–‹ä¸€å€‹å®¹å™¨ 0.03 ç¾é‡‘ã€‚"
      ],
      "metadata": {
        "id": "T_lv5cfA6tgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-nano',\n",
        "    tools=[{\n",
        "        'type': 'code_interpreter',\n",
        "        'container': {'type': 'auto'}\n",
        "    }],\n",
        "    instructions=(\n",
        "        'ä½ æ˜¯ä½¿ç”¨ç¹é«”ä¸­æ–‡çš„åŠ©ç†ï¼Œç•¶é‡åˆ°æ•¸å­¸ç›¸é—œå•é¡Œæ™‚ï¼Œ'\n",
        "        'ä¸è¦å…ˆå›ç­”ï¼Œä¸€å¾‹å¯«ç¨‹å¼å†å›è¦†'\n",
        "    ),\n",
        "    input='3.8 å’Œ 3.11 å“ªä¸€å€‹å¤§ï¼Ÿ'\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "YnmanEgfduBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response)"
      ],
      "metadata": {
        "id": "3PcNzaRSeI30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output[0].code)"
      ],
      "metadata": {
        "id": "su-8tBVOZ-cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### å–å¾—ç¨‹å¼ç¢¼è¼¸å‡ºçµæœ"
      ],
      "metadata": {
        "id": "X9VuokSB2wFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-nano',\n",
        "    tools=[{\n",
        "        'type': 'code_interpreter',\n",
        "        'container': {'type': 'auto'}\n",
        "    }],\n",
        "    instructions=(\n",
        "        'ä½ æ˜¯ä½¿ç”¨ç¹é«”ä¸­æ–‡çš„åŠ©ç†ï¼Œç•¶é‡åˆ°æ•¸å­¸ç›¸é—œå•é¡Œæ™‚ï¼Œ'\n",
        "        'ä¸è¦å…ˆå›ç­”ï¼Œä¸€å¾‹å¯«ç¨‹å¼å†å›è¦†'\n",
        "    ),\n",
        "    input='3.8 å’Œ 3.11 å“ªä¸€å€‹å¤§ï¼Ÿ',\n",
        "    include=['code_interpreter_call.outputs']\n",
        ")\n",
        "\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "LE19sv97OINC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä½¿ç”¨ä¸²æµæ–¹å¼"
      ],
      "metadata": {
        "id": "gLbian_W20Ng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-nano',\n",
        "    tools=[{\n",
        "        'type': 'code_interpreter',\n",
        "        'container': {'type': 'auto'}\n",
        "    }],\n",
        "    instructions=(\n",
        "        'ä½ æ˜¯ä½¿ç”¨ç¹é«”ä¸­æ–‡çš„åŠ©ç†ï¼Œç•¶é‡åˆ°æ•¸å­¸ç›¸é—œå•é¡Œæ™‚ï¼Œ'\n",
        "        'ä¸è¦å…ˆå›ç­”ï¼Œä¸€å¾‹å¯«ç¨‹å¼å†å›è¦†'\n",
        "    ),\n",
        "    input='3.8 å’Œ 3.11 å“ªä¸€å€‹å¤§ï¼Ÿ',\n",
        "    include=['code_interpreter_call.outputs'],\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for event in response:\n",
        "    pprint(event)"
      ],
      "metadata": {
        "id": "Qd3B-oKlSJuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ç”± Code Interpreter è™•ç†æª”æ¡ˆ"
      ],
      "metadata": {
        "id": "l9Zkgnag2bRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://flagtech.github.io/images/tomica.jpg -o tomica.jpg\n"
      ],
      "metadata": {
        "id": "oAfJpxsaWaDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = upload_file(\n",
        "    'https://flagtech.github.io/images/tomica.jpg'\n",
        ")"
      ],
      "metadata": {
        "id": "qNAM0YwaeeOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¤‡é›œçš„å•é¡Œå¯èƒ½æœƒè·‘è¶…å¤šè¼ªå·¥å…·è·‘å¾ˆä¹…ï¼Œç”šè‡³é€¾æ™‚ï¼š"
      ],
      "metadata": {
        "id": "wBgSj55s7kbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    tools=[{\n",
        "        'type': 'code_interpreter',\n",
        "        'container': {\n",
        "            'type': 'auto',\n",
        "            'file_ids': [file_id]\n",
        "        }\n",
        "    }],\n",
        "    instructions='å°æ–¼ç†å·¥æ•¸å­¸å½±åƒè™•ç†å•é¡Œï¼Œ'\n",
        "                 'ç”¨ the python tool å¯«ç¨‹å¼è™•ç†',\n",
        "    input='å¹«æˆ‘æŠŠç…§ç‰‡è®Šæˆç°éš'\n",
        "    # input='å°‡ç…§ç‰‡å»èƒŒ'\n",
        ")\n",
        "\n",
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "xOoO7wWvXJFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response)"
      ],
      "metadata": {
        "id": "bvrBf4XOXtjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ç›®å‰ä»¥ä¸‹åªæœƒå‚³å› Noneï¼š\n",
        "\n",
        "```python\n",
        "annotation = response.output[-1].content[0].annotations[0]\n",
        "file_response = client.containers.files.content.retrieve(\n",
        "    container_id=annotation.container_id,\n",
        "    file_id=annotation.file_id\n",
        ")\n",
        "\n",
        "pprint(file_response)\n",
        "```\n",
        "\n",
        "æ‰€ä»¥æ”¹ç”¨åŸå§‹çš„ REST APIï¼š"
      ],
      "metadata": {
        "id": "1mm2HsnJ3E8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_content_from_container(container_id, file_id):\n",
        "    url = (\n",
        "        'https://api.openai.com/v1/containers/'\n",
        "        f'{container_id}'\n",
        "        '/files/'\n",
        "        f'{file_id}'\n",
        "        '/content'\n",
        "    )\n",
        "    response = requests.get(\n",
        "        url,\n",
        "        headers={\n",
        "            'Authorization': f'Bearer {client.api_key}'\n",
        "        }\n",
        "    )\n",
        "    if response.status_code != 200:\n",
        "        return None\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "WCTYyBSgneQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_code_interpreter_files(response):\n",
        "    files = []\n",
        "    for output in response.output:\n",
        "        if output.type != 'message':\n",
        "            continue\n",
        "        for content in output.content:\n",
        "            for annotation in content.annotations:\n",
        "                if annotation.type != 'container_file_citation':\n",
        "                    continue\n",
        "                files.append((\n",
        "                    annotation.container_id,\n",
        "                    annotation.file_id,\n",
        "                    annotation.filename\n",
        "                ))\n",
        "                content = get_file_content_from_container(\n",
        "                    file_id=annotation.file_id,\n",
        "                    container_id=annotation.container_id,\n",
        "                )\n",
        "                if not content:\n",
        "                    print(f'ç„¡æ³•ä¸‹è¼‰ {annotation.filename}')\n",
        "                    continue\n",
        "                with open(annotation.filename, 'wb') as f:\n",
        "                    f.write(content)\n",
        "    return files"
      ],
      "metadata": {
        "id": "DH7hbNqeYuny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = get_code_interpreter_files(response)\n",
        "pprint(files)"
      ],
      "metadata": {
        "id": "XBCtLLTE0nDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "å…¶å¯¦å®¹å™¨è‡ªå·±æœƒå¤±æ•ˆï¼Œè³‡æ–™ä¹Ÿæœƒæ¶ˆå¤±ï¼Œä¸¦æ²’æœ‰çœŸçš„éœ€è¦åˆªé™¤æª”æ¡ˆä»¥åŠå®¹å™¨çš„å¿…è¦ã€‚"
      ],
      "metadata": {
        "id": "DtKmBIpJB7wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for file in files:\n",
        "    client.containers.files.delete(\n",
        "        container_id=file[0],\n",
        "        file_id=file[1]\n",
        "    )"
      ],
      "metadata": {
        "id": "SL0T_PDW5juH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.containers.delete(files[0][0])"
      ],
      "metadata": {
        "id": "cPlxwU_P5zT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "è£œå……èªªæ˜ï¼Œåˆªé™¤å®¹å™¨ä¸­æª”æ¡ˆèˆ‡å®¹å™¨æœ¬èº«çš„ REST API ç‰ˆæœ¬ï¼š\n",
        "\n",
        "```python\n",
        "def delete_container_file(container_id, file_id):\n",
        "    url = (\n",
        "        'https://api.openai.com/v1/containers/'\n",
        "        f'{container_id}'\n",
        "        '/files/'\n",
        "        f'{file_id}'\n",
        "    )\n",
        "    response = requests.delete(\n",
        "        url,\n",
        "        headers={\n",
        "            'Authorization': f'Bearer {client.api_key}'\n",
        "        }\n",
        "    )\n",
        "    return response.status_code == 200\n",
        "```\n",
        "\n",
        "```python\n",
        "def delete_container(container_id):\n",
        "    url = (\n",
        "        'https://api.openai.com/v1/containers/'\n",
        "        f'{container_id}'\n",
        "    )\n",
        "    response = requests.delete(\n",
        "        url,\n",
        "        headers={\n",
        "            'Authorization': f'Bearer {client.api_key}'\n",
        "        }\n",
        "    )\n",
        "    return response.status_code == 200\n",
        "```\n",
        "\n",
        "```python\n",
        "for file in files:\n",
        "    if delete_container_file(file[0], file[1]):\n",
        "        print(f'æˆåŠŸåˆªé™¤ {file[2]}')\n",
        "```"
      ],
      "metadata": {
        "id": "uQr0GkpM6kZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ‰‹å‹•å»ºç«‹å®¹å™¨"
      ],
      "metadata": {
        "id": "iLhI_PAlzIwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ä½ ä¹Ÿå¯ä»¥è‡ªå·±å»ºç«‹å®¹å™¨ï¼Œä¸¦æŒ‡å®šä½¿ç”¨è©²å®¹å™¨ï¼Œé€™ä¹Ÿå¯ä»¥æŒ‡å®šä½¿ç”¨è‡ªå‹•å»ºç«‹çš„å®¹å™¨ã€‚å®¹å™¨ä¸­çš„æª”æ¡ˆå¯ä»¥åœ¨å»ºç«‹æ™‚åŒæ™‚åŠ å…¥ï¼Œä¹Ÿå¯ä»¥åœ¨å»ºç«‹å¾ŒåŠ å…¥ã€‚"
      ],
      "metadata": {
        "id": "FZh2OFpB7B8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.containers.create(\n",
        "    name='test',\n",
        "    # expires_after={\n",
        "    #     'anchor': 'last_active_at',\n",
        "    #     'minutes': 20\n",
        "    # }\n",
        ")\n",
        "\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "OVBukMqUxug0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REST API ç‰ˆæœ¬ï¼š\n",
        "\n",
        "```python\n",
        "def create_container(name, expires_after=20, file_ids=None):\n",
        "    url = 'https://api.openai.com/v1/containers'\n",
        "    data = {\n",
        "        'name': name,\n",
        "        'expires_after': {\n",
        "            'anchor': 'last_active_at',\n",
        "            'minutes': expires_after,\n",
        "        },\n",
        "        'file_ids': file_ids if file_ids else []\n",
        "    }\n",
        "    response = requests.post(\n",
        "        url,\n",
        "        headers={\n",
        "            'Authorization': f'Bearer {client.api_key}'\n",
        "        },\n",
        "        json=data\n",
        "    )\n",
        "    if response.status_code != 200:\n",
        "        return None\n",
        "    return response.json()['id']\n",
        "```"
      ],
      "metadata": {
        "id": "rNdymQG87_vX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.containers.files.create(\n",
        "    container_id=response.id,\n",
        "    file_id=file_id\n",
        ")\n",
        "\n",
        "pprint(respsone)"
      ],
      "metadata": {
        "id": "PkkTvE6Z9QlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REST API ç‰ˆæœ¬ï¼š\n",
        "\n",
        "```python\n",
        "def add_file_to_container(container_id, file_id):\n",
        "    url = (\n",
        "        'https://api.openai.com/v1/containers'\n",
        "        f'/{container_id}/files'\n",
        "    )\n",
        "    response = requests.post(\n",
        "        url,\n",
        "        headers={\n",
        "            'Authorization': f'Bearer {client.api_key}'\n",
        "        },\n",
        "        json={\n",
        "            'file_id': file_id\n",
        "        }\n",
        "    )\n",
        "    if response.status_code != 200:\n",
        "        return None\n",
        "    return response.json()['id']\n",
        "```"
      ],
      "metadata": {
        "id": "Z1PxpueC9HSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    tools=[{\n",
        "        'type': 'code_interpreter',\n",
        "        'container': response.container_id\n",
        "    }],\n",
        "    instructions='å°æ–¼ç†å·¥æ•¸å­¸å½±åƒè™•ç†å•é¡Œï¼Œ'\n",
        "                 'ç”¨ the python tool å¯«ç¨‹å¼è™•ç†',\n",
        "    input='å°‡ç…§ç‰‡è®Šæˆè—è‰²èª¿è‰²éšæ•ˆæœçš„åœ–'\n",
        ")"
      ],
      "metadata": {
        "id": "jBBDVild87Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(response)"
      ],
      "metadata": {
        "id": "LRVaw3Vz-all"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = get_code_interpreter_files(response)\n",
        "print(files[-1][-1])"
      ],
      "metadata": {
        "id": "mOVwD1ur-db-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-3 å…§å»ºç”Ÿåœ–å·¥å…·"
      ],
      "metadata": {
        "id": "JtU6I58J6qsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- èƒŒå¾Œç”Ÿåœ–çš„æ˜¯ [gpt-image-1](https://platform.openai.com/docs/models/gpt-image-1) æ¨¡å‹\n",
        "- [å¯ç”¨é¸é …](https://platform.openai.com/docs/guides/image-generation#customize-image-output)\n",
        "- [è²»ç”¨](https://platform.openai.com/docs/guides/image-generation#cost-and-latency)"
      ],
      "metadata": {
        "id": "vAPe50MFULSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    input='ç”¨æ‰‹å¡šæ²»è™«é¢¨æ ¼ç”Ÿæˆå·¥ç¨‹å¸«åœ¨æµ·ç˜ä¸Šå¯«ç¨‹å¼çš„åœ–',\n",
        "    tools=[{\n",
        "        'type': 'image_generation',\n",
        "        'size': 'auto',\n",
        "        'quality': 'auto',\n",
        "    }]\n",
        ")\n",
        "\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "uERo9xGA-7xH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "from IPython.display import Image\n",
        "\n",
        "def get_img_b64(outputs):\n",
        "    img_data = [\n",
        "        output.result for output in outputs\n",
        "        if output.type == 'image_generation_call'\n",
        "    ]\n",
        "    return img_data[0] if img_data else None\n",
        "\n",
        "def get_img_obj(img_b64, width=300):\n",
        "    return Image(base64.b64decode(img_b64), width=width)\n",
        "\n",
        "def save_img(img_b64, filename='gen.png'):\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(base64.b64decode(img_b64))"
      ],
      "metadata": {
        "id": "8rh92UhD9r9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_b64 = get_img_b64(response.output)\n",
        "display(get_img_obj(img_b64))\n",
        "save_img(img_b64)"
      ],
      "metadata": {
        "id": "7wOXSMmkABog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.output_text)"
      ],
      "metadata": {
        "id": "T1Jm-uDABNvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¸²æ¥å›æ‡‰æŒçºŒä¿®æ”¹"
      ],
      "metadata": {
        "id": "uheiZDG-I2kY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    input='æŠŠå®ƒè®Šæˆã€Šæ”»æ®¼æ©Ÿå‹•éšŠã€‹çš„é¢¨æ ¼ï¼Œä½†ç•«é¢è¦ç´°ç·»æ˜äº®',\n",
        "    tools=[{\n",
        "        'type': 'image_generation',\n",
        "    }],\n",
        "    previous_response_id=response.id\n",
        ")\n",
        "\n",
        "img_b64 = get_img_b64(response.output)\n",
        "display(get_img_obj(img_b64))"
      ],
      "metadata": {
        "id": "XPrezsLEB61H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä»¥ä¸²æµæ¨¡å¼å–å¾—éç¨‹è®ŠåŒ–åœ–"
      ],
      "metadata": {
        "id": "0JltSwB1tFjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "æœƒæœ‰ partial_images+1 æ¬¡çš„ outputï¼Œæœ€å¾Œä¸€æ¬¡å°±æ˜¯å®Œæ•´çš„çµæœ"
      ],
      "metadata": {
        "id": "EO-Gd1PttKCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    input='ç”¨å‰åœåŠ›é¢¨æ ¼ç”Ÿæˆå·¥ç¨‹å¸«åœ¨æµ·ç˜ä¸Šå¯«ç¨‹å¼çš„åœ–',\n",
        "    tools=[{\n",
        "        'type': 'image_generation',\n",
        "        'partial_images': 3 # ä¸²æµæ¨¡å¼æ‰èƒ½ç”¨\n",
        "    }],\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "for output in response:\n",
        "    pprint(output)"
      ],
      "metadata": {
        "id": "mu1bQihwHHA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    input='ç”¨è’™å¾·é‡Œå®‰é¢¨æ ¼ç”Ÿæˆå·¥ç¨‹å¸«åœ¨æµ·ç˜ä¸Šå¯«ç¨‹å¼çš„åœ–',\n",
        "    tools=[{\n",
        "        'type': 'image_generation',\n",
        "        'partial_images': 3 # ä¸²æµæ¨¡å¼æ‰èƒ½ç”¨\n",
        "    }],\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "imgs = []\n",
        "display_handle = display(None, display_id=True)\n",
        "\n",
        "for event in response:\n",
        "    if event.type == 'response.completed':\n",
        "        b64_data = get_img_b64(event.response.output)\n",
        "    elif event.type == (\n",
        "        'response.image_generation_call.partial_image'\n",
        "    ):\n",
        "        b64_data = event.partial_image_b64\n",
        "    else: continue\n",
        "    display_handle.update(get_img_obj(b64_data))\n",
        "    imgs.append(b64_data)"
      ],
      "metadata": {
        "id": "68qyP0LemYB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgs[-2] == imgs[-1]"
      ],
      "metadata": {
        "id": "aRFZ68qlnS_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### åœ¨èƒŒæ™¯åŸ·è¡Œ Responses API"
      ],
      "metadata": {
        "id": "h-H7i0VsJA2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.responses.create(\n",
        "    model='gpt-4.1-mini',\n",
        "    input='ç”¨æ¢µè°·é¢¨æ ¼ç”Ÿæˆå·¥ç¨‹å¸«åœ¨æµ·ç˜ä¸Šå¯«ç¨‹å¼çš„åœ–',\n",
        "    tools=[{\n",
        "        'type': 'image_generation',\n",
        "        'size': 'auto',\n",
        "        'quality': 'auto',\n",
        "    }],\n",
        "    background=True\n",
        ")\n",
        "\n",
        "response = client.responses.retrieve(response.id)\n",
        "pprint(response)"
      ],
      "metadata": {
        "id": "qNunBGW4JAIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "while response.status != 'completed':\n",
        "    time.sleep(5)\n",
        "    response = client.responses.retrieve(response.id)\n",
        "    print(response.status)"
      ],
      "metadata": {
        "id": "WGZU-t5FJ1gQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_b64 = get_img_b64(response.output)\n",
        "display(get_img_obj(img_b64))"
      ],
      "metadata": {
        "id": "zG_0Mr9RLmjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6-4 å¹«èŠå¤©ç¨‹å¼åŠ å…¥æ–°å…§å»ºå·¥å…·"
      ],
      "metadata": {
        "id": "nJ8o6KJR0Ab5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "è¦ç‰¹åˆ¥ç•™æ„æœ‰äº›åœ–å½¢å­—å…ƒï¼Œåƒæ˜¯ 'âŒ¨ï¸'ã€'ğŸ–Œï¸' å› ç‚ºæœ‰åŠ ä¸Šäº†[**è®Šé«”é¸æ“‡ç¬¦ (variation selector)**](https://grok.com/share/bGVnYWN5_78048bb7-7098-4fc2-818f-7475e3188243)ï¼Œæ‰€ä»¥æœƒè¢«è¨ˆç‚º 2 å€‹å­—å…ƒï¼Œåœ¨åº•ä¸‹è¨ˆç®—è‡ªè¨‚å·¥å…·å€‹æ•¸æ™‚æœƒå‡ºéŒ¯ã€‚"
      ],
      "metadata": {
        "id": "c4vsxaF_Piy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ä¿®æ”¹ Chat é¡åˆ¥"
      ],
      "metadata": {
        "id": "OIurIitt5xV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "    def __init__(self, client, **kwargs):\n",
        "        self._client = client\n",
        "        self._last_id = kwargs.pop('last_id', None)\n",
        "        # é™åˆ¶å·¥å…·åŸ·è¡Œåœˆæ•¸ï¼Œé¿å…ç„¡çª®ç›¡å«ç”¨å·¥å…·\n",
        "        self._max_tools_rounds = kwargs.pop('max_tools_rounds', 4)\n",
        "        self.tools = [] # é è¨­æ²’æœ‰ä½¿ç”¨å·¥å…·\n",
        "        self._commands = kwargs.pop('commands', [])\n",
        "\n",
        "    def get_reply_text(self, msg, **kwargs) -> str:\n",
        "        instructions = kwargs.pop('instructions', 'ä½¿ç”¨ç¹é«”ä¸­æ–‡')\n",
        "        model = kwargs.pop('model', 'gpt-4.1-nano')\n",
        "        stream = kwargs.pop('stream', False)\n",
        "        tool_results = [] # å‡½å¼å«ç”¨çš„ç›¸é—œè³‡è¨Š\n",
        "        for command in self._commands:\n",
        "            extra_args = {\n",
        "                k: kwargs[k] + command.extra_args[k]\n",
        "                if k in kwargs\n",
        "                else command.extra_args[k]\n",
        "                for k in command.extra_args\n",
        "            }\n",
        "            kwargs.update(extra_args)\n",
        "        try:\n",
        "            messages = [{'role': 'user', 'content': msg}]\n",
        "            for _ in range(self._max_tools_rounds):\n",
        "                # æ–¹ä¾¿ç¨å¾Œä¸²æ¥å‡½å¼å«ç”¨è³‡è¨Š\n",
        "                if tool_results: # ä¸²æ¥å«ç”¨å‡½å¼çš„è³‡è¨Š\n",
        "                    messages += tool_results\n",
        "                response = self._client.responses.create(\n",
        "                    instructions=instructions,\n",
        "                    model=model,\n",
        "                    input=messages,\n",
        "                    stream=True, # éƒ½ä»¥ä¸²æµæ–¹å¼è™•ç†ï¼Œç°¡åŒ–ç¨‹å¼é‚è¼¯\n",
        "                    previous_response_id=self._last_id, # ä¸²æ¥å›æ‡‰\n",
        "                    **kwargs\n",
        "                )\n",
        "                for event in response:\n",
        "                    for command in self._commands:\n",
        "                        result = command.handle_event(\n",
        "                            self, stream, event\n",
        "                        )\n",
        "                        if result: break\n",
        "                    tool_results = []\n",
        "                    if isinstance(result, list):\n",
        "                        # å·¥å…·è¦é€å›çµ¦æ¨¡å‹çš„è¨Šæ¯ä¸²åˆ—\n",
        "                        tool_results = result\n",
        "                        break\n",
        "                    elif result: # æŒ‡ä»¤è™•ç†å™¨ç”¢ç”Ÿçš„å…§å®¹\n",
        "                        yield result\n",
        "                    if event.type == 'response.output_text.delta':\n",
        "                        if stream: yield event.delta\n",
        "                    elif event.type == (\n",
        "                        'response.output_text.done'\n",
        "                    ):\n",
        "                        # éä¸²æµæ¨¡å¼è¦å‚³å›å®Œæ•´å…§å®¹\n",
        "                        if not stream:\n",
        "                            yield event.text\n",
        "                    elif event.type == 'response.completed':\n",
        "                        # æ›´æ–°æœ€å¾Œå›æ‡‰çš„è­˜åˆ¥ç¢¼\n",
        "                        self._last_id = event.response.id\n",
        "                if not tool_results:\n",
        "                    # æ²’æœ‰è¦é€å›çµ¦æ¨¡å‹çš„è¨Šæ¯\n",
        "                    # è¡¨ç¤ºå·²ç¶“æˆåŠŸç”Ÿæˆå…§å®¹\n",
        "                    break\n",
        "        except openai.APIError as err:\n",
        "            print(f'Error:{err.body[\"message\"]}', file=sys.stderr)\n",
        "            return ''\n",
        "\n",
        "    def find_tool_index(self, tool_type):\n",
        "        for i, tool in enumerate(self.tools):\n",
        "            if tool['type'] == tool_type: return i\n",
        "        return -1\n",
        "\n",
        "    def _get_prompt(self):\n",
        "        prompt = ''\n",
        "        for command in self._commands:\n",
        "            idx = self.find_tool_index(command.tool_name)\n",
        "            if idx != -1:\n",
        "                prompt += f'{command.icon}'\n",
        "        user_tools_count = len(self.tools) - len(prompt)\n",
        "        prompt += f'(ğŸ› ï¸{user_tools_count})>>> '\n",
        "        return prompt\n",
        "\n",
        "    def _process_command(self, cmd):\n",
        "        for command in self._commands:\n",
        "            if command.handle_command(self, cmd):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def loop(self, **kwargs) -> None:\n",
        "        print(\"ç›´æ¥æŒ‰ â†µ å¯çµæŸå°è©±\")\n",
        "        while True:\n",
        "            user_msg = input(self._get_prompt())\n",
        "            if not user_msg.strip(): break # ç›´æ¥ â†µ å°±çµæŸ\n",
        "            if self._process_command(user_msg):\n",
        "                continue # æŒ‡ä»¤ä¸éœ€å›è¦†ï¼Œå›é ­è®“ä½¿ç”¨è€…è¼¸å…¥\n",
        "            text = ''\n",
        "            display_handle = display(text, display_id=True)\n",
        "            display_extra_handle = None\n",
        "            for reply in self.get_reply_text(\n",
        "                user_msg,\n",
        "                tools=self.tools, # å‚³å…¥è¦ä½¿ç”¨çš„å·¥å…·\n",
        "                **kwargs\n",
        "            ):\n",
        "                if not isinstance(reply, str):\n",
        "                    if not display_extra_handle:\n",
        "                        display_extra_handle = display(\n",
        "                            reply, display_id=True\n",
        "                        )\n",
        "                    else:\n",
        "                        display_extra_handle.update(reply)\n",
        "                    continue\n",
        "                text += reply\n",
        "                if os.path.exists(text):\n",
        "                    display_handle.update(Markdown(f' text'))\n",
        "                else:\n",
        "                    display_handle.update(Markdown(text))\n",
        "\n",
        "    def save(self, filename) -> None:\n",
        "        with open(filename, 'wb') as f:\n",
        "            pickle.dump(\n",
        "                {\n",
        "                    'last_id': self._last_id,\n",
        "                    'tools': self.tools,\n",
        "                    'commands': self._commands\n",
        "                },\n",
        "                f\n",
        "            )\n",
        "\n",
        "    def load(self, filename) -> None:\n",
        "        with open(filename, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            self._last_id = data['last_id']\n",
        "            self.tools = data['tools']\n",
        "            self._commands = data['commands']\n",
        "\n",
        "    def show_thread(self):\n",
        "        if not self._last_id: return\n",
        "        inputs = client.responses.input_items.list(self._last_id)\n",
        "        response = client.responses.retrieve(self._last_id)\n",
        "        for item in inputs.data[::-1]:\n",
        "            # ç•¥éå‡½å¼å«ç”¨æŒ‡ç¤ºç­‰éè¨Šæ¯å…§å®¹\n",
        "            if item.type != 'message': continue\n",
        "            prompt = \">>> \" if item.role == 'user' else ''\n",
        "            for content in item.content:\n",
        "                print(f'{prompt}{content.text}')\n",
        "        print(response.output_text)\n",
        "\n",
        "    def delete_thread(self):\n",
        "        if not self._last_id: return\n",
        "        last_id = self._last_id\n",
        "        while last_id:\n",
        "            response = client.responses.retrieve(last_id)\n",
        "            last_id, curr_id = (\n",
        "                response.previous_response_id,\n",
        "                last_id\n",
        "            )\n",
        "            client.responses.delete(curr_id)\n",
        "        self._last_id = None"
      ],
      "metadata": {
        "id": "NNMjQAu_0G6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è™•ç† Code Interpreter æŒ‡ä»¤çš„é¡åˆ¥"
      ],
      "metadata": {
        "id": "tYbyhKij519p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CodeInterpreterCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/c',\n",
        "            'code_interpreter',\n",
        "            'ğŸ',\n",
        "            verbose\n",
        "        )\n",
        "\n",
        "    def get_file_content_from_container(\n",
        "            self, container_id, file_id\n",
        "    ):\n",
        "        url = (\n",
        "            'https://api.openai.com/v1/containers/'\n",
        "            f'{container_id}'\n",
        "            '/files/'\n",
        "            f'{file_id}'\n",
        "            '/content'\n",
        "        )\n",
        "        response = requests.get(\n",
        "            url,\n",
        "            headers={\n",
        "                'Authorization': f'Bearer {client.api_key}'\n",
        "            }\n",
        "        )\n",
        "        if response.status_code != 200:\n",
        "            return None\n",
        "        return response.content\n",
        "\n",
        "    def get_code_interpreter_files(self, response):\n",
        "        files = []\n",
        "        for output in response.output:\n",
        "            if output.type != 'message':\n",
        "                continue\n",
        "            for content in output.content:\n",
        "                for annotation in content.annotations:\n",
        "                    if annotation.type != (\n",
        "                        'container_file_citation'\n",
        "                    ):\n",
        "                        continue\n",
        "                    files.append((\n",
        "                        annotation.container_id,\n",
        "                        annotation.file_id,\n",
        "                        annotation.filename\n",
        "                    ))\n",
        "                    content = (\n",
        "                        self.get_file_content_from_container(\n",
        "                        annotation.container_id,\n",
        "                        annotation.file_id\n",
        "                    ))\n",
        "                    if not content:\n",
        "                        print(f'ç„¡æ³•ä¸‹è¼‰ {annotation.filename}')\n",
        "                        continue\n",
        "                    with open(annotation.filename, 'wb') as f:\n",
        "                        f.write(content)\n",
        "        return files\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        file_ids = []\n",
        "        if len(cmd) > 3:\n",
        "            file_id= upload_file(cmd[3:])\n",
        "            if not file_id:\n",
        "                print(f'ç„¡æ³•ä¸Šå‚³æª”æ¡ˆï¼š{file_path}')\n",
        "                return True\n",
        "            file_ids.append(file_id)\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'container': {\n",
        "                    'type': 'auto',\n",
        "                    'file_ids': file_ids\n",
        "                }\n",
        "            })\n",
        "            self.extra_args = {\n",
        "                'include': ['code_interpreter_call.outputs'],\n",
        "            }\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "            self.extra_args = {}\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if event.type == 'response.completed':\n",
        "            files = self.get_code_interpreter_files(\n",
        "                event.response\n",
        "            )\n",
        "            for f in files:\n",
        "                print(f'å·²ä¸‹è¼‰ï¼š{f[2]}')\n",
        "            return None\n",
        "        if not self.verbose: return None\n",
        "        if event.type == (\n",
        "            'response.code_interpreter_call.'\n",
        "            'in_progress'\n",
        "        ):\n",
        "            if stream: return '\\n```python\\n'\n",
        "        elif event.type == (\n",
        "            'response.'\n",
        "            'code_interpreter_call_code.delta'\n",
        "        ):\n",
        "            if stream: return event.delta\n",
        "        elif event.type == (\n",
        "            'response.'\n",
        "            'code_interpreter_call_code.done'\n",
        "        ):\n",
        "            if stream: return '\\n```\\n\\n'\n",
        "            else: return f'\\n\\n```python\\n{event.code}\\n```\\n\\n'\n",
        "        elif event.type == 'response.output_item.done':\n",
        "            if event.item.type == 'code_interpreter_call':\n",
        "                results = (\n",
        "                    f'\\nçµæœæ˜¯ï¼š\\n\\n```\\n'\n",
        "                    f'{event.item.outputs[0][\"logs\"]}'\n",
        "                    f'\\n```\\n\\n'\n",
        "                )\n",
        "                return results\n",
        "        return None"
      ],
      "metadata": {
        "id": "WVgBSxTErswM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### è™•ç†ç”Ÿåœ–æŒ‡ä»¤çš„é¡åˆ¥"
      ],
      "metadata": {
        "id": "LfPh0Ugl55uH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "import base64\n",
        "\n",
        "class ImageGenerationCommand(BaseComand):\n",
        "    def __init__(self, verbose=False):\n",
        "        super().__init__(\n",
        "            '/i',\n",
        "            'image_generation',\n",
        "            'ğŸ¨',\n",
        "            verbose=verbose,\n",
        "        )\n",
        "\n",
        "    def get_img_b64(self, outputs):\n",
        "        img_data = [\n",
        "            output.result for output in outputs\n",
        "            if output.type == 'image_generation_call'\n",
        "        ]\n",
        "        return img_data[0] if img_data else None\n",
        "\n",
        "    def get_img_obj(self, img_b64, width=300):\n",
        "        return Image(base64.b64decode(img_b64), width=width)\n",
        "\n",
        "    def save_img(self, img_b64, filename='gen.png'):\n",
        "        with open(filename, 'wb') as f:\n",
        "            f.write(base64.b64decode(img_b64))\n",
        "\n",
        "    def handle_command(self, chat, cmd):\n",
        "        if not super().handle_command(chat, cmd):\n",
        "            return False\n",
        "        idx = chat.find_tool_index(self.tool_name)\n",
        "        if idx == -1:\n",
        "            chat.tools.append({\n",
        "                'type': self.tool_name,\n",
        "                'partial_images': 3 if self.verbose else 1\n",
        "            })\n",
        "        else:\n",
        "            chat.tools.pop(idx)\n",
        "        return True\n",
        "\n",
        "    def handle_event(self, chat, stream, event):\n",
        "        if event.type == 'response.completed':\n",
        "            b64_data = self.get_img_b64(event.response.output)\n",
        "            if not b64_data: return None\n",
        "        elif event.type == (\n",
        "            'response.image_generation_call.partial_image'\n",
        "        ):\n",
        "            b64_data = event.partial_image_b64\n",
        "        else: return None\n",
        "        return self.get_img_obj(b64_data)"
      ],
      "metadata": {
        "id": "RVoQFLcX0rhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### æ¸¬è©¦å…¨åŠŸèƒ½çš„èŠå¤©ç¨‹å¼"
      ],
      "metadata": {
        "id": "fnfwq3bh59-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_search_command = FileSearchCommand(verbose=True)\n",
        "\n",
        "chat = Chat(\n",
        "    client,\n",
        "    commands=[\n",
        "        CodeInterpreterCommand(verbose=True),\n",
        "        ImageGenerationCommand(verbose=True),\n",
        "        FunctionCallingCommand(\n",
        "            tools=[shell_helper_tool],\n",
        "            verbose=True\n",
        "        ),\n",
        "        file_search_command,\n",
        "        WebSearchCommand(verbose=True)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "VM6hgkiK74Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat.loop(\n",
        "    model='gpt-4.1-mini',\n",
        "    stream=True,\n",
        "    instructions='ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œ'\\\n",
        "                 'å°æ–¼æ•¸ç†å•é¡Œéƒ½å…ˆå¯«ç¨‹å¼åŸ·è¡Œå¾Œå†å›è¦†'\n",
        ")"
      ],
      "metadata": {
        "id": "5Sc9fe0b8PYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_search_command.remove_vector_store(chat)\n",
        "chat.delete_thread()"
      ],
      "metadata": {
        "id": "T_FDHsp5eXe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Ax_6G-Z-wim"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}