{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ LangChain åˆ†å‰²ç¨‹å¼ç¢¼\n",
    "\n",
    "## æ¦‚è§€\n",
    "\n",
    "`RecursiveCharacterTextSplitter` å…§å»ºäº†é‡å°å¤šç¨®ç¨‹å¼èªè¨€å„ªåŒ–çš„åˆ†éš”ç¬¦æ¸…å–®ï¼Œå¯æœ‰æ•ˆåœ°å°‡åŸå§‹ç¢¼é€²è¡Œèªæ„åˆ‡åˆ†ã€‚\n",
    "\n",
    "è€Œ `CodeTextSplitter` å‰‡æä¾›æ›´é€²éšçš„ç¨‹å¼ç¢¼åˆ†å‰²åŠŸèƒ½ï¼Œè®“ä½ èƒ½å¤ æ ¹æ“šèªè¨€èªæ³•é€²è¡Œç²¾ç´°è™•ç†ã€‚\n",
    "\n",
    "ä½¿ç”¨æ™‚ï¼Œéœ€å…ˆåŒ¯å…¥ `Language` åˆ—èˆ‰ï¼ˆenumï¼‰é¡åˆ¥ï¼Œä¸¦æŒ‡å®šæ¬²ä½¿ç”¨çš„ç¨‹å¼èªè¨€ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“š ç›®éŒ„\n",
    "\n",
    "- [æ¦‚è§€](#æ¦‚è§€)\n",
    "- [ç’°å¢ƒè¨­ç½®](#ç’°å¢ƒè¨­ç½®)\n",
    "- [ç¨‹å¼ç¢¼åˆ†å‰²ç¯„ä¾‹](#ç¨‹å¼ç¢¼åˆ†å‰²ç¯„ä¾‹)\n",
    "  - [Python](#python)\n",
    "  - [JavaScript](#javascript)\n",
    "  - [TypeScript](#typescript)\n",
    "  - [Markdown](#markdown)\n",
    "  - [LaTeX](#latex)\n",
    "  - [HTML](#html)\n",
    "  - [Solidity](#solidity)\n",
    "  - [C#](#c)\n",
    "  - [PHP](#php)\n",
    "  - [Kotlin](#kotlin)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”— åƒè€ƒè³‡æ–™\n",
    "\n",
    "- [LangChain å®˜æ–¹æ–‡ä»¶ï¼šHow to split code](https://python.langchain.com/docs/how_to/code_splitter/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain_text_splitters\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Code-Splitter\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¨‹å¼ç¢¼åˆ†å‰²ç¯„ä¾‹\n",
    "\n",
    "ä»¥ä¸‹ç¤ºç¯„å¦‚ä½•ä½¿ç”¨ `RecursiveCharacterTextSplitter` é€²è¡Œç¨‹å¼ç¢¼çš„åˆ†å‰²æ“ä½œã€‚\n",
    "\n",
    "### åŸºæœ¬æ­¥é©Ÿï¼š\n",
    "\n",
    "- å¾ `langchain_text_splitters` æ¨¡çµ„åŒ¯å…¥ `Language` èˆ‡ `RecursiveCharacterTextSplitter` é¡åˆ¥ã€‚\n",
    "- `RecursiveCharacterTextSplitter` æ˜¯ä¸€ç¨®éè¿´å¼å­—å…ƒç´šæ–‡æœ¬åˆ†å‰²å™¨ï¼Œå¯ä¾æ“šä¸åŒèªè¨€èªæ³•åšç²¾ç´°åˆ‡å‰²ã€‚\n",
    "\n",
    "### ğŸ“Œ ç¯„ä¾‹ç¨‹å¼ç¢¼\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# æŒ‡å®šè¦åˆ†å‰²çš„ç¨‹å¼èªè¨€ï¼Œä¾‹å¦‚ Python\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20\n",
    ")\n",
    "\n",
    "code_snippet = \"\"\"\n",
    "def fibonacci(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    elif n == 1:\n",
    "        return [0]\n",
    "    elif n == 2:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        fib = [0, 1]\n",
    "        for i in range(2, n):\n",
    "            fib.append(fib[-1] + fib[-2])\n",
    "        return fib\n",
    "\"\"\"\n",
    "\n",
    "chunks = python_splitter.split_text(code_snippet)\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {idx+1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import (\n",
    "    Language,\n",
    "    RecursiveCharacterTextSplitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supported languages are stored in the langchain_text_splitters.Language enum. \n",
    "\n",
    "API Reference: [Language](https://python.langchain.com/api_reference/text_splitters/base/langchain_text_splitters.base.Language.html#language) | [RecursiveCharacterTextSplitter](https://python.langchain.com/api_reference/text_splitters/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html#recursivecharactertextsplitter)\n",
    "\n",
    "See below for the full list of supported languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cpp',\n",
       " 'go',\n",
       " 'java',\n",
       " 'kotlin',\n",
       " 'js',\n",
       " 'ts',\n",
       " 'php',\n",
       " 'proto',\n",
       " 'python',\n",
       " 'rst',\n",
       " 'ruby',\n",
       " 'rust',\n",
       " 'scala',\n",
       " 'swift',\n",
       " 'markdown',\n",
       " 'latex',\n",
       " 'html',\n",
       " 'sol',\n",
       " 'csharp',\n",
       " 'cobol',\n",
       " 'c',\n",
       " 'lua',\n",
       " 'perl',\n",
       " 'haskell',\n",
       " 'elixir',\n",
       " 'powershell']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the full list of supported languages.\n",
    "[e.value for e in Language]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æŸ¥çœ‹ç‰¹å®šèªè¨€çš„é è¨­åˆ†å‰²ç¬¦è™Ÿ\n",
    "\n",
    "ä½ å¯ä»¥ä½¿ç”¨ `RecursiveCharacterTextSplitter` é¡åˆ¥ä¸­çš„ ```get_separators_for_language``` æ–¹æ³•ï¼ŒæŸ¥çœ‹æŒ‡å®šç¨‹å¼èªè¨€æ‰€ä½¿ç”¨çš„åˆ†å‰²ç¬¦è™Ÿï¼ˆseparatorsï¼‰æ¸…å–®ã€‚\n",
    "\n",
    "é€™å°æ–¼è‡ªè¨‚åˆ†å‰²é‚è¼¯æˆ–äº†è§£èªè¨€çµæ§‹éå¸¸æœ‰å¹«åŠ©ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ ç¯„ä¾‹ï¼šå–å¾— Python çš„åˆ†å‰²ç¬¦è™Ÿ\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "# æŸ¥çœ‹ Python çš„é è¨­åˆ†å‰²ç¬¦è™Ÿ\n",
    "separators = RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)\n",
    "\n",
    "print(\"Python é è¨­åˆ†å‰²ç¬¦è™Ÿï¼š\")\n",
    "for s in separators:\n",
    "    print(repr(s))  # ä½¿ç”¨ repr() é¡¯ç¤ºç‰¹æ®Šå­—å…ƒï¼ˆå¦‚æ›è¡Œç¬¦è™Ÿï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nclass ', '\\ndef ', '\\n\\tdef ', '\\n\\n', '\\n', ' ', '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can check the separators used for the given language.\n",
    "RecursiveCharacterTextSplitter.get_separators_for_language(Language.PYTHON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»¥ä¸‹æ˜¯å°‡ä½ æä¾›çš„æ•™å­¸æ®µè½ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡çš„ Markdown å…§å®¹ï¼Œæ ¼å¼èˆ‡åŸæ–‡ä¸€è‡´ï¼š\n",
    "\n",
    "### Python\n",
    "\n",
    "ä»¥ä¸‹ç¤ºç¯„å¦‚ä½•ä½¿ç”¨ ```RecursiveCharacterTextSplitter``` å°‡ Python ç¨‹å¼ç¢¼åˆ†å‰²æˆè¼ƒå°çš„å€å¡Šï¼š\n",
    "\n",
    "- é¦–å…ˆï¼Œå°‡ ```language``` åƒæ•¸è¨­ç‚º ```Language.PYTHON```ï¼Œé€™è¡¨ç¤ºæˆ‘å€‘è™•ç†çš„æ˜¯ Python èªè¨€çš„ç¨‹å¼ç¢¼ã€‚\n",
    "- æ¥è‘—ï¼Œè¨­å®š ```chunk_size``` ç‚º 50ï¼Œé€™ä»£è¡¨æ¯å€‹åˆ†å‰²å¾Œçš„å€å¡Šæœ€å¤§ç‚º 50 å€‹å­—å…ƒã€‚\n",
    "- æœ€å¾Œï¼Œè¨­å®š ```chunk_overlap``` ç‚º 0ï¼Œä»¥ç¢ºä¿å„å€å¡Šä¹‹é–“ä¸æœƒæœ‰é‡ç–Šã€‚\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "code = \\\"\\\"\\\"\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "def subtract(a, b):\n",
    "    return a - b\n",
    "\n",
    "print(add(2, 3))\n",
    "print(subtract(5, 2))\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    language=Language.PYTHON,\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(code)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n\")\n",
    "\n",
    "é€™æ¨£å¯ä»¥å°‡è¼ƒé•·çš„ç¨‹å¼ç¢¼è‡ªå‹•åˆ†æˆå¹¾å€‹å°å€å¡Šï¼Œä¾¿æ–¼èªæ„è™•ç†æˆ–é¤µçµ¦å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰åˆ†æã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'),\n",
       " Document(metadata={}, page_content='hello_world()')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Create `Document`. The created `Document` is returned as a list.\n",
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def hello_world():\n",
      "    print(\"Hello, World!\")\n",
      "==================\n",
      "hello_world()\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "# This section iterates through the list of documents created by the RecursiveCharacterTextSplitter\n",
    "# and prints each document's content followed by a separator line for readability.\n",
    "for doc in python_docs:\n",
    "    print(doc.page_content, end=\"\\n==================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JavaScript\n",
    "\n",
    "Here's how to split JavaScript code into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "- First, specify ```Language.JS``` for the ```language``` parameter. It tells the splitter you're working with JavaScript code.\n",
    "- Then, set ```chunk_size``` to 60. This limits the size of each resulting chunk to a maximum of 60 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='function helloWorld() {\\n  console.log(\"Hello, World!\");\\n}'),\n",
       " Document(metadata={}, page_content='helloWorld();')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JS_CODE = \"\"\"\n",
    "function helloWorld() {\n",
    "  console.log(\"Hello, World!\");\n",
    "}\n",
    "\n",
    "helloWorld();\n",
    "\"\"\"\n",
    "\n",
    "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.JS, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Create `Document`. The created `Document` is returned as a list.\n",
    "js_docs = js_splitter.create_documents([JS_CODE])\n",
    "js_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TypeScript\n",
    "\n",
    "Here's how to split TypeScript code into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "- First, specify ```Language.TS``` for the ```language``` parameter. It tells the splitter you're working with TypeScript code.\n",
    "- Then, set ```chunk_size``` to 60. This limits the size of each resulting chunk to a maximum of 60 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='function helloWorld(): void {'),\n",
       " Document(metadata={}, page_content='console.log(\"Hello, World!\");\\n}'),\n",
       " Document(metadata={}, page_content='helloWorld();')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TS_CODE = \"\"\"\n",
    "function helloWorld(): void {\n",
    "  console.log(\"Hello, World!\");\n",
    "}\n",
    "\n",
    "helloWorld();\n",
    "\"\"\"\n",
    "\n",
    "ts_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.TS, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "\n",
    "\n",
    "ts_docs = ts_splitter.create_documents([TS_CODE])\n",
    "ts_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown\n",
    "\n",
    "Here's how to split Markdown text into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "\n",
    "- First, Specify ```Language.MARKDOWN``` for the ```language``` parameter. It tells the splitter you're working with Markdown text.\n",
    "- Then, set ```chunk_size``` to 60. This limits the size of each resulting chunk to a maximum of 60 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='# ğŸ¦œï¸ğŸ”— LangChain'),\n",
       " Document(metadata={}, page_content='âš¡ Building applications with LLMs through composability âš¡'),\n",
       " Document(metadata={}, page_content='## What is LangChain?'),\n",
       " Document(metadata={}, page_content=\"# Hopefully this code block isn't split\"),\n",
       " Document(metadata={}, page_content='LangChain is a framework for...'),\n",
       " Document(metadata={}, page_content='As an open-source project in a rapidly developing field, we'),\n",
       " Document(metadata={}, page_content='are extremely open to contributions.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_text = \"\"\"\n",
    "# ğŸ¦œï¸ğŸ”— LangChain\n",
    "\n",
    "âš¡ Building applications with LLMs through composability âš¡\n",
    "\n",
    "## What is LangChain?\n",
    "\n",
    "# Hopefully this code block isn't split\n",
    "LangChain is a framework for...\n",
    "\n",
    "As an open-source project in a rapidly developing field, we are extremely open to contributions.\n",
    "\"\"\"\n",
    "\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN,\n",
    "    chunk_size=60,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "md_docs = md_splitter.create_documents([markdown_text])\n",
    "md_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LaTeX\n",
    "\n",
    "LaTeX is a markup language for document creation, widely used for representing mathematical symbols and formulas.\n",
    "\n",
    "Here's how to split LaTeX text into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "- First, specify ```Language.LATEX``` for the ```language``` parameter. It tells the splitter you're working with LaTeX text.\n",
    "- Then, set ```chunk_size``` to 60. This limits the size of each resulting chunk to a maximum of 60 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='\\\\documentclass{article}\\n\\n\\x08egin{document}\\n\\n\\\\maketitle'),\n",
       " Document(metadata={}, page_content='\\\\section{Introduction}\\nLarge language models (LLMs) are a'),\n",
       " Document(metadata={}, page_content='type of machine learning model that can be trained on vast'),\n",
       " Document(metadata={}, page_content='amounts of text data to generate human-like language. In'),\n",
       " Document(metadata={}, page_content='recent years, LLMs have made significant advances in a'),\n",
       " Document(metadata={}, page_content='variety of natural language processing tasks, including'),\n",
       " Document(metadata={}, page_content='language translation, text generation, and sentiment'),\n",
       " Document(metadata={}, page_content='analysis.'),\n",
       " Document(metadata={}, page_content='\\\\subsection{History of LLMs}\\nThe earliest LLMs were'),\n",
       " Document(metadata={}, page_content='developed in the 1980s and 1990s, but they were limited by'),\n",
       " Document(metadata={}, page_content='the amount of data that could be processed and the'),\n",
       " Document(metadata={}, page_content='computational power available at the time. In the past'),\n",
       " Document(metadata={}, page_content='decade, however, advances in hardware and software have'),\n",
       " Document(metadata={}, page_content='made it possible to train LLMs on massive datasets, leading'),\n",
       " Document(metadata={}, page_content='to significant improvements in performance.'),\n",
       " Document(metadata={}, page_content='\\\\subsection{Applications of LLMs}\\nLLMs have many'),\n",
       " Document(metadata={}, page_content='applications in industry, including chatbots, content'),\n",
       " Document(metadata={}, page_content='creation, and virtual assistants. They can also be used in'),\n",
       " Document(metadata={}, page_content='academia for research in linguistics, psychology, and'),\n",
       " Document(metadata={}, page_content='computational linguistics.\\n\\n\\\\end{document}')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latex_text = \"\"\"\n",
    "\\documentclass{article}\n",
    "\n",
    "\\begin{document}\n",
    "\n",
    "\\maketitle\n",
    "\n",
    "\\section{Introduction}\n",
    "Large language models (LLMs) are a type of machine learning model that can be trained on vast amounts of text data to generate human-like language. In recent years, LLMs have made significant advances in a variety of natural language processing tasks, including language translation, text generation, and sentiment analysis.\n",
    "\n",
    "\\subsection{History of LLMs}\n",
    "The earliest LLMs were developed in the 1980s and 1990s, but they were limited by the amount of data that could be processed and the computational power available at the time. In the past decade, however, advances in hardware and software have made it possible to train LLMs on massive datasets, leading to significant improvements in performance.\n",
    "\n",
    "\\subsection{Applications of LLMs}\n",
    "LLMs have many applications in industry, including chatbots, content creation, and virtual assistants. They can also be used in academia for research in linguistics, psychology, and computational linguistics.\n",
    "\n",
    "\\end{document}\n",
    "\"\"\"\n",
    "\n",
    "latex_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.LATEX,\n",
    "    chunk_size=60,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "latex_docs = latex_splitter.create_documents([latex_text])\n",
    "latex_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML\n",
    "\n",
    "Here's how to split HTML text into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "- First, specify ```Language.HTML``` for the ```language``` parameter. It tells the splitter you're working with HTML.\n",
    "- Then, set ```chunk_size``` to 60. This limits the size of each resulting chunk to a maximum of 60 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='<!DOCTYPE html>\\n<html>'),\n",
       " Document(metadata={}, page_content='<head>\\n        <title>ğŸ¦œï¸ğŸ”— LangChain</title>'),\n",
       " Document(metadata={}, page_content='<style>\\n            body {\\n                font-family: Aria'),\n",
       " Document(metadata={}, page_content='l, sans-serif;\\n            }\\n            h1 {'),\n",
       " Document(metadata={}, page_content='color: darkblue;\\n            }\\n        </style>\\n    </head'),\n",
       " Document(metadata={}, page_content='>'),\n",
       " Document(metadata={}, page_content='<body>'),\n",
       " Document(metadata={}, page_content='<div>\\n            <h1>ğŸ¦œï¸ğŸ”— LangChain</h1>'),\n",
       " Document(metadata={}, page_content='<p>âš¡ Building applications with LLMs through composability âš¡'),\n",
       " Document(metadata={}, page_content='</p>\\n        </div>'),\n",
       " Document(metadata={}, page_content='<div>\\n            As an open-source project in a rapidly dev'),\n",
       " Document(metadata={}, page_content='eloping field, we are extremely open to contributions.'),\n",
       " Document(metadata={}, page_content='</div>\\n    </body>\\n</html>')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_text = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "    <head>\n",
    "        <title>ğŸ¦œï¸ğŸ”— LangChain</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "            }\n",
    "            h1 {\n",
    "                color: darkblue;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div>\n",
    "            <h1>ğŸ¦œï¸ğŸ”— LangChain</h1>\n",
    "            <p>âš¡ Building applications with LLMs through composability âš¡</p>\n",
    "        </div>\n",
    "        <div>\n",
    "            As an open-source project in a rapidly developing field, we are extremely open to contributions.\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "html_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.HTML, chunk_size=60, chunk_overlap=0\n",
    ")\n",
    "\n",
    "html_docs = html_splitter.create_documents([html_text])\n",
    "html_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solidity\n",
    "\n",
    "Here's how to split Solidity code (sotred as a string in the ```SOL_CODE``` variable) into smaller chunks by creating a ```RecursiveCharacterTextSplitter``` instance called ```sol_splitter``` to handle the splitting.\n",
    "- First, specify ```Language.SOL``` for the ```language``` parameter. It tells the splitter you're working with Solidity code.\n",
    "- Then, set ```chunk_size``` to 128. This limits the size of each resulting chunk to a maximum of 128 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping.\n",
    "- The ```sol_splitter.create_documents()``` method splits the Solidity code(```SOL_CODE```) into chunks and stores them in the ```sol_docs``` variable.\n",
    "- Print or display the output(```sol_docs```) to verify the split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='pragma solidity ^0.8.20;'),\n",
       " Document(metadata={}, page_content='contract HelloWorld {  \\n   function add(uint a, uint b) pure public returns(uint) {\\n       return a + b;\\n   }\\n}')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOL_CODE = \"\"\"\n",
    "pragma solidity ^0.8.20; \n",
    "contract HelloWorld {  \n",
    "   function add(uint a, uint b) pure public returns(uint) {\n",
    "       return a + b;\n",
    "   }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "sol_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.SOL, chunk_size=128, chunk_overlap=0\n",
    ")\n",
    "\n",
    "sol_docs = sol_splitter.create_documents([SOL_CODE])\n",
    "sol_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C#\n",
    "\n",
    "Here's how to split C# code into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "- First, specify ```Language.CSHARP``` for the ```language``` parameter. It tells the splitter you're working with C# code.\n",
    "- Then, set ```chunk_size``` to 128. This limits the size of each resulting chunk to a maximum of 128 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='using System;'),\n",
       " Document(metadata={}, page_content='class Program\\n{\\n    static void Main()\\n    {\\n        Console.WriteLine(\"Enter a number (1-5):\");'),\n",
       " Document(metadata={}, page_content='int input = Convert.ToInt32(Console.ReadLine());\\n        for (int i = 1; i <= input; i++)\\n        {'),\n",
       " Document(metadata={}, page_content='if (i % 2 == 0)\\n            {\\n                Console.WriteLine($\"{i} is even.\");\\n            }\\n            else'),\n",
       " Document(metadata={}, page_content='{\\n                Console.WriteLine($\"{i} is odd.\");\\n            }\\n        }\\n        Console.WriteLine(\"Goodbye!\");'),\n",
       " Document(metadata={}, page_content='}\\n}')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_CODE = \"\"\"\n",
    "using System;\n",
    "class Program\n",
    "{\n",
    "    static void Main()\n",
    "    {\n",
    "        Console.WriteLine(\"Enter a number (1-5):\");\n",
    "        int input = Convert.ToInt32(Console.ReadLine());\n",
    "        for (int i = 1; i <= input; i++)\n",
    "        {\n",
    "            if (i % 2 == 0)\n",
    "            {\n",
    "                Console.WriteLine($\"{i} is even.\");\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "                Console.WriteLine($\"{i} is odd.\");\n",
    "            }\n",
    "        }\n",
    "        Console.WriteLine(\"Goodbye!\");\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "c_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.CSHARP, chunk_size=128, chunk_overlap=0\n",
    ")\n",
    "\n",
    "c_docs = c_splitter.create_documents([C_CODE])\n",
    "c_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHP\n",
    "\n",
    "Here's how to split PHP code into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "- First, specify ```Language.PHP``` for the ```language``` parameter. It tells the splitter you're working with PHP code.\n",
    "- Then, set ```chunk_size``` to 50. This limits the size of each resulting chunk to a maximum of 50 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='<?php\\nnamespace foo;'),\n",
       " Document(metadata={}, page_content='class Hello {'),\n",
       " Document(metadata={}, page_content='public function __construct() { }\\n}'),\n",
       " Document(metadata={}, page_content='function hello() {\\n    echo \"Hello World!\";\\n}'),\n",
       " Document(metadata={}, page_content='interface Human {\\n    public function breath();\\n}'),\n",
       " Document(metadata={}, page_content='trait Foo { }\\nenum Color\\n{\\n    case Red;'),\n",
       " Document(metadata={}, page_content='case Blue;\\n}')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PHP_CODE = \"\"\"<?php\n",
    "namespace foo;\n",
    "class Hello {\n",
    "    public function __construct() { }\n",
    "}\n",
    "function hello() {\n",
    "    echo \"Hello World!\";\n",
    "}\n",
    "interface Human {\n",
    "    public function breath();\n",
    "}\n",
    "trait Foo { }\n",
    "enum Color\n",
    "{\n",
    "    case Red;\n",
    "    case Blue;\n",
    "}\"\"\"\n",
    "\n",
    "php_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PHP, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "\n",
    "php_docs = php_splitter.create_documents([PHP_CODE])\n",
    "php_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kotlin\n",
    "\n",
    "Here's how to split Kotline code into smaller chunks using the ```RecursiveCharacterTextSplitter```.\n",
    "- First, specify ```Language.KOTLIN``` for the ```language``` parameter. It tells the splitter you're working with Kotline code.\n",
    "- Then, set ```chunk_size``` to 100. This limits the size of each resulting chunk to a maximum of 100 characters.\n",
    "- Finally, set ```chunk_overlap``` to 0. It prevents any of the chunks from overlapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='fun main() {\\n    val directoryPath = System.getProperty(\"user.dir\")'),\n",
       " Document(metadata={}, page_content='val files = File(directoryPath).listFiles()?.filter { !it.isDirectory }?.sortedBy {'),\n",
       " Document(metadata={}, page_content='it.lastModified() } ?: emptyArray()'),\n",
       " Document(metadata={}, page_content='files.forEach { file ->'),\n",
       " Document(metadata={}, page_content='println(\"Name: ${file.name} | Last Write Time: ${file.lastModified()}\")\\n    }\\n}')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KOTLIN_CODE = \"\"\"\n",
    "fun main() {\n",
    "    val directoryPath = System.getProperty(\"user.dir\")\n",
    "    val files = File(directoryPath).listFiles()?.filter { !it.isDirectory }?.sortedBy { it.lastModified() } ?: emptyArray()\n",
    "\n",
    "    files.forEach { file ->\n",
    "        println(\"Name: ${file.name} | Last Write Time: ${file.lastModified()}\")\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "kotlin_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.KOTLIN, chunk_size=100, chunk_overlap=0\n",
    ")\n",
    "\n",
    "kotlin_docs = kotlin_splitter.create_documents([KOTLIN_CODE])\n",
    "kotlin_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
