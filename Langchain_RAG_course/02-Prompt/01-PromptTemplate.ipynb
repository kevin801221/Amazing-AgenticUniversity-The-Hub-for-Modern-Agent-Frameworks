{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WM95b3r-VWtf"
   },
   "source": [
    "# 提示模板\n",
    "## 概述\n",
    "本教學涵蓋如何使用 ```LangChain``` 建立和使用提示模板。\n",
    "提示模板對於生成動態且靈活的提示至關重要，能夠滿足各種使用情境，如對話歷史記錄、結構化輸出和專門查詢。\n",
    "在本教學中，我們將探索建立 ```PromptTemplate``` 物件的方法、應用部分變數、透過 YAML 檔案管理模板，以及利用進階工具如 ```ChatPromptTemplate``` 和 ```MessagePlaceholder``` 來增強功能。\n",
    "\n",
    "### 目錄\n",
    "- [概述](#概述)\n",
    "- [環境設定](#環境設定)\n",
    "- [建立 PromptTemplate 物件](#建立prompttemplate物件)\n",
    "- [使用 partial_variables](#使用partial_variables)\n",
    "- [從 YAML 檔案載入提示模板](#從yaml檔案載入提示模板)\n",
    "- [ChatPromptTemplate](#chatprompttemplate)\n",
    "- [MessagePlaceholder](#messageplaceholder)\n",
    "\n",
    "### 參考資料\n",
    "- [LangChain Documentation : Prompts](https://python.langchain.com/api_reference/core/prompts.html#)\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "提示模板是 LangChain 生態系統的基礎組件，它讓開發者能夠建立可重用、動態的提示，大幅提高了 AI 應用開發的效率和一致性。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**提示模板的核心價值：**\n",
    "- **可重用性**：一次建立，多處使用，減少重複程式碼\n",
    "- **動態性**：支援變數替換，適應不同的輸入情境\n",
    "- **結構化**：清晰的模板結構便於維護和除錯\n",
    "- **標準化**：確保整個應用中提示的一致性\n",
    "\n",
    "**主要組件功能：**\n",
    "\n",
    "**PromptTemplate：**\n",
    "- 基礎的文字模板，支援變數插值\n",
    "- 適合簡單的單輪對話或查詢場景\n",
    "- 提供輸入驗證和格式化功能\n",
    "\n",
    "**partial_variables：**\n",
    "- 允許預設部分變數值\n",
    "- 適用於有固定元素的模板（如系統資訊、日期等）\n",
    "- 提高模板的靈活性和可配置性\n",
    "\n",
    "**YAML 檔案管理：**\n",
    "- 將提示邏輯與程式碼分離\n",
    "- 便於非技術人員編輯和維護\n",
    "- 支援版本控制和團隊協作\n",
    "\n",
    "**ChatPromptTemplate：**\n",
    "- 專為多輪對話設計\n",
    "- 支援系統、使用者、助手等不同角色\n",
    "- 更適合複雜的對話式 AI 應用\n",
    "\n",
    "**MessagePlaceholder：**\n",
    "- 動態插入訊息序列\n",
    "- 特別適合處理對話歷史記錄\n",
    "- 支援靈活的訊息結構\n",
    "\n",
    "**實際應用場景：**\n",
    "- **客服機器人**：標準化的問答模板\n",
    "- **內容生成**：部落格文章、產品描述等格式化內容\n",
    "- **資料分析**：結構化的分析報告模板\n",
    "- **教育應用**：個人化的學習內容生成\n",
    "\n",
    "**最佳實務建議：**\n",
    "- 設計模板時考慮變數的命名規範\n",
    "- 使用部分變數來設定常用的預設值\n",
    "- 將複雜的提示分解為可組合的子模板\n",
    "- 定期審查和優化模板的效果\n",
    "\n",
    "**進階技巧：**\n",
    "- 結合條件邏輯建立動態模板\n",
    "- 使用模板繼承減少重複程式碼\n",
    "- 實施模板版本管理和 A/B 測試\n",
    "- 建立模板庫以促進團隊共享\n",
    "\n",
    "提示模板是構建可維護、可擴展 AI 應用的關鍵工具，掌握其使用方法對於 LangChain 開發者來說至關重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKt2ztpAVWtg"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can check out the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mastmuM3VWtg",
    "outputId": "999b5939-1e97-4c82-e73f-e192132b91ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dg5i8oABVWth"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RuJxDRC8VWth",
    "outputId": "c82196d9-aa11-47e4-d388-325ea7cc3345"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkmwbFmEVWth",
    "outputId": "c3d94c7c-c51e-45ee-9c1d-9b3a1702c434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        # \"OPENAI_API_KEY\": \"\",\n",
    "        # \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"Prompt-Template\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xq2PGhaIVWth"
   },
   "source": [
    "Let's setup ```ChatOpenAI``` with ```gpt-4o``` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUByBq2jVWth"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Load the model\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7zSEwfReVWth"
   },
   "source": [
    "## 建立 ```PromptTemplate``` 物件\n",
    "有兩種方式可以建立 ```PromptTemplate``` 物件。\n",
    "- 1. 使用 ```from_template()``` 方法\n",
    "- 2. 一次性建立 ```PromptTemplate``` 物件和提示\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "這兩種建立方法提供了不同層次的靈活性，開發者可以根據具體需求選擇最適合的方式。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**方法一：```from_template()``` 方法**\n",
    "- **優點**：簡潔快速，適合簡單的模板建立\n",
    "- **適用場景**：原型開發、簡單應用、快速測試\n",
    "- **特點**：自動推斷變數，減少配置工作\n",
    "\n",
    "**範例應用：**\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 簡單直接的方式\n",
    "template = \"告訴我關於 {topic} 的 {details}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "```\n",
    "\n",
    "**方法二：完整物件建立**\n",
    "- **優點**：完全控制，支援進階配置\n",
    "- **適用場景**：複雜應用、需要詳細配置的模板\n",
    "- **特點**：明確指定輸入變數、輸出解析器等\n",
    "\n",
    "**範例應用：**\n",
    "```python\n",
    "# 完整配置的方式\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"details\"],\n",
    "    template=\"告訴我關於 {topic} 的 {details}\",\n",
    "    # 可以添加更多配置選項\n",
    "    validate_template=True\n",
    ")\n",
    "```\n",
    "\n",
    "**選擇建議：**\n",
    "- **快速原型**：使用 ```from_template()```\n",
    "- **生產環境**：考慮完整物件建立以獲得更好的控制\n",
    "- **團隊開發**：明確的變數定義有助於程式碼可讀性\n",
    "- **複雜邏輯**：需要額外配置時選擇完整建立方式\n",
    "\n",
    "**進階技巧：**\n",
    "- 結合兩種方法的優勢\n",
    "- 使用工廠模式管理不同類型的模板\n",
    "- 實施模板驗證和錯誤處理機制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4dEJad0VWti"
   },
   "source": [
    "### Method 1. Using the ```from_template()``` method\n",
    "\n",
    "- Define template with variable as ```{variable}``` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sczoqg3MVWti",
    "outputId": "e9cf2e4a-20ff-41aa-a714-a3302a20cbf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Define template. In this case, {country} is a variable\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a `PromptTemplate` object using the `from_template` method\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7h-ANwQLVWti"
   },
   "source": [
    "You can complete the prompt by assigning a value to the variable ```country``` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMABOGKAVWti",
    "outputId": "30840482-c8f3-4ad9-f67b-a248955484d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of United States of America?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt. Assign value to the variable using `format` method\n",
    "prompt = prompt.format(country=\"United States of America\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xMt4NVUeVWti"
   },
   "outputs": [],
   "source": [
    "# Define template\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a `PromptTemplate` object using the `from_template` method\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create chain\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zthz756JVWti",
    "outputId": "0d16a829-29cf-4cda-8780-36305a74c1a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of the United States of America is Washington, D.C.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the country variable with a value of your choice\n",
    "chain.invoke(\"United States of America\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GNlBHSnVWtj"
   },
   "source": [
    "### 方法二：一次性建立 ```PromptTemplate``` 物件和提示\n",
    "明確指定 ```input_variables``` 以進行額外驗證。\n",
    "否則，這些變數與模板字串中的變數不匹配可能會在實例化時引發異常。\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "明確指定 ```input_variables``` 是一個重要的最佳實務，它提供了額外的安全性和可讀性，特別是在複雜的生產環境中。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**```input_variables``` 的重要性：**\n",
    "\n",
    "**驗證機制：**\n",
    "- **變數一致性檢查**：確保模板中的變數與宣告的一致\n",
    "- **錯誤提前發現**：在實例化階段就捕獲問題，而非執行時\n",
    "- **型別安全**：提供更好的開發時檢查\n",
    "\n",
    "**範例說明：**\n",
    "```python\n",
    "# 正確的做法\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"level\"],\n",
    "    template=\"解釋 {topic} 給 {level} 程度的學習者\"\n",
    ")\n",
    "\n",
    "# 錯誤示範 - 變數不匹配\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],  # 遺漏了 'level'\n",
    "    template=\"解釋 {topic} 給 {level} 程度的學習者\"\n",
    "    # 這會引發 ValueError\n",
    ")\n",
    "```\n",
    "\n",
    "**常見錯誤類型：**\n",
    "- **遺漏變數**：模板中有變數但未在 input_variables 中宣告\n",
    "- **多餘變數**：input_variables 中有變數但模板中未使用\n",
    "- **變數名稱錯誤**：拼寫錯誤導致的不匹配\n",
    "\n",
    "**最佳實務建議：**\n",
    "- **始終明確宣告**：即使 LangChain 可以自動推斷\n",
    "- **使用描述性名稱**：讓變數用途一目了然\n",
    "- **文檔化複雜變數**：為複雜的變數添加註釋\n",
    "- **單元測試**：測試模板的各種輸入組合\n",
    "\n",
    "**進階配置選項：**\n",
    "```python\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"level\"],\n",
    "    template=\"解釋 {topic} 給 {level} 程度的學習者\",\n",
    "    validate_template=True,  # 啟用嚴格驗證\n",
    "    template_format=\"f-string\"  # 指定格式\n",
    ")\n",
    "```\n",
    "\n",
    "**除錯技巧：**\n",
    "- 檢查變數名稱的拼寫\n",
    "- 確認大括號語法正確\n",
    "- 使用 IDE 的語法高亮協助檢查\n",
    "- 建立測試案例驗證模板行為\n",
    "\n",
    "這種明確的方法雖然需要更多程式碼，但能大幅提高程式碼的可靠性和可維護性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEab7P_TVWtj",
    "outputId": "dae03376-67f5-4103-8425-603839b58afc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define template\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a prompt template with `PromptTemplate` object\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ks9koRitVWtj",
    "outputId": "4112eb8c-d3b3-4c02-dce8-65e827019ed4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of United States of America?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt\n",
    "prompt.format(country=\"United States of America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w830jCDLVWtj",
    "outputId": "7055cd10-1aba-4187-f4d2-a7a277155c17"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': 'United States of America'}, template='What are the capitals of {country1} and {country2}, respectively?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define template\n",
    "template = \"What are the capitals of {country1} and {country2}, respectively?\"\n",
    "\n",
    "# Create a prompt template with `PromptTemplate` object\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"country1\"],\n",
    "    partial_variables={\n",
    "        \"country2\": \"United States of America\"  # Pass `partial_variables` in dictionary form\n",
    "    },\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_uvJc3ZVWtj",
    "outputId": "aefca3b6-0c34-4f7d-f7e6-574f709c73fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the capitals of South Korea and United States of America, respectively?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country1=\"South Korea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4h0FD0xRVWtj",
    "outputId": "2fc6e068-451b-4a5e-f06c-3b33f4e8da55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': 'India'}, template='What are the capitals of {country1} and {country2}, respectively?')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial = prompt.partial(country2=\"India\")\n",
    "prompt_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7o8yi9zPVWtj",
    "outputId": "fef468c8-fdbc-4a9a-8fcb-e1280bcbff30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the capitals of South Korea and India, respectively?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_partial.format(country1=\"South Korea\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "29NKYVr2VWtj"
   },
   "outputs": [],
   "source": [
    "chain = prompt_partial | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a_X9Ul9jVWtj",
    "outputId": "197a6482-26f1-4d95-9d65-0c3660a4be7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of the United States of America is Washington, D.C., and the capital of India is New Delhi.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"United States of America\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZMM3zB6VWtk",
    "outputId": "759c6ab7-75fc-47a2-ba0a-62c976e791bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of the United States of America is Washington, D.C., and the capital of India is New Delhi.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country1\": \"United States of America\", \"country2\": \"India\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTkvrjSfVWtk"
   },
   "source": [
    "## 使用 ```partial_variables```\n",
    "使用 ```partial_variables```，您可以部分應用函式。這在有**共用變數**需要分享時特別有用。\n",
    "常見的範例是**日期或時間**。\n",
    "假設您想在提示中指定當前日期，將日期硬編碼到提示中或與其他輸入變數一起傳遞可能不太實用。在這種情況下，使用返回當前日期的函式來部分修改提示會更加方便。\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "```partial_variables``` 是提示模板中非常實用的功能，它解決了動態值（如時間、系統資訊）與靜態模板結合的問題，大幅提升了模板的靈活性和實用性。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**```partial_variables``` 的核心價值：**\n",
    "\n",
    "**動態內容處理：**\n",
    "- **時間資訊**：當前日期、時間戳、時區資訊\n",
    "- **系統資訊**：用戶 ID、會話 ID、應用版本\n",
    "- **上下文資訊**：地理位置、語言設定、權限級別\n",
    "\n",
    "**使用方式：**\n",
    "```python\n",
    "from datetime import datetime\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def get_current_date():\n",
    "    return datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# 使用函式作為部分變數\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"task\"],\n",
    "    template=\"今天是 {date}，請幫我完成以下任務：{task}\",\n",
    "    partial_variables={\"date\": get_current_date}\n",
    ")\n",
    "\n",
    "# 或者使用固定值\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=\"系統版本：{version}\\n用戶查詢：{query}\",\n",
    "    partial_variables={\"version\": \"v2.1.0\"}\n",
    ")\n",
    "```\n",
    "\n",
    "**實際應用場景：**\n",
    "\n",
    "**商業應用：**\n",
    "- **報告生成**：自動插入報告日期和時間\n",
    "- **個人化內容**：根據用戶資訊客製化訊息\n",
    "- **合規要求**：自動記錄操作時間和版本資訊\n",
    "\n",
    "**技術應用：**\n",
    "- **日誌記錄**：統一的時間戳格式\n",
    "- **API 文檔**：動態插入當前 API 版本\n",
    "- **測試環境**：區分不同環境的配置資訊\n",
    "\n",
    "**進階技巧：**\n",
    "\n",
    "**條件式部分變數：**\n",
    "```python\n",
    "def get_greeting():\n",
    "    hour = datetime.now().hour\n",
    "    if hour < 12:\n",
    "        return \"早安\"\n",
    "    elif hour < 18:\n",
    "        return \"午安\"\n",
    "    else:\n",
    "        return \"晚安\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"name\"],\n",
    "    template=\"{greeting}，{name}！有什麼我可以幫助您的嗎？\",\n",
    "    partial_variables={\"greeting\": get_greeting}\n",
    ")\n",
    "```\n",
    "\n",
    "**組合多個部分變數：**\n",
    "```python\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "    時間：{timestamp}\n",
    "    系統：{system_info}\n",
    "    用戶問題：{question}\n",
    "    \n",
    "    請根據上述資訊提供回答。\n",
    "    \"\"\",\n",
    "    partial_variables={\n",
    "        \"timestamp\": lambda: datetime.now().isoformat(),\n",
    "        \"system_info\": lambda: \"AI助手 v3.0\"\n",
    "    }\n",
    ")\n",
    "```\n",
    "\n",
    "**最佳實務建議：**\n",
    "- **快取機制**：對於成本較高的函式，考慮添加快取\n",
    "- **錯誤處理**：確保部分變數函式的健壯性\n",
    "- **性能考量**：避免在部分變數中執行耗時操作\n",
    "- **測試覆蓋**：為部分變數函式建立單元測試\n",
    "\n",
    "**常見陷阱與解決方案：**\n",
    "- **時區問題**：確保時間函式使用正確的時區\n",
    "- **格式一致性**：統一日期時間格式\n",
    "- **函式純度**：避免副作用，確保函式的可預測性\n",
    "\n",
    "```partial_variables``` 讓模板變得更加動態和智能，是建立專業級 AI 應用的重要工具。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTxKYu_HVWtk",
    "outputId": "7bd395a8-c23d-40ea-8b29-eb0d22675e9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'January 14'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Print the current date\n",
    "datetime.now().strftime(\"%B %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvlXGtH7VWtk"
   },
   "outputs": [],
   "source": [
    "# Define function to return the current date\n",
    "def get_today():\n",
    "    return datetime.now().strftime(\"%B %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pi0uC_LbVWtk"
   },
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Today's date is {today}. Please list {n} celebrities whose birthday is today. Please specify their date of birth.\",\n",
    "    input_variables=[\"n\"],\n",
    "    partial_variables={\n",
    "        \"today\": get_today  # Pass `partial_variables` in dictionary form\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hn05msxVWtk",
    "outputId": "36756856-84bd-467f-89b6-f9dbe17c51b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is January 14. Please list 3 celebrities whose birthday is today. Please specify their date of birth.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create prompt\n",
    "prompt.format(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ka3WXlgBVWtk"
   },
   "outputs": [],
   "source": [
    "# Create chain\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JMoyt88DVWtk",
    "outputId": "2a1891d6-f5a7-4e7d-bfa0-d30b4dd03fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three celebrities born on January 14:\n",
      "\n",
      "1. **Dave Grohl** - Born on January 14, 1969.\n",
      "2. **LL Cool J** - Born on January 14, 1968.\n",
      "3. **Jason Bateman** - Born on January 14, 1969.\n"
     ]
    }
   ],
   "source": [
    "# Invoke chain and check the result\n",
    "print(chain.invoke(3).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4SDB_BPVWtk",
    "outputId": "e50b160f-c363-4c66-c1ef-bf53436f526b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three celebrities born on January 2:\n",
      "\n",
      "1. **Cuba Gooding Jr.** - Born on January 2, 1968.\n",
      "2. **Taye Diggs** - Born on January 2, 1971.\n",
      "3. **Kate Bosworth** - Born on January 2, 1983.\n"
     ]
    }
   ],
   "source": [
    "# Invoke chain and check the result\n",
    "print(chain.invoke({\"today\": \"Jan 02\", \"n\": 3}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxSTXp6bVWtk"
   },
   "source": [
    "## Load Prompt Templates from YAML Files\n",
    "\n",
    "You can manage prompt templates in seperate yaml files and load using ```load_prompt``` ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQG6geJ-VWtl",
    "outputId": "1a292d51-df2f-4e9c-855b-0e3a30da4674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['fruit'], input_types={}, partial_variables={}, template='What is the color of {fruit}?')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"prompts/fruit_color.yaml\", encoding=\"utf-8\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OG5T9A6qVWtm",
    "outputId": "88b9398b-5f46-4b9c-b3e0-34ee33ad3148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the color of an apple?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(fruit=\"an apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9KHxOvpVWtm",
    "outputId": "441fbca1-1651-41a1-b07e-e1c918d57059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide information about the capital city of United States of America.\n",
      "Summarize the characteristics of the capital in the following format, within 300 words.\n",
      "----\n",
      "[Format]\n",
      "1. Area\n",
      "2. Population\n",
      "3. Historical Sites\n",
      "4. Regional Products\n",
      "\n",
      "#Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt2 = load_prompt(\"prompts/capital.yaml\")\n",
    "print(prompt2.format(country=\"United States of America\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUC1vLXsVWtm"
   },
   "source": [
    "## ```ChatPromptTemplate```\n",
    "```ChatPromptTemplate``` 可用於將對話歷史記錄包含為提示。\n",
    "訊息以元組格式 (```role```, ```message```) 結構化，並建立為清單。\n",
    "**角色**\n",
    "- ```system```：系統設定訊息，通常用於全域設定相關的提示。\n",
    "- ```human```：使用者輸入訊息。\n",
    "- ```ai```：AI 回應訊息。\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "```ChatPromptTemplate``` 是處理多輪對話的強大工具，它提供了結構化的方式來管理不同角色的訊息，這對於建立自然且上下文感知的對話系統至關重要。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**```ChatPromptTemplate``` 的核心優勢：**\n",
    "\n",
    "**角色區分系統：**\n",
    "- **清晰的對話結構**：明確區分不同參與者的訊息\n",
    "- **上下文保持**：維持完整的對話歷史記錄\n",
    "- **角色一致性**：確保每個角色的特性和行為一致\n",
    "\n",
    "**三種核心角色詳解：**\n",
    "\n",
    "**```system``` 角色：**\n",
    "```python\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 系統角色設定 AI 的行為和個性\n",
    "messages = [\n",
    "    (\"system\", \"你是一個專業的程式設計導師，請用清晰易懂的方式回答問題。\"),\n",
    "    (\"human\", \"什麼是遞迴？\"),\n",
    "    (\"ai\", \"遞迴是一種程式設計技巧...\"),\n",
    "    (\"human\", \"可以給我一個範例嗎？\")\n",
    "]\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "```\n",
    "\n",
    "**```human``` 角色：**\n",
    "- 代表使用者的輸入和查詢\n",
    "- 可以包含問題、指令或對話內容\n",
    "- 通常是觸發 AI 回應的起點\n",
    "\n",
    "**```ai``` 角色：**\n",
    "- 代表 AI 助手的回應\n",
    "- 用於建立對話歷史記錄\n",
    "- 提供上下文供後續互動參考\n",
    "\n",
    "**實際應用模式：**\n",
    "\n",
    "**客服對話系統：**\n",
    "```python\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一個客服代表，友善且專業地幫助客戶解決問題。\"),\n",
    "    (\"human\", \"我的訂單還沒收到\"),\n",
    "    (\"ai\", \"很抱歉聽到這個問題，讓我幫您查詢訂單狀態。\"),\n",
    "    (\"human\", \"訂單號碼是 {order_number}\")\n",
    "])\n",
    "```\n",
    "\n",
    "**教育輔導系統：**\n",
    "```python\n",
    "education_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一位耐心的數學老師，用循序漸進的方式教學。\"),\n",
    "    (\"human\", \"我不懂二次方程式\"),\n",
    "    (\"ai\", \"沒關係，我們從基礎開始學習...\"),\n",
    "    (\"human\", \"{new_question}\")\n",
    "])\n",
    "```\n",
    "\n",
    "**動態對話建構：**\n",
    "```python\n",
    "def build_chat_history(conversation_history, new_message):\n",
    "    messages = [(\"system\", \"你是一個有用的助手\")]\n",
    "    \n",
    "    # 添加歷史對話\n",
    "    for turn in conversation_history:\n",
    "        messages.append((\"human\", turn[\"user\"]))\n",
    "        messages.append((\"ai\", turn[\"assistant\"]))\n",
    "    \n",
    "    # 添加新訊息\n",
    "    messages.append((\"human\", new_message))\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages(messages)\n",
    "```\n",
    "\n",
    "**進階技巧：**\n",
    "\n",
    "**條件式訊息：**\n",
    "```python\n",
    "def create_conditional_chat(user_type, query):\n",
    "    if user_type == \"expert\":\n",
    "        system_msg = \"請提供技術深度的專業回答\"\n",
    "    else:\n",
    "        system_msg = \"請用簡單易懂的方式回答\"\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_msg),\n",
    "        (\"human\", query)\n",
    "    ])\n",
    "```\n",
    "\n",
    "**模板變數整合：**\n",
    "```python\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是專精於 {domain} 的專家\"),\n",
    "    (\"human\", \"關於 {topic} 的問題：{question}\")\n",
    "])\n",
    "\n",
    "# 使用時填入變數\n",
    "formatted = chat_template.format_messages(\n",
    "    domain=\"機器學習\",\n",
    "    topic=\"神經網路\",\n",
    "    question=\"什麼是反向傳播？\"\n",
    ")\n",
    "```\n",
    "\n",
    "**最佳實務建議：**\n",
    "- **角色一致性**：確保每個角色的語調和風格一致\n",
    "- **適當的系統提示**：清楚定義 AI 的行為和限制\n",
    "- **對話長度管理**：避免對話歷史過長影響效能\n",
    "- **上下文相關性**：只保留與當前對話相關的歷史記錄\n",
    "\n",
    "```ChatPromptTemplate``` 是建立高品質對話系統的基礎工具，它讓開發者能夠創建更自然、更有上下文感知能力的 AI 互動體驗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4c6f5MRVWtm",
    "outputId": "aee66d58-f612-4f22-c2fe-d7eaa3fe969a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?'), additional_kwargs={})])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RmTAL202VWtm",
    "outputId": "4ed3c229-a38c-4786-9322-ef7a5ac624ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What is the capital of United States of America?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.format(country=\"United States of America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Po4s4E2VWtm",
    "outputId": "6a2915c5-41c4-4969-eee5-9e4ea0e0b0ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a friendly AI assistant. Your name is Teddy.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Nice to meet you!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"You are a friendly AI assistant. Your name is {name}.\"),\n",
    "        (\"human\", \"Nice to meet you!\"),\n",
    "        (\"ai\", \"Hello! How can I assist you?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create chat messages\n",
    "messages = chat_template.format_messages(name=\"Teddy\", user_input=\"What is your name?\")\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q47shXh-VWtm"
   },
   "source": [
    "You can directly invoke LLM using the messages created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bjjLw1WlVWtn",
    "outputId": "dc09aa96-8d69-4308-8540-868353dc2e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Teddy. How can I help you today?'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTMKtF2kVWtn"
   },
   "source": [
    "You can also create a chain to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5A2JtS5OVWtn"
   },
   "outputs": [],
   "source": [
    "chain = chat_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MhPHZZXVVWtn",
    "outputId": "a53c2333-147a-4ce2-a25d-c728595db9ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My name is Teddy. How can I help you today?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"name\": \"Teddy\", \"user_input\": \"What is your name?\"}).content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJJgeuYbVWtn"
   },
   "source": [
    "## ```ChatPromptTemplate```\n",
    "```ChatPromptTemplate``` 可用於將對話歷史記錄包含為提示。\n",
    "訊息以元組格式 (```role```, ```message```) 結構化，並建立為清單。\n",
    "**角色**\n",
    "- ```system```：系統設定訊息，通常用於全域設定相關的提示。\n",
    "- ```human```：使用者輸入訊息。\n",
    "- ```ai```：AI 回應訊息。\n",
    "\n",
    "---\n",
    "\n",
    "## 我的見解\n",
    "\n",
    "```ChatPromptTemplate``` 是處理多輪對話的強大工具，它提供了結構化的方式來管理不同角色的訊息，這對於建立自然且上下文感知的對話系統至關重要。\n",
    "\n",
    "## 學習補充重點\n",
    "\n",
    "**```ChatPromptTemplate``` 的核心優勢：**\n",
    "\n",
    "**角色區分系統：**\n",
    "- **清晰的對話結構**：明確區分不同參與者的訊息\n",
    "- **上下文保持**：維持完整的對話歷史記錄\n",
    "- **角色一致性**：確保每個角色的特性和行為一致\n",
    "\n",
    "**三種核心角色詳解：**\n",
    "\n",
    "**```system``` 角色：**\n",
    "```python\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# 系統角色設定 AI 的行為和個性\n",
    "messages = [\n",
    "    (\"system\", \"你是一個專業的程式設計導師，請用清晰易懂的方式回答問題。\"),\n",
    "    (\"human\", \"什麼是遞迴？\"),\n",
    "    (\"ai\", \"遞迴是一種程式設計技巧...\"),\n",
    "    (\"human\", \"可以給我一個範例嗎？\")\n",
    "]\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(messages)\n",
    "```\n",
    "\n",
    "**```human``` 角色：**\n",
    "- 代表使用者的輸入和查詢\n",
    "- 可以包含問題、指令或對話內容\n",
    "- 通常是觸發 AI 回應的起點\n",
    "\n",
    "**```ai``` 角色：**\n",
    "- 代表 AI 助手的回應\n",
    "- 用於建立對話歷史記錄\n",
    "- 提供上下文供後續互動參考\n",
    "\n",
    "**實際應用模式：**\n",
    "\n",
    "**客服對話系統：**\n",
    "```python\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一個客服代表，友善且專業地幫助客戶解決問題。\"),\n",
    "    (\"human\", \"我的訂單還沒收到\"),\n",
    "    (\"ai\", \"很抱歉聽到這個問題，讓我幫您查詢訂單狀態。\"),\n",
    "    (\"human\", \"訂單號碼是 {order_number}\")\n",
    "])\n",
    "```\n",
    "\n",
    "**教育輔導系統：**\n",
    "```python\n",
    "education_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是一位耐心的數學老師，用循序漸進的方式教學。\"),\n",
    "    (\"human\", \"我不懂二次方程式\"),\n",
    "    (\"ai\", \"沒關係，我們從基礎開始學習...\"),\n",
    "    (\"human\", \"{new_question}\")\n",
    "])\n",
    "```\n",
    "\n",
    "**動態對話建構：**\n",
    "```python\n",
    "def build_chat_history(conversation_history, new_message):\n",
    "    messages = [(\"system\", \"你是一個有用的助手\")]\n",
    "    \n",
    "    # 添加歷史對話\n",
    "    for turn in conversation_history:\n",
    "        messages.append((\"human\", turn[\"user\"]))\n",
    "        messages.append((\"ai\", turn[\"assistant\"]))\n",
    "    \n",
    "    # 添加新訊息\n",
    "    messages.append((\"human\", new_message))\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages(messages)\n",
    "```\n",
    "\n",
    "**進階技巧：**\n",
    "\n",
    "**條件式訊息：**\n",
    "```python\n",
    "def create_conditional_chat(user_type, query):\n",
    "    if user_type == \"expert\":\n",
    "        system_msg = \"請提供技術深度的專業回答\"\n",
    "    else:\n",
    "        system_msg = \"請用簡單易懂的方式回答\"\n",
    "    \n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        (\"system\", system_msg),\n",
    "        (\"human\", query)\n",
    "    ])\n",
    "```\n",
    "\n",
    "**模板變數整合：**\n",
    "```python\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你是專精於 {domain} 的專家\"),\n",
    "    (\"human\", \"關於 {topic} 的問題：{question}\")\n",
    "])\n",
    "\n",
    "# 使用時填入變數\n",
    "formatted = chat_template.format_messages(\n",
    "    domain=\"機器學習\",\n",
    "    topic=\"神經網路\",\n",
    "    question=\"什麼是反向傳播？\"\n",
    ")\n",
    "```\n",
    "\n",
    "**最佳實務建議：**\n",
    "- **角色一致性**：確保每個角色的語調和風格一致\n",
    "- **適當的系統提示**：清楚定義 AI 的行為和限制\n",
    "- **對話長度管理**：避免對話歷史過長影響效能\n",
    "- **上下文相關性**：只保留與當前對話相關的歷史記錄\n",
    "\n",
    "```ChatPromptTemplate``` 是建立高品質對話系統的基礎工具，它讓開發者能夠創建更自然、更有上下文感知能力的 AI 互動體驗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6F5iOExVWtn",
    "outputId": "46f0ce54-9c63-4e00-dec4-e6b5444b6aa3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000020B148D7E20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a summarization specialist AI assistant. Your mission is to summarize conversations using key points.'), additional_kwargs={}), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='Summarize the conversation so far in {word_count} words.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a summarization specialist AI assistant. Your mission is to summarize conversations using key points.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"Summarize the conversation so far in {word_count} words.\"),\n",
    "    ]\n",
    ")\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itsH3zbHVWtn"
   },
   "source": [
    "You can use ```MessagesPlaceholder``` to add the conversation message list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GaTnMy-VVWtn",
    "outputId": "48f53a77-2d02-47a0-e531-f9d7b8b7bb17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a summarization specialist AI assistant. Your mission is to summarize conversations using key points.\n",
      "Human: Hello! I’m Teddy. Nice to meet you.\n",
      "AI: Nice to meet you! I look forward to working with you.\n",
      "Human: Summarize the conversation so far in 5 words.\n"
     ]
    }
   ],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=5,\n",
    "    conversation=[\n",
    "        (\"human\", \"Hello! I’m Teddy. Nice to meet you.\"),\n",
    "        (\"ai\", \"Nice to meet you! I look forward to working with you.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(formatted_chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_a5JWWVrVWto"
   },
   "outputs": [],
   "source": [
    "# Create chain\n",
    "chain = chat_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PI2lZShPVWto",
    "outputId": "a30ee0f2-9e56-4ba4-ad60-97f42551d151"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Teddy introduces himself, exchanges greetings.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke chain and check the result\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 5,\n",
    "        \"conversation\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"Hello! I'm Teddy. Nice to meet you.\",\n",
    "            ),\n",
    "            (\"ai\", \"Nice to meet you! I look forward to working with you.\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
