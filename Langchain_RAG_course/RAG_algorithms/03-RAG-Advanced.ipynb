{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b82288e",
   "metadata": {
    "id": "6b82288e"
   },
   "source": [
    "# Exploring RAG in LangChain\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/12-RAG/03-RAG-Advanced.ipynb)[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/12-RAG/03-RAG-Advanced.ipynb)\n",
    "![rag-1.png](./assets/12-rag-rag-basic-pdf-rag-process-01.png)\n",
    "\n",
    "![rag-2.png](./assets/12-rag-rag-basic-pdf-rag-process-02.png)\n",
    "\n",
    "## OverView\n",
    "\n",
    "This tutorial explores the entire process of indexing, retrieval, and generation using LangChain's RAG framework. It provides a broad overview of a typical RAG application pipeline and demonstrates how to effectively retrieve and generate responses by using LangChain's key features, such as data loaders, vector databases, embedding, retrievers, and generators, structured in a modular design.\n",
    "\n",
    "### 1. Question Processing\n",
    "\n",
    "The question processing stage involves receiving a user's question, handling it, and finding relevant data. The following components are required for this process:\n",
    "\n",
    "- **Data Source Connection**\n",
    "To find answers to the question, it is necessary to connect to various text data sources. LangChain helps you easily establish connections to various data sources.\n",
    "- **Data Indexing and Retrieval**\n",
    "To efficiently find relevant information from data sources, the data must be indexed. LangChain automates the indexing process and provides tools to retrieve data related to the user's question.\n",
    "\n",
    "\n",
    "### 2. Answer Generation\n",
    "\n",
    "Once the relevant data is found, the next step is to generate an answer based on it. The following components are essential for this stage:\n",
    "\n",
    "- **Answer Generation Model**\n",
    "LangChain uses advanced natural language processing (NLP) models to generate answers from the retrieved data. These models take the user's question and the retrieved data as input and generate an appropriate answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d6f1b5",
   "metadata": {
    "id": "66d6f1b5"
   },
   "source": [
    "## 架構\n",
    "\n",
    "本教程將建立一個典型的 RAG 應用程式，如 [Q&A 介紹](https://python.langchain.com/docs/tutorials/) 中所述。這包含兩個主要組件：\n",
    "\n",
    "- **索引** : 從來源收集數據並建立索引的管道。_此過程通常離線進行。_\n",
    "\n",
    "- **檢索和生成** : 實際的 RAG 鏈即時處理用戶查詢，從索引中檢索相關數據，並將其傳遞給模型。\n",
    "\n",
    "從原始數據到生成答案的整個工作流程如下：\n",
    "\n",
    "### 索引\n",
    "\n",
    "![](https://python.langchain.com/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png)\n",
    "\n",
    "- 索引圖片來源: https://python.langchain.com/docs/tutorials/rag/\n",
    "\n",
    "1. **載入** : 第一步是載入數據。為此，我們將使用 [文檔載入器](https://python.langchain.com/docs/integrations/document_loaders/)。\n",
    "\n",
    "2. **分割** : [文本分割器](https://python.langchain.com/docs/concepts/text_splitters/) 將大型 ```Documents``` 分割成較小的塊。\n",
    "這對於數據索引和傳遞給模型很有用，因為大塊可能難以檢索，且可能不適合模型有限的上下文窗口。\n",
    "\n",
    "3. **存儲** : 分割的數據需要存儲並索引在某個位置以供未來檢索。這通常使用 [向量存儲](https://python.langchain.com/docs/concepts/vectorstores/) 和 [嵌入](https://python.langchain.com/docs/integrations/text_embedding/) 模型來完成。\n",
    "\n",
    "### 檢索和生成\n",
    "\n",
    "![](https://python.langchain.com/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png)\n",
    "\n",
    "- 檢索和生成圖片來源: https://python.langchain.com/docs/tutorials/rag/\n",
    "\n",
    "1. **檢索** : 當提供用戶輸入時，使用 [檢索器](https://python.langchain.com/docs/integrations/retrievers/) 從數據存儲中檢索相關塊。\n",
    "\n",
    "2. **生成** : [聊天模型](https://python.langchain.com/docs/integrations/chat/) / [LLM](https://python.langchain.com/docs/integrations/llms/) 使用包含問題和檢索數據的提示生成答案。\n",
    "\n",
    "**架構詳細說明：**\n",
    "\n",
    "### RAG 系統的核心優勢\n",
    "\n",
    "**1. 知識更新能力**\n",
    "- 無需重新訓練模型即可更新知識庫\n",
    "- 支援即時添加新文檔和信息\n",
    "- 避免模型知識截止日期的限制\n",
    "\n",
    "**2. 可追溯性和可解釋性**\n",
    "- 每個答案都可以追溯到具體的來源文檔\n",
    "- 用戶可以驗證答案的準確性和可靠性\n",
    "- 提供透明的推理過程\n",
    "\n",
    "**3. 領域特化**\n",
    "- 可以針對特定領域或企業知識進行優化\n",
    "- 支援私有數據和專業內容\n",
    "- 保持領域專業性和準確性\n",
    "\n",
    "### 技術實現細節\n",
    "\n",
    "**索引階段的關鍵考量：**\n",
    "- **數據品質**：清理和預處理原始文檔\n",
    "- **分塊策略**：平衡信息完整性和檢索效率\n",
    "- **向量化**：選擇適合的嵌入模型和參數\n",
    "\n",
    "**檢索階段的優化：**\n",
    "- **相似性搜尋**：基於語義相似性找到最相關的內容\n",
    "- **重排序**：進一步優化檢索結果的相關性\n",
    "- **上下文管理**：控制傳遞給生成模型的信息量\n",
    "\n",
    "這種架構設計確保了 RAG 系統既能利用大型語言模型的生成能力，又能提供準確、可靠的領域知識。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf05522",
   "metadata": {
    "id": "1cf05522"
   },
   "source": [
    "## 練習使用的文檔\n",
    "\n",
    "歐洲人工智能方法 - 政策觀點\n",
    "\n",
    "- 作者：數位啟蒙論壇在 EIT Digital 指導下，並獲得 EIT Manufacturing、EIT Urban Mobility、EIT Health 和 EIT Climate-KIC 的貢獻支持\n",
    "- 連結：https://eit.europa.eu/news-events/news/european-approach-artificial-intelligence-policy-perspective\n",
    "- 檔案名稱：**A European Approach to Artificial Intelligence - A Policy Perspective.pdf**\n",
    "\n",
    "_請將下載的檔案複製到 **data** 資料夾中進行練習。_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f999535",
   "metadata": {
    "id": "1f999535"
   },
   "source": [
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Document Used for Practice](#document-used-for-practice)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Explore Each Module](#explore-each-module)\n",
    "- [Step 1: Load Document](#step-1:-load-document)\n",
    "- [Step 2: Split Documents](#step-2:-split-documents)\n",
    "- [Step 3: Embedding](#step-3:-embedding)\n",
    "- [Step 4: Create Vectorstore](#step-4-create-vectorstore)\n",
    "- [Step 5: Create Retriever ](#step-5-create-retriever)\n",
    "- [Step 6: Create Prompt](#step-6-create-prompt)\n",
    "- [Step 7: Create LLM](#step-7-create-llm)\n",
    "\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain: Document Loaders](https://python.langchain.com/docs/integrations/document_loaders/)\n",
    "- [LangChain: Text splitters](https://python.langchain.com/docs/concepts/text_splitters/)\n",
    "- [LangChain: Vector Store](https://python.langchain.com/docs/concepts/vectorstores/)\n",
    "- [LangChain: Embeddings](https://python.langchain.com/docs/integrations/text_embedding/)\n",
    "- [LangChain: Retriever](https://python.langchain.com/docs/integrations/retrievers/)\n",
    "- [LangChain: Chat Models](https://python.langchain.com/docs/integrations/chat/)\n",
    "- [LangChain: LLM](https://python.langchain.com/docs/integrations/llms/)\n",
    "- [Langchain: Indexing](https://python.langchain.com/docs/tutorials/rag/)\n",
    "- [Langchain: Retrieval and Generation](https://python.langchain.com/docs/tutorials/rag/)\n",
    "- [Semantic Similarity Splitter](https://python.langchain.com/api_reference/experimental/text_splitter/langchain_experimental.text_splitter.SemanticChunker.html)\n",
    "- [OpenAI API Model List / Pricing](https://openai.com/api/pricing/)\n",
    "- [HuggingFace LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f12ae2",
   "metadata": {
    "id": "52f12ae2"
   },
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bcdd777",
   "metadata": {
    "id": "9bcdd777"
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "719a762f",
   "metadata": {
    "id": "719a762f"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"bs4\",\n",
    "        \"faiss-cpu\",\n",
    "        \"pypdf\",\n",
    "        \"pypdf2\"\n",
    "        \"unstructured\",\n",
    "        \"unstructured[pdf]\",\n",
    "        \"fastembed\",\n",
    "        \"chromadb\",\n",
    "        \"rank_bm25\",\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_experimental\"\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "418ab505",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "418ab505",
    "outputId": "430008eb-38b9-4180-e1bd-98f8ceca2481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"HUGGINGFACEHUB_API_TOKEN\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"03-RAG-Advanced\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3314b553",
   "metadata": {
    "id": "3314b553"
   },
   "source": [
    "Environment variables have been set successfully.\n",
    "You can alternatively set API keys, such as ```OPENAI_API_KEY``` in a ```.env``` file and load them.\n",
    "\n",
    "[Note] This is not necessary if you've already set the required API keys in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f1b1f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33f1b1f8",
    "outputId": "e099e555-38db-42a2-bebd-032c66e14941"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load API keys from .env file\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d050a",
   "metadata": {
    "id": "9b0d050a"
   },
   "source": [
    "## Explore Each Module\n",
    "The following are the modules used in this content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d1b0fc",
   "metadata": {
    "id": "f3d1b0fc"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e783c4",
   "metadata": {
    "id": "48e783c4"
   },
   "source": [
    "以下是使用基本 RAG 模型處理網頁（```WebBaseLoader```）的範例。\n",
    "\n",
    "在每個步驟中，您都可以配置各種選項或應用新技術。\n",
    "如果在使用 ```WebBaseLoader``` 時由於未設定 ```USER_AGENT``` 而顯示警告，\n",
    "\n",
    "請在 ```.env``` 檔案中添加 ```USER_AGENT = myagent```。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "377894c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "377894c9",
    "outputId": "4c28b236-4f73-49e5-a74e-a19850c33f68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/\n",
      "Number of documents: 1\n",
      "============================================================\n",
      "[HUMAN]\n",
      "Why did OpenAI and Scarlett Johansson have a conflict?\n",
      "\n",
      "[AI]\n",
      "Scarlett Johansson and OpenAI had a conflict over a voice for ChatGPT that sounded similar to her own, which she claimed was created without her consent. After declining an offer to voice the AI, Johansson expressed shock and anger when the voice was used in a demo shortly thereafter. Her lawyers demanded details on the voice's creation and requested its removal, while OpenAI stated it was not an imitation of her voice.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Documents\n",
    "# Load the contents of news articles, split them into chunks, and index them.\n",
    "url = \"https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/\"\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(url,),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"div\",\n",
    "            attrs={\"class\": [\"article-body fs-article fs-premium fs-responsive-text current-article font-body color-body bg-base font-accent article-subtype__masthead\",\n",
    "                             \"header-content-container masthead-header__container\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "# Step 2: Split Documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Step 3: Embedding & Create Vectorstore\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "\n",
    "# Step 4: retriever\n",
    "# Retrieve and generate information contained in the news.\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Step 5: Create Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Step 6: Create LLM\n",
    "# Generate the language model (LLM).\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # Combine the retrieved document results into a single paragraph.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Create Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Step 8: Run Chain\n",
    "# Input queries about the documents and output answers.\n",
    "question = \"Why did OpenAI and Scarlett Johansson have a conflict?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# output the results.\n",
    "print(f\"URL: {url}\")\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7972a13e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7972a13e",
    "outputId": "f6799d2e-b405-4823-c757-f5a683c3636a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/'}, page_content=\"ForbesInnovationEditors' PickThe Prompt: Scarlett Johansson Vs OpenAIPlus AI-generated kids draw predators on TikTok and Instagram. \\nShare to FacebookShare to TwitterShare to Linkedin“I was shocked, angered and in disbelief,” Scarlett Johansson said about OpenAI's Sky voice for ChatGPT that sounds similar to her own.FilmMagic\\nThe Prompt is a weekly rundown of AI’s buzziest startups, biggest breakthroughs, and business deals. To get it in your inbox, subscribe here.\\n\\n\\nWelcome back to The Prompt.\\n\\nScarlett Johansson’s lawyers have demanded that OpenAI take down a voice for ChatGPT that sounds much like her own after she’d declined to work with the company to create it. The actress said in a statement provided to Forbes that her lawyers have asked the AI company to detail the “exact processes” it used to create the voice, which sounds eerily similar to Johansson’s voiceover work in the sci-fi movie Her. “I was shocked, angered and in disbelief,” she said.\\n\\nThe actress said in the statement that last September Sam Altman offered to hire her to voice ChatGPT, adding that her voice would be comforting to people. She turned down the offer, citing personal reasons. Two days before OpenAI launched its latest model, GPT-4o, Altman reached out again, asking her to reconsider. But before she could respond, the voice was used in a demo, where it flirted, laughed and sang on stage. (“Oh stop it! You’re making me blush,” the voice said to the employee presenting the demo.)\\n\\nOn Monday, OpenAI said it would take down the voice, while claiming that it is not “an imitation of Scarlett Johansson” and that it had partnered with professional voice actors to create it. But Altman’s one-word tweet – “Her” – posted after the demo last week only further fueled the connection between the AI’s voice and Johannson’s.\\nNow, let’s get into the headlines.\\nBIG PLAYSActor and filmmaker Donald Glover tests out Google's new AI video tools.GOOGLE \\n\\nGoogle made a long string of AI-related announcements at its annual developer conference last week. The biggest one is that AI overviews — AI-generated summaries on any topic that will sit on top of search results — are rolling out to everyone across the U.S. But users were quick to express their frustration with the inaccuracies of these AI-generated snapshots. “90% of the results are pure nonsense or just incorrect,” one person wrote. “I literally might just stop using Google if I can't figure out how to turn off the damn AI overview,” another posted on X.\\nConsumers will also be able to use videos recorded with Google Lens to search for answers to questions like “What breed is this dog?” or “How do I fix this?” Plus, a new feature built on Gemini models will let them search their Google Photos gallery. Workspace products are getting an AI uplift as well: Google’s AI model Gemini 1.5 will let paying users find and summarize information in their Google Drive, Docs, Slides, Sheets and Gmail, and help generate content across these apps. Meanwhile, Google hired artists like actor and filmmaker Donald Glover and musician Wyclef Jean to promote Google’s new video and music creation AI tools.\\nDeepMind CEO Demis Hassabis touted Project Astra, a “universal assistant” that the company claims can see, hear and speak while understanding its surroundings. In a demo, the multimodel AI agent helps identify and fix pieces of code, create a band name and even find misplaced glasses.\\nTALENT RESHUFFLE\\nKey safety researchers at OpenAI, including cofounder and Chief Scientist Ilya Sutskever and machine learning researcher Jan Leike, have resigned. The two led the company’s efforts to develop ways to control AI systems that might become smarter than humans and prevent them from going rogue at the company’s superalignment team, which now no longer exists, according to Wired. In a thread on X, Leike wrote: “Over the past few months my team has been sailing against the wind. Sometimes we were struggling for compute and it was getting harder and harder to get this crucial research done. Over the past years, safety culture and processes have taken a backseat to shiny products.”\\nThe departure of these researchers also shone a light on OpenAI’s strict and binding nondisclosure agreements and off-boarding documents. Employees who refused to sign them when they left the company risked losing their vested equity in the company, according to Vox. OpenAI CEO Sam Altman responded on X saying “there was a provision about potential equity cancellation in our previous exit docs; although we never clawed anything back, it should never have been something we had in any documents or communication.”\\nAI DEALS OF THE WEEKAlexandr Wang was just 19 when he started Scale. His cofounder, Lucy Guo, was 21.Scale AI\\nScale AI has raised $1 billion at a $14 billion valuation in a round led by Accel. Amazon, Meta, Intel Capital and AMD Ventures are among the firm’s new investors. The company has hired hundreds of thousands of contractors in countries like Kenya and Venezuela through its in-house agency RemoTasks to complete data labeling tasks for training AI models, Forbes reported last year. In February, Forbes reported that the startup secretly scrapped a deal with TikTok amid national security concerns.\\nPlus: Coactive AI, which sorts through and structures a company’s visual data, has raised a $30 million round at a $200 million valuation led by Emerson Collective and Cherryrock Capital. And London-based PolyAI, which sells generative AI voice assistants for customer service and was cofounded by three machine learning PhD students at Cambridge, has raised $50 million at a nearly $500 million valuation.\\nDEEP DIVE Images of AI children on TikTok and Instagram are becoming magnets for many with a sexual interest in minors.ILLUSTRATION BY CECILIA RUNXI ZHANG; IMAGE BY ANTAGAIN/GETTY IMAGES\\nThe girls in the photos on TikTok and Instagram look like they could be 5 or 6 years old. On the older end, not quite 13. They’re pictured in lace and leather, bikinis and crop tops. They’re dressed suggestively as nurses, superheroes, ballerinas and french maids. Some wear bunny ears or devil horns; others, pigtails and oversized glasses. They’re black, white and Asian, blondes, redheads and brunettes. They were all made with AI, and they’ve become magnets for the attention of a troubling audience on some of the biggest social media apps in the world—older men.\\n“AI makes great works of art: I would like to have a pretty little virgin like that in my hands to make it mine,” one TikTok user commented on a recent post of young blonde girls in maid outfits, with bows around their necks and flowers in their hair.\\nSimilar remarks flooded photos of AI kids on Instagram. “I would love to take her innocence even if she’s a fake image,” one person wrote on a post of a small, pale child dressed as a bride. On another, of a young girl in short-shorts, the same user commented on “her cute pair of small size [breasts],” depicted as two apple emojis, “and her perfect innocent slice of cherry pie down below.”\\nForbes found hundreds of posts and comments like these on images of AI-generated kids on the platforms from 2024 alone. Many were tagged to musical hits—like Beyonce’s “Texas Hold ‘Em,” Taylor Swift’s “Shake It Off” and Tracy Chapman’s “Fast Car”—to help them reach more eyeballs.\\nChild predators have prowled most every major social media app—where they can hide behind screens and anonymous usernames—but TikTok and Instagram’s popularity with teens and minors has made them both top destinations. And though platforms’ struggle to crack down on child sexual abuse material (or CSAM) predates today’s AI boom, AI text-to-image generators are making it even easier for predators to find or create exactly what they’re looking for.\\nTikTok and Instagram permanently removed the accounts, videos and comments referenced in this story after Forbes asked about them; both companies said they violated platform rules.\\nRead the full story in Forbes here.\\nYOUR WEEKLY DEMO\\nOn Monday, Microsoft introduced a new line of Windows computers that have a suite of AI features built-in. Called “Copilot+ PCs”, the computers come equipped with AI-powered apps deployed locally on the device so you can run them without using an internet connection. The computers can record your screen to help you find anything you may have seen on it, generate images from text-based prompts and translate audio from 40 languages. Sold by brands like Dell, Lenovo and Samsung, the computers are able to do all this without internet access because their Qualcomm Snapdragon chips have a dedicated AI processor. The company claims its new laptops are about 60% faster and have 20% more battery life than Apple’s MacBook Air M3, and the first models will be on sale in mid-June.\\nMODEL BEHAVIOR\\nIn the past, universities have invited esteemed alumni to deliver commencement speeches at graduation ceremonies. This year, some institutions turned to AI. At D’Youville University in Buffalo, New York, a rather creepy-looking robot named Sophia delivered the commencement speech, doling out generic life lessons to an audience of 2,000 people. At Rensselaer Polytechnic Institute’s bicentennial graduation ceremony, GPT-4 was used to generate a speech from the perspective of Emily Warren Roebling, who helped complete the construction of the Brooklyn Bridge and received a posthumous degree from the university. The speech was read out by actress Liz Wisan.\\n\")]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b686d9",
   "metadata": {
    "id": "31b686d9"
   },
   "source": [
    "## Step 1: Load Document\n",
    "\n",
    "- [Link to official documentation - Document loaders](https://python.langchain.com/docs/integrations/document_loaders/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595217a5",
   "metadata": {
    "id": "595217a5"
   },
   "source": [
    "### 網頁\n",
    "\n",
    "```WebBaseLoader``` 使用 ```bs4.SoupStrainer``` 來僅解析指定網頁中的必要部分。\n",
    "\n",
    "[注意]\n",
    "\n",
    "- ```bs4.SoupStrainer``` 可以方便地從網頁中提取所需元素\n",
    "\n",
    "(範例)\n",
    "\n",
    "```python\n",
    "bs4.SoupStrainer(\n",
    "    \"div\",\n",
    "    attrs={\"class\": [\"newsct_article _article_body\", \"media_end_head_title\"]}, # 輸入類別名稱。\n",
    ")\n",
    "\n",
    "bs4.SoupStrainer(\n",
    "    \"article\",\n",
    "    attrs={\"id\": [\"dic_area\"]}, # 輸入類別名稱。\n",
    ")\n",
    "```\n",
    "\n",
    "**詳細說明：**\n",
    "\n",
    "### bs4.SoupStrainer 的核心功能\n",
    "\n",
    "**1. 選擇性解析**\n",
    "- 只解析網頁中特定的 HTML 元素\n",
    "- 大幅提高解析效率和速度\n",
    "- 減少記憶體使用量\n",
    "\n",
    "**2. 精確定位**\n",
    "- **標籤選擇**：指定 HTML 標籤類型（如 `div`、`article`、`p`）\n",
    "- **屬性篩選**：根據 class、id 等屬性進行篩選\n",
    "- **內容過濾**：排除不相關的網頁內容\n",
    "\n",
    "**3. 常見使用模式**\n",
    "\n",
    "```python\n",
    "# 根據 class 屬性篩選\n",
    "bs4.SoupStrainer(\n",
    "    \"div\",\n",
    "    attrs={\"class\": \"content-body\"}\n",
    ")\n",
    "\n",
    "# 根據 id 屬性篩選\n",
    "bs4.SoupStrainer(\n",
    "    \"section\",\n",
    "    attrs={\"id\": \"main-content\"}\n",
    ")\n",
    "\n",
    "# 多個 class 值\n",
    "bs4.SoupStrainer(\n",
    "    \"p\",\n",
    "    attrs={\"class\": [\"paragraph\", \"text-content\"]}\n",
    ")\n",
    "```\n",
    "\n",
    "**4. 實際應用場景**\n",
    "- **新聞網站**：提取文章正文，排除廣告和側邊欄\n",
    "- **部落格**：獲取文章內容，忽略評論和導航\n",
    "- **學術網站**：提取論文摘要或主要內容\n",
    "\n",
    "**5. 在 RAG 系統中的優勢**\n",
    "- **提高品質**：只提取相關內容，減少雜訊\n",
    "- **節省資源**：降低處理和存儲成本\n",
    "- **增強檢索**：更精確的內容提高檢索準確性\n",
    "\n",
    "這種精準的內容提取對於建立高品質的 RAG 知識庫至關重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a040ec3",
   "metadata": {
    "id": "8a040ec3"
   },
   "source": [
    "Here is another example, a BBC news article. Try running it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc118579",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "fc118579",
    "outputId": "992b75c6-9e2d-4777-b86a-f03e1bc46798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Could AI \\'trading bots\\' transform the world of investing?Getty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative returns. Yet as every reputable financial firm warns - your '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the contents of the news article, split it into chunks, and index it.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.bbc.com/news/business-68092814\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"main\",\n",
    "            attrs={\"id\": [\"main-content\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43be1cf",
   "metadata": {
    "id": "f43be1cf"
   },
   "source": [
    "### PDF\n",
    "The following section covers the document loader for importing **PDF** files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b14f827c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b14f827c",
    "outputId": "8edb9632-1b47-4981-fc0a-1e10ba3067ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 24\n",
      "\n",
      "[page_content]\n",
      "A EUROPEAN APPROACH TO ARTIFICIAL INTELLIGENCE - A POLICY PERSPECTIVE\n",
      "10\n",
      "requirements becomes mandatory in all sectors and create bar -\n",
      "riers especially for innovators and SMEs. Public procurement ‘data \n",
      "sovereignty clauses’ induce large players to withdraw from AI for \n",
      "urban ecosystems. Strict liability sanctions block AI in healthcare, \n",
      "while limiting space of self-driving experimentation. The support \n",
      "measures to boost European AI are not sufficient to offset the \n",
      "unintended effect of generic\n",
      "\n",
      "[metadata]\n",
      "{'source': 'data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf', 'page': 9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF file. Enter the file path.\n",
    "loader = PyPDFLoader(\"data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf\")\n",
    "\n",
    "\n",
    "\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "\n",
    "# Output the content of the 10th page.\n",
    "print(f\"\\n[page_content]\\n{docs[9].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[9].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45216d9",
   "metadata": {
    "id": "a45216d9"
   },
   "source": [
    "### CSV\n",
    "The following section covers the document loader for importing CSV files.\n",
    "\n",
    "CSV retrieves data using row numbers instead of page numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77419a2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "77419a2a",
    "outputId": "bb42b003-8674-45e7-d25d-e3c3f06325ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 20\n",
      "\n",
      "[row_content]\n",
      "PassengerId: 10\n",
      "Survived: 1\n",
      "Pclass: 2\n",
      "Name: Nasser, Mrs. Nicholas (Adele Achem)\n",
      "Sex: female\n",
      "Age: 14\n",
      "SibSp: 1\n",
      "Parch: 0\n",
      "Ticket: 237736\n",
      "Fare: 30.0708\n",
      "Cabin: \n",
      "Embarked: C\n",
      "\n",
      "[metadata]\n",
      "{'source': 'data/titanic.csv', 'row': 9}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "# Load CSV file\n",
    "loader = CSVLoader(file_path=\"data/titanic.csv\")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "\n",
    "# Output the content of the 10th row.\n",
    "print(f\"\\n[row_content]\\n{docs[9].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[9].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866c8ea",
   "metadata": {
    "id": "4866c8ea"
   },
   "source": [
    "### TXT\n",
    "The following section covers the document loader for importing TXT files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5c00113",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5c00113",
    "outputId": "29c84533-7f2b-4c58-aa79-9238063c1e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n",
      "\n",
      "[page_content]\n",
      "- Semantic Search\n",
      "\n",
      "Definition: Semantic search is a search method that goes beyond simple keyword matching to understand the meaning of the user’s query and return relevant results.\n",
      "Example: When a user searches for \"planets in the solar system,\" it returns information about related planets such as \"Jupiter\" or \"Mars.\"\n",
      "Keywords: Natural Language Processing, Search Algorithm, Data Mining\n",
      "\n",
      "- Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, int\n",
      "\n",
      "[metadata]\n",
      "{'source': 'data/appendix-keywords_eng.txt'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/appendix-keywords_eng.txt\", encoding=\"utf-8\")\n",
    "docs = loader.load()\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "\n",
    "# Output the content of the 10th page.\n",
    "print(f\"\\n[page_content]\\n{docs[0].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567b4e0",
   "metadata": {
    "id": "7567b4e0"
   },
   "source": [
    "### Load all files in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133bf8dd",
   "metadata": {
    "id": "133bf8dd"
   },
   "source": [
    "Here is an example of loading all ```.txt``` files in the folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fecb15de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fecb15de",
    "outputId": "58e172f1-feb7-4719-ea26-2bc428f56041"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:08<00:00,  4.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 2\n",
      "\n",
      "[page_content]\n",
      "Selecting the “right” amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generat\n",
      "\n",
      "[metadata]\n",
      "{'source': 'data/chain-of-density.txt'}\n",
      "\n",
      "\n",
      "[metadata]\n",
      "{'source': 'data/appendix-keywords_eng.txt'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\".\", glob=\"data/*.txt\", show_progress=True)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "\n",
    "# Output the content of the 10th page.\n",
    "print(f\"\\n[page_content]\\n{docs[0].page_content[:500]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[0].metadata}\\n\")\n",
    "print(f\"\\n[metadata]\\n{docs[1].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9cbb02",
   "metadata": {
    "id": "6b9cbb02"
   },
   "source": [
    "The following is an example of loading all ```.pdf``` files in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cc40246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0cc40246",
    "outputId": "5e47fd25-ca1c-4cbd-bfc0-2448b231200b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content: 1\n",
      "\n",
      "[metadata]\n",
      "\n",
      "{'source': 'data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf'}\n",
      "\n",
      "========= [Preview] Front Section =========\n",
      "\n",
      "While a clear cut definition of Artificial Intelligence (AI) would be the building block for its regulatory and governance framework, there is not yet a widely accepted definition of what AI is (Buiten, 2019; Scherer, 2016). Definitions focussing on intelligence are often circular in that defining what level of intelligence is nee- ded to qualify as ‘artificial intelligence’ remains subjective and situational1. Pragmatic ostensive definitions simply group under the AI labels a wide array of tech\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\".\", glob=\"data/*.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"page_content: {len(docs)}\\n\")\n",
    "print(\"[metadata]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [Preview] Front Section =========\\n\")\n",
    "print(docs[0].page_content[2500:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3065d6",
   "metadata": {
    "id": "9d3065d6"
   },
   "source": [
    "### Python\n",
    "\n",
    "The following is an example of loading ```.py``` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36678ef2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36678ef2",
    "outputId": "a0b196de-85b0-47f9-ef8d-58c4c9ade3eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content: 1\n",
      "\n",
      "[metadata]\n",
      "\n",
      "{'source': 'data/audio_utils.py'}\n",
      "\n",
      "========= [Preview] Front Section =========\n",
      "\n",
      "import re\n",
      "import os\n",
      "from pytube import YouTube\n",
      "from moviepy.editor import AudioFileClip, VideoFileClip\n",
      "from pydub import AudioSegment\n",
      "from pydub.silence import detect_nonsilent\n",
      "\n",
      "\n",
      "def extract_abr(abr):\n",
      "    youtube_audio_pattern = re.compile(r\"\\d+\")\n",
      "    kbps = youtube_audio_pattern.search(abr)\n",
      "    if kbps:\n",
      "        kbps = kbps.group()\n",
      "        return int(kbps)\n",
      "    else:\n",
      "        return 0\n",
      "\n",
      "\n",
      "def get_audio_filepath(filename):\n",
      "    # Create the audio folder if it doesn't exist\n",
      "    if not os.path.isdir(\"au\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import PythonLoader\n",
    "\n",
    "loader = DirectoryLoader(\".\", glob=\"**/*.py\", loader_cls=PythonLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"page_content: {len(docs)}\\n\")\n",
    "print(\"[metadata]\\n\")\n",
    "print(docs[0].metadata)\n",
    "print(\"\\n========= [Preview] Front Section =========\\n\")\n",
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bd21b",
   "metadata": {
    "id": "505bd21b"
   },
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0321a46",
   "metadata": {
    "id": "b0321a46"
   },
   "source": [
    "## Step 2: Split Documents\n",
    "\n",
    "It splits the document into small chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ad4770",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "47ad4770",
    "outputId": "38b3dd29-04c5-4e15-b06b-398c547b337f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Could AI \\'trading bots\\' transform the world of investing?Getty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative returns. Yet as every reputable financial firm warns - your '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the content of the news article, split it into chunks, and index it.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.bbc.com/news/business-68092814\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"main\",\n",
    "            attrs={\"id\": [\"main-content\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"Number of Documents: {len(docs)}\")\n",
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dc11cb",
   "metadata": {
    "id": "62dc11cb"
   },
   "source": [
    "### CharacterTextSplitter\n",
    "\n",
    "這是最簡單的方法。它基於字符（預設：\"\\n\\n\"）分割文本，並以字符數量來測量塊大小。\n",
    "\n",
    "1. **文本分割方式**：按單個字符單位。\n",
    "2. **塊大小測量方式**：按字符的 ```len``` 長度。\n",
    "\n",
    "視覺化範例：https://chunkviz.up.railway.app/\n",
    "\n",
    "```CharacterTextSplitter``` 類別提供將文本分割成指定大小塊的功能。\n",
    "\n",
    "- ```separator``` 參數指定用於分隔塊的字串，在此情況下使用兩個換行字符（\"\\n\\n\"）。\n",
    "- ```chunk_size``` 決定每個塊的最大長度。\n",
    "- ```chunk_overlap``` 指定相鄰塊之間重疊的字符數量。\n",
    "- ```length_function``` 定義用於計算塊長度的函數，預設為 ```len``` 函數，返回字串長度。\n",
    "- ```is_separator_regex``` 是一個布林值，決定 ```separator``` 是否被解釋為正則表達式。\n",
    "\n",
    "**詳細說明：**\n",
    "\n",
    "### CharacterTextSplitter 的核心特性\n",
    "\n",
    "**1. 簡單直觀的分割邏輯**\n",
    "- 按指定的分隔符進行分割\n",
    "- 不考慮語意邊界，純粹基於字符計算\n",
    "- 適合結構化文本或格式統一的內容\n",
    "\n",
    "**2. 參數配置的實際應用**\n",
    "\n",
    "```python\n",
    "# 基本配置\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",      # 段落分隔\n",
    "    chunk_size=1000,       # 每塊最多1000字符\n",
    "    chunk_overlap=200,     # 相鄰塊重疊200字符\n",
    "    length_function=len,   # 使用字符數計算長度\n",
    "    is_separator_regex=False\n",
    ")\n",
    "```\n",
    "\n",
    "**3. 重疊機制的重要性**\n",
    "- **上下文保持**：確保重要信息不會在分割邊界處丟失\n",
    "- **語意連接**：維持前後文的關聯性\n",
    "- **檢索優化**：提高相關內容的檢索機會\n",
    "\n",
    "**4. 適用場景**\n",
    "- **結構化文檔**：法律文件、技術手冊\n",
    "- **格式統一內容**：新聞文章、部落格文章\n",
    "- **快速原型**：RAG 系統的初期開發和測試\n",
    "\n",
    "**5. 限制和考量**\n",
    "- **語意完整性**：可能在句子中間切斷\n",
    "- **語言特性**：對不同語言的處理效果差異\n",
    "- **文檔結構**：無法識別標題、列表等邏輯結構\n",
    "\n",
    "**6. 最佳實踐**\n",
    "- 根據內容類型調整分隔符\n",
    "- 設定適當的重疊比例（通常 10-20%）\n",
    "- 考慮目標模型的上下文窗口大小\n",
    "\n",
    "這種簡單的分割方法雖然基礎，但在許多實際應用中仍然有效且實用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ade83078",
   "metadata": {
    "id": "ade83078"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d7e0d",
   "metadata": {
    "id": "ea7d7e0d"
   },
   "source": [
    "此函數使用 ```text_splitter``` 物件的 ```create_documents``` 方法將給定的文本（```state_of_the_union```）分割成多個文檔，並將結果存儲在 ```texts``` 變數中。然後輸出 texts 中的第一個文檔。此過程可視為處理和分析文本數據的初始步驟，特別適用於將大型文本數據分割成可管理的塊。\n",
    "\n",
    "**詳細說明：**\n",
    "\n",
    "### create_documents 方法的工作原理\n",
    "\n",
    "**1. 文檔分割流程**\n",
    "```python\n",
    "# 基本使用模式\n",
    "texts = text_splitter.create_documents([state_of_the_union])\n",
    "print(texts[0])  # 顯示第一個分割後的文檔\n",
    "```\n",
    "\n",
    "**2. 輸入和輸出格式**\n",
    "- **輸入**：文本字串列表 `[state_of_the_union]`\n",
    "- **輸出**：`Document` 物件列表，每個物件包含：\n",
    "  - `page_content`：分割後的文本內容\n",
    "  - `metadata`：相關元數據（如來源、位置等）\n",
    "\n",
    "**3. 實際應用價值**\n",
    "\n",
    "**文本預處理**\n",
    "- 將冗長的原始文本轉換為適合處理的小塊\n",
    "- 每個塊都是獨立的 `Document` 物件\n",
    "- 便於後續的向量化和索引操作\n",
    "\n",
    "**記憶體管理**\n",
    "- 避免一次性處理超大文本檔案\n",
    "- 允許逐塊處理，提高系統效率\n",
    "- 減少記憶體佔用和處理時間\n",
    "\n",
    "**RAG 系統整合**\n",
    "- 為向量資料庫準備合適大小的文本塊\n",
    "- 確保每個塊都能完整表達一個概念或主題\n",
    "- 提高檢索的精確度和相關性\n",
    "\n",
    "**4. 典型的處理流程**\n",
    "```python\n",
    "# 1. 分割文檔\n",
    "texts = text_splitter.create_documents([original_text])\n",
    "\n",
    "# 2. 檢查分割結果\n",
    "print(f\"總共分割出 {len(texts)} 個文檔塊\")\n",
    "print(f\"第一個塊的長度：{len(texts[0].page_content)}\")\n",
    "\n",
    "# 3. 後續處理\n",
    "for i, doc in enumerate(texts):\n",
    "    print(f\"文檔 {i+1}: {doc.page_content[:100]}...\")\n",
    "```\n",
    "\n",
    "**5. 在文本分析中的重要性**\n",
    "- **可管理性**：將大型文檔分解為可處理的單元\n",
    "- **並行處理**：支援多核心或分散式處理\n",
    "- **品質控制**：便於檢查和驗證分割結果的合理性\n",
    "\n",
    "這種分割方法是 RAG 系統和其他文本分析應用的基礎步驟，確保後續處理的有效性和準確性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472bc3c3",
   "metadata": {
    "id": "472bc3c3"
   },
   "outputs": [],
   "source": [
    "# Load a portion of the \"Chain of Density\" paper.\n",
    "with open(\"data/chain-of-density.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70e11f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70e11f5b",
    "outputId": "8de9934d-6451-4c6a-a0de-49882d1bca5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selecting the “right” amount of information to include in a summary is a difficult task. \\nA good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries genera']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=10, separator=\"\\n\\n\"\n",
    ")\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24506d98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24506d98",
    "outputId": "a48b6aca-256a-4538-e563-bae0d0d7e93b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selecting the “right” amount of information to include in a summary is a difficult task.',\n",
       " 'A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries genera']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10, separator=\"\\n\")\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57da16a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "57da16a7",
    "outputId": "d26f03d9-7228-4d96-e17b-a07195c05ef3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selecting the “right” amount of information to include in a summary is a difficult task. \\nA good',\n",
       " 'A good summary should be detailed and entity-centric without being overly dense and hard to follow.',\n",
       " 'to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with',\n",
       " 'with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial',\n",
       " 'an initial entity-sparse summary before iteratively incorporating missing salient entities without',\n",
       " 'without increasing the length. Summaries genera']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=10, separator=\" \")\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c743226",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c743226",
    "outputId": "b3938a57-34db-4477-d9b5-c121c56ccddf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selecting the “right” amount of information to include in a summary is a difficult task. \\nA good',\n",
       " 'summary should be detailed and entity-centric without being overly dense and hard to follow. To',\n",
       " 'better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to',\n",
       " 'as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary',\n",
       " 'before iteratively incorporating missing salient entities without increasing the length. Summaries',\n",
       " 'genera']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0, separator=\" \")\n",
    "text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b5b02d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2b5b02d4",
    "outputId": "b3c9e60c-884c-4e6c-e17c-9d95b211d875"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100, separator=\" \")\n",
    "# Split the text file into chunks.\n",
    "text_splitter.split_text(text)\n",
    "\n",
    "# Split the document into chunks.\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2f39fc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2f39fc8",
    "outputId": "945cfb6c-6d6f-4c43-f9bd-00e2f55cbacd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.bbc.com/news/business-68092814'}, page_content='Could AI \\'trading bots\\' transform the world of investing?Getty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative returns. Yet as every reputable financial firm warns - your capital may be at risk.Or putting it more simply - you could lose your money - whether it is a human or a computer that is making stock market decisions on your behalf.Yet such has been the hype about the ability of AI over the past few years, that almost one in three investors would be happy to let a trading bot make all the decisions for them, according to one 2023 survey in the US.John Allan says investors should be more cautious about using AI. He is head of innovation and operations for the')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e376c2cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "e376c2cd",
    "outputId": "09e12e58-f3c2-43fb-f94a-8c93b8dd6023"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Could AI \\'trading bots\\' transform the world of investing?Getty ImagesIt is hard for both humans and computers to predict stock market movementsSearch for \"AI investing\" online, and you\\'ll be flooded with endless offers to let artificial intelligence manage your money.I recently spent half an hour finding out what so-called AI \"trading bots\" could apparently do with my investments.Many prominently suggest that they can give me lucrative returns. Yet as every reputable financial firm warns - your '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the content of the news article, split it into chunks, and index it.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.bbc.com/news/business-68092814\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            \"main\",\n",
    "            attrs={\"id\": [\"main-content\"]},\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define the splitter.\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100, separator=\" \")\n",
    "\n",
    "# Split the document while loading it.\n",
    "split_docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "print(f\"Number of documents: {len(docs)}\")\n",
    "docs[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3662cd",
   "metadata": {
    "id": "dc3662cd"
   },
   "source": [
    "### RecursiveTextSplitter\n",
    "這個文本分割器是推薦用於一般文本的。\n",
    "\n",
    "1. ```文本分割方式```：基於分隔符列表。\n",
    "2. ```塊大小測量方式```：按字符的 len 長度。\n",
    "\n",
    "```RecursiveCharacterTextSplitter``` 類別提供遞歸分割文本的功能。此類別接受參數，如 ```chunk_size``` 來指定要分割的塊的大小，```chunk_overlap``` 來定義相鄰塊之間的重疊大小，```length_function``` 來計算塊的長度，以及 ```is_separator_regex``` 來指示分隔符是否為正則表達式。\n",
    "\n",
    "在範例中，塊大小設定為 100，重疊大小為 20，長度計算函數為 ```len```，```is_separator_regex``` 設定為 ```False``` 以指示分隔符不是正則表達式。\n",
    "\n",
    "**詳細說明：**\n",
    "\n",
    "### RecursiveCharacterTextSplitter 的優勢\n",
    "\n",
    "**1. 智能分割策略**\n",
    "- 使用**分隔符優先級列表**進行分割\n",
    "- 預設分隔符順序：`[\"\\n\\n\", \"\\n\", \" \", \"\"]`\n",
    "- 優先保持段落和句子的完整性\n",
    "\n",
    "**2. 遞歸分割機制**\n",
    "```python\n",
    "# 分割邏輯流程\n",
    "1. 嘗試用 \"\\n\\n\" (段落分隔) 分割\n",
    "2. 如果塊仍太大，用 \"\\n\" (行分隔) 進一步分割\n",
    "3. 如果還是太大，用 \" \" (空格) 分割\n",
    "4. 最後用 \"\" (字符) 強制分割\n",
    "```\n",
    "\n",
    "**3. 語意保持特性**\n",
    "- **段落完整性**：優先保持段落不被切斷\n",
    "- **句子完整性**：盡量避免在句子中間分割\n",
    "- **詞語完整性**：最後才考慮字符級分割\n",
    "\n",
    "**4. 配置參數說明**\n",
    "```python\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,        # 目標塊大小\n",
    "    chunk_overlap=20,      # 重疊字符數（20%重疊率）\n",
    "    length_function=len,   # 長度計算方式\n",
    "    is_separator_regex=False,  # 分隔符不是正則表達式\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # 分隔符優先級\n",
    ")\n",
    "```\n",
    "\n",
    "**5. 與 CharacterTextSplitter 的比較**\n",
    "| 特性 | RecursiveCharacterTextSplitter | CharacterTextSplitter |\n",
    "|------|-------------------------------|----------------------|\n",
    "| 分割智能度 | 高（多層次分隔符） | 低（單一分隔符） |\n",
    "| 語意保持 | 好（優先保持段落句子完整） | 一般（可能切斷句子） |\n",
    "| 適用場景 | 一般文本、自然語言 | 結構化文本 |\n",
    "| 處理複雜度 | 中等 | 簡單 |\n",
    "\n",
    "**6. 最佳實踐建議**\n",
    "- **chunk_size**：根據模型上下文窗口設定（通常 500-2000 字符）\n",
    "- **chunk_overlap**：設定為 chunk_size 的 10-20%\n",
    "- **自定義分隔符**：可根據文檔類型調整分隔符優先級\n",
    "\n",
    "**7. 實際應用場景**\n",
    "- **技術文檔**：保持程式碼區塊和說明的完整性\n",
    "- **學術論文**：維持段落和論點的邏輯結構\n",
    "- **小說文本**：保持對話和描述的連貫性\n",
    "- **新聞文章**：維持段落和引用的完整性\n",
    "\n",
    "這種遞歸分割方法在大多數文本處理場景中都能提供更好的結果，是 RAG 系統的推薦選擇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5fc0587c",
   "metadata": {
    "id": "5fc0587c"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a8cf631",
   "metadata": {
    "id": "6a8cf631"
   },
   "outputs": [],
   "source": [
    "# Load a portion of the \"Chain of Density\" paper.\n",
    "with open(\"data/chain-of-density.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26f2bb98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26f2bb98",
    "outputId": "53a73c21-b979-4c25-85df-c1f3892f13cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the “right” amount of information to include in a summary is a difficult task. \n",
      "A good\n",
      "A good summary should be detailed and entity-centric without being overly dense and hard to follow.\n",
      "to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with\n",
      "with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial\n",
      "an initial entity-sparse summary before iteratively incorporating missing salient entities without\n",
      "without increasing the length. Summaries genera\n",
      "============================================================\n",
      "Selecting the “right” amount of information to include in a summary is a difficult task.\n",
      "A good summary should be detailed and entity-centric without being overly dense and hard to follow.\n",
      "follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what\n",
      "with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an\n",
      "an initial entity-sparse summary before iteratively incorporating missing salient entities without\n",
      "without increasing the length. Summaries genera\n"
     ]
    }
   ],
   "source": [
    "character_text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=10, separator=\" \"\n",
    ")\n",
    "for sent in character_text_splitter.split_text(text):\n",
    "    print(sent)\n",
    "print(\"===\" * 20)\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=10\n",
    ")\n",
    "for sent in recursive_text_splitter.split_text(text):\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264cf4ae",
   "metadata": {
    "id": "264cf4ae"
   },
   "source": [
    "- Attempts to split the given document sequentially using the specified list of separators.\n",
    "- Attempts splitting in order until the chunks are sufficiently small. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"].\n",
    "- This generally has the effect of keeping all paragraphs (as well as sentences and words) as long as possible, while appearing to be the most semantically relevant pieces of text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "393ec4f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "393ec4f4",
    "outputId": "7a35b5f8-f052-4f91-a6de-6849093f555f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n', '\\n', ' ', '']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the default separators specified in recursive_text_splitter.\n",
    "recursive_text_splitter._separators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e49d975",
   "metadata": {
    "id": "1e49d975"
   },
   "source": [
    "### 語義相似性\n",
    "\n",
    "基於語義相似性進行文本分割。\n",
    "\n",
    "來源：[SemanticChunker](https://python.langchain.com/api_reference/experimental/text_splitter/langchain_experimental.text_splitter.SemanticChunker.html)\n",
    "\n",
    "從高層次來看，該過程包括將文本分割成句子，將它們分組為三句一組，然後在嵌入空間中合併相似的句子。\n",
    "\n",
    "**詳細說明：**\n",
    "\n",
    "### SemanticChunker 的核心原理\n",
    "\n",
    "**1. 語義驅動的分割策略**\n",
    "- 不依賴字符數或固定分隔符\n",
    "- 基於內容的**語義相似性**進行智能分組\n",
    "- 確保每個塊在主題上具有內聚性\n",
    "\n",
    "**2. 三階段處理流程**\n",
    "\n",
    "**階段一：句子分割**\n",
    "```python\n",
    "# 將原始文本分解為獨立句子\n",
    "text → [\"句子1\", \"句子2\", \"句子3\", ...]\n",
    "```\n",
    "\n",
    "**階段二：三句分組**\n",
    "```python\n",
    "# 創建滑動窗口組合\n",
    "[\"句子1\", \"句子2\", \"句子3\"]  # 組合1\n",
    "[\"句子2\", \"句子3\", \"句子4\"]  # 組合2\n",
    "[\"句子3\", \"句子4\", \"句子5\"]  # 組合3\n",
    "```\n",
    "\n",
    "**階段三：語義合併**\n",
    "```python\n",
    "# 在向量空間中計算相似度\n",
    "embedding_1 = embed(\"句子1-2-3\")\n",
    "embedding_2 = embed(\"句子2-3-4\")\n",
    "similarity = cosine_similarity(embedding_1, embedding_2)\n",
    "\n",
    "# 根據相似度閾值決定是否合併\n",
    "if similarity > threshold:\n",
    "    merge_chunks()\n",
    "```\n",
    "\n",
    "**3. 核心優勢**\n",
    "\n",
    "**語義連貫性**\n",
    "- 確保相關內容聚集在同一塊中\n",
    "- 避免主題在分割邊界處被切斷\n",
    "- 提高 RAG 檢索的準確性\n",
    "\n",
    "**自適應分割**\n",
    "- 根據內容密度動態調整塊大小\n",
    "- 複雜主題可能產生較大的塊\n",
    "- 簡單內容形成較小的塊\n",
    "\n",
    "**上下文保持**\n",
    "- 三句重疊設計確保上下文連續性\n",
    "- 重要概念不會在邊界處丟失\n",
    "- 改善語言模型的理解能力\n",
    "\n",
    "**4. 與傳統方法的比較**\n",
    "\n",
    "| 特性 | SemanticChunker | RecursiveCharacterTextSplitter |\n",
    "|------|----------------|-------------------------------|\n",
    "| 分割依據 | 語義相似性 | 字符數/分隔符 |\n",
    "| 塊大小 | 動態（內容驅動） | 固定（參數控制） |\n",
    "| 主題完整性 | 高 | 中等 |\n",
    "| 計算成本 | 高（需要嵌入計算） | 低 |\n",
    "\n",
    "**5. 適用場景**\n",
    "\n",
    "**高品質 RAG 系統**\n",
    "- 需要精確主題匹配的問答系統\n",
    "- 複雜技術文檔的智能檢索\n",
    "- 學術研究的語義搜索\n",
    "\n",
    "**多主題文檔**\n",
    "- 包含多個不相關主題的長文檔\n",
    "- 新聞文章集合的主題分類\n",
    "- 企業知識庫的內容組織\n",
    "\n",
    "**6. 實施考量**\n",
    "\n",
    "**嵌入模型選擇**\n",
    "- 需要高品質的句子嵌入模型\n",
    "- 考慮語言特性和領域適應性\n",
    "- 平衡準確性和計算效率\n",
    "\n",
    "**相似度閾值調整**\n",
    "- 過高：產生過多小塊，可能丟失上下文\n",
    "- 過低：產生過大塊，降低檢索精度\n",
    "- 需要根據具體應用進行調優\n",
    "\n",
    "這種基於語義的分割方法雖然計算成本較高，但在需要高品質檢索的 RAG 應用中能夠顯著提升性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dccff243",
   "metadata": {
    "id": "dccff243"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Create a SemanticChunker.\n",
    "semantic_text_splitter = SemanticChunker(OpenAIEmbeddings(model=\"text-embedding-3-small\"), add_start_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a27b2d73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a27b2d73",
    "outputId": "80eb4f7d-f3a9-4b27-a298-e8a8d1b41e5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the “right” amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a “Chain of Density” (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generated by CoD are more abstractive, exhibit more fusion, and have less of a lead bias than GPT-4 summaries generated by a vanilla prompt. We conduct a human preference study on 100 CNN DailyMail articles and find that that humans prefer GPT-4 summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries. Qualitative analysis supports the notion that there exists a tradeoff between infor-mativeness and readability. 500 annotated CoD summaries, as well as an extra 5,000 unannotated summaries, are freely available on HuggingFace. Introduction\n",
      "\n",
      "Automatic summarization has come a long way in the past few years, largely due to a paradigm shift away from supervised fine-tuning on labeled datasets to zero-shot prompting with Large Language Models (LLMs), such as GPT-4 (OpenAI, 2023). Without additional training, careful prompting can enable fine-grained control over summary characteristics, such as length (Goyal et al., 2022), topics (Bhaskar et al., 2023), and style (Pu and Demberg, 2023). An overlooked aspect is the information density of an summary. In theory, as a compression of another text, a summary should be denser–containing a higher concentration of information–than the source document. Given the high latency of LLM decoding (Kad-dour et al., 2023), covering more information in fewer words is a worthy goal, especially for real-time applications. Yet, how dense is an open question.\n",
      "============================================================\n",
      "A summary is uninformative if it contains insufficient detail. If it contains too much information, however, it can be-come difficult to follow without having to increase the overall length. Conveying more information subject to a fixed token budget requires a combination of abstrac-tion, compression, and fusion. There is a limit to how much space can be made for additional information before becoming illegible or even factually incorrect.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Load a portion of the \"Chain of Density\" paper.\n",
    "with open(\"data/chain-of-density.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "for sent in semantic_text_splitter.split_text(text):\n",
    "    print(sent)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f3467",
   "metadata": {
    "id": "f04f3467"
   },
   "source": [
    "## Step 3: Embedding\n",
    "\n",
    "- [Link to official documentation - Embedding](https://python.langchain.com/docs/integrations/text_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9affbaf8",
   "metadata": {
    "id": "9affbaf8"
   },
   "source": [
    "### Paid Embeddings (OpenAI)\n",
    "\n",
    "It uses OpenAI's embedding model, which is a paid service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ccc62a14",
   "metadata": {
    "id": "ccc62a14"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Step 3: Create Embeddings & Vectorstore\n",
    "# Generate the vector store.\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f65e243",
   "metadata": {
    "id": "7f65e243"
   },
   "source": [
    "Below is a list of Embedding models supported by ```OpenAI``` :\n",
    "\n",
    "The default model is ```text-embedding-ada-002``` .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c021b1",
   "metadata": {
    "id": "97c021b1"
   },
   "source": [
    "| MODEL                  | ROUGH PAGES PER DOLLAR | EXAMPLE PERFORMANCE ON MTEB EVAL |\n",
    "| ---------------------- | ---------------------- | -------------------------------- |\n",
    "| text-embedding-3-small | 62,500                 | 62.3%                            |\n",
    "| text-embedding-3-large | 9,615                  | 64.6%                            |\n",
    "| text-embedding-ada-002 | 12,500                 | 61.0%                            |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d07fbf1",
   "metadata": {
    "id": "8d07fbf1"
   },
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241cf6e8",
   "metadata": {
    "id": "241cf6e8"
   },
   "source": [
    "### 免費開源基礎的嵌入模型\n",
    "1. HuggingFaceEmbeddings（預設模型：sentence-transformers/all-mpnet-base-v2）\n",
    "2. FastEmbedEmbeddings\n",
    "\n",
    "**注意**\n",
    "- 使用嵌入模型時，請確保驗證您使用的語言是否受支援。\n",
    "\n",
    "**詳細說明：**\n",
    "\n",
    "### 開源嵌入模型的選擇\n",
    "\n",
    "**1. HuggingFaceEmbeddings**\n",
    "\n",
    "**預設模型特性：**\n",
    "- **all-mpnet-base-v2**：高品質的通用句子嵌入模型\n",
    "- **多語言支援**：主要針對英語優化，其他語言性能較低\n",
    "- **維度**：768 維向量\n",
    "- **適用場景**：一般文本、問答系統、語義搜索\n",
    "\n",
    "**配置選項：**\n",
    "```python\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 使用預設模型\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# 自定義模型\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",  # 更輕量的選擇\n",
    "    model_kwargs={'device': 'cpu'},  # 或 'cuda' 使用 GPU\n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "```\n",
    "\n",
    "**2. FastEmbedEmbeddings**\n",
    "\n",
    "**核心優勢：**\n",
    "- **高效能**：專為速度優化的嵌入計算\n",
    "- **輕量級**：較小的模型大小和記憶體佔用\n",
    "- **快速部署**：簡化的安裝和配置流程\n",
    "\n",
    "**適用場景：**\n",
    "- 需要快速響應的應用\n",
    "- 資源受限的環境\n",
    "- 大規模文本處理\n",
    "\n",
    "### 語言支援考量\n",
    "\n",
    "**1. 中文支援的替代方案**\n",
    "```python\n",
    "# 針對中文優化的模型\n",
    "chinese_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"shibing624/text2vec-base-chinese\"\n",
    ")\n",
    "\n",
    "# 多語言模型\n",
    "multilingual_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    ")\n",
    "```\n",
    "\n",
    "**2. 模型性能比較**\n",
    "\n",
    "| 模型 | 語言支援 | 模型大小 | 性能 | 推薦用途 |\n",
    "|------|----------|----------|------|----------|\n",
    "| all-mpnet-base-v2 | 英語 | ~420MB | 高 | 英語 RAG 系統 |\n",
    "| all-MiniLM-L6-v2 | 英語 | ~80MB | 中 | 輕量英語應用 |\n",
    "| paraphrase-multilingual-* | 多語言 | ~220MB | 中高 | 多語言應用 |\n",
    "| text2vec-base-chinese | 中文 | ~400MB | 高 | 中文 RAG 系統 |\n",
    "\n",
    "**3. 最佳實踐建議**\n",
    "\n",
    "**語言匹配**\n",
    "- 確保嵌入模型與文檔語言匹配\n",
    "- 考慮多語言混合文檔的處理策略\n",
    "- 測試不同模型在特定領域的表現\n",
    "\n",
    "**性能優化**\n",
    "- 使用 GPU 加速（如果可用）\n",
    "- 批量處理提升效率\n",
    "- 考慮模型量化減少記憶體使用\n",
    "\n",
    "**品質驗證**\n",
    "- 在實際數據上測試嵌入品質\n",
    "- 比較不同模型的檢索性能\n",
    "- 根據應用需求選擇合適的模型\n",
    "\n",
    "**4. 實際部署注意事項**\n",
    "- **初次載入時間**：模型下載和初始化可能需要時間\n",
    "- **記憶體需求**：確保系統有足夠記憶體載入模型\n",
    "- **網路依賴**：首次使用需要網路下載模型\n",
    "- **版本相容性**：注意不同版本間的相容性問題\n",
    "\n",
    "選擇合適的開源嵌入模型是建立高效 RAG 系統的關鍵步驟，需要平衡性能、資源消耗和語言支援等因素。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ca55cbf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ca55cbf",
    "outputId": "e061accc-36d1-4393-c07c-5c1f5ea37b4c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Generate the vector store. (Default model: sentence-transformers/all-mpnet-base-v2)\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=splits, embedding=HuggingFaceEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4642c71",
   "metadata": {
    "id": "a4642c71"
   },
   "outputs": [],
   "source": [
    "# %pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d13003a",
   "metadata": {
    "id": "5d13003a"
   },
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=FastEmbedEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd42083c",
   "metadata": {
    "id": "cd42083c"
   },
   "source": [
    "## 步驟 4：創建向量存儲\n",
    "\n",
    "創建向量存儲是指從文檔生成向量嵌入並將其存儲在資料庫中的過程。\n",
    "\n",
    "**詳細說明：**\n",
    "\n",
    "### 向量存儲的核心概念\n",
    "\n",
    "**1. 向量化過程**\n",
    "```python\n",
    "文檔文本 → 嵌入模型 → 數值向量 → 向量資料庫\n",
    "```\n",
    "\n",
    "**2. 向量存儲的組成要素**\n",
    "\n",
    "**文檔內容**\n",
    "- 原始文本內容（page_content）\n",
    "- 相關元數據（metadata）\n",
    "- 文檔來源和位置信息\n",
    "\n",
    "**向量表示**\n",
    "- 高維數值向量（通常 512-1536 維）\n",
    "- 語義信息的數學表示\n",
    "- 支援快速相似性搜索\n",
    "\n",
    "**索引結構**\n",
    "- 高效的搜索算法（如 HNSW、IVF）\n",
    "- 相似性計算優化\n",
    "- 分散式存儲支援\n",
    "\n",
    "### 常見向量資料庫選項\n",
    "\n",
    "**1. 內存型（開發測試）**\n",
    "```python\n",
    "# FAISS - 高效能向量搜索\n",
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Chroma - 輕量級選擇\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(docs, embeddings)\n",
    "```\n",
    "\n",
    "**2. 持久化（生產環境）**\n",
    "```python\n",
    "# Pinecone - 託管服務\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "vectorstore = Pinecone.from_documents(docs, embeddings, index_name=\"my-index\")\n",
    "\n",
    "# Weaviate - 開源方案\n",
    "from langchain_community.vectorstores import Weaviate\n",
    "vectorstore = Weaviate.from_documents(docs, embeddings)\n",
    "```\n",
    "\n",
    "### 創建過程的關鍵步驟\n",
    "\n",
    "**1. 文檔預處理**\n",
    "- 確保文檔格式正確\n",
    "- 驗證文檔內容和元數據\n",
    "- 處理特殊字符和編碼問題\n",
    "\n",
    "**2. 批量向量化**\n",
    "```python\n",
    "# 批量處理提升效率\n",
    "batch_size = 100\n",
    "for i in range(0, len(documents), batch_size):\n",
    "    batch = documents[i:i+batch_size]\n",
    "    vectors = embeddings.embed_documents([doc.page_content for doc in batch])\n",
    "    vectorstore.add_documents(batch)\n",
    "```\n",
    "\n",
    "**3. 索引優化**\n",
    "- 選擇適合的索引算法\n",
    "- 調整索引參數提升搜索性能\n",
    "- 考慮記憶體和磁碟使用平衡\n",
    "\n",
    "### 性能和擴展性考量\n",
    "\n",
    "**1. 存儲容量規劃**\n",
    "- 估算向量存儲空間需求\n",
    "- 規劃擴展策略和容量增長\n",
    "- 考慮數據備份和災難恢復\n",
    "\n",
    "**2. 查詢性能優化**\n",
    "- 調整相似性搜索參數\n",
    "- 實施快取策略減少重複計算\n",
    "- 使用適當的距離度量方法\n",
    "\n",
    "**3. 分散式部署**\n",
    "- 支援橫向擴展的資料庫選擇\n",
    "- 負載平衡和高可用性設計\n",
    "- 數據一致性和同步機制\n",
    "\n",
    "### 品質保證措施\n",
    "\n",
    "**1. 向量品質驗證**\n",
    "```python\n",
    "# 測試向量生成\n",
    "test_query = \"sample query\"\n",
    "query_vector = embeddings.embed_query(test_query)\n",
    "print(f\"向量維度: {len(query_vector)}\")\n",
    "print(f\"向量範圍: {min(query_vector)} 到 {max(query_vector)}\")\n",
    "```\n",
    "\n",
    "**2. 搜索準確性測試**\n",
    "```python\n",
    "# 驗證檢索結果\n",
    "results = vectorstore.similarity_search(test_query, k=5)\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"結果 {i+1}: {doc.page_content[:100]}...\")\n",
    "```\n",
    "\n",
    "向量存儲的品質直接影響 RAG 系統的檢索效果，因此在創建過程中需要細心處理每個環節，確保最終的檢索性能和準確性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9033e0af",
   "metadata": {
    "id": "9033e0af"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Apply FAISS DB\n",
    "vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0a99a27",
   "metadata": {
    "id": "d0a99a27"
   },
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# Apply Chroma DB\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8150225",
   "metadata": {
    "id": "c8150225"
   },
   "source": [
    "## 步驟 5：創建檢索器\n",
    "\n",
    "檢索器是一個接口，當給定非結構化查詢時返回文檔。\n",
    "\n",
    "檢索器不需要存儲文檔；它只返回（或檢索）文檔。\n",
    "\n",
    "- [官方文檔連結 - 檢索器](https://python.langchain.com/docs/integrations/retrievers/)\n",
    "\n",
    "**檢索器**是通過對生成的向量存儲使用 ```invoke()``` 方法創建的。\n",
    "\n",
    "**補充說明：**\n",
    "\n",
    "### 檢索器的核心功能\n",
    "\n",
    "**1. 查詢處理**\n",
    "- 接收自然語言查詢\n",
    "- 轉換為向量表示\n",
    "- 在向量空間中搜索相似文檔\n",
    "\n",
    "**2. 文檔返回**\n",
    "```python\n",
    "# 基本檢索器創建\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# 帶參數的檢索器\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",  # 搜索類型\n",
    "    search_kwargs={\"k\": 3}     # 返回前3個最相關文檔\n",
    ")\n",
    "```\n",
    "\n",
    "**3. 搜索策略選項**\n",
    "- **similarity**：基於相似度的搜索\n",
    "- **mmr**：最大邊際相關性，減少重複\n",
    "- **similarity_score_threshold**：設定相似度閾值\n",
    "\n",
    "這個接口設計讓檢索器可以靈活地與不同的向量存儲後端配合工作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90798e85",
   "metadata": {
    "id": "90798e85"
   },
   "source": [
    "### Similarity Retrieval\n",
    "\n",
    "- The default setting is ```similarity``` , which uses cosine similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b2bd6d95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2bd6d95",
    "outputId": "3b98b7f6-365a-4917-d558-0233fe8ccbd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/'}, page_content=\"ForbesInnovationEditors' PickThe Prompt: Scarlett Johansson Vs OpenAIPlus AI-generated kids draw predators on TikTok and Instagram. \\nShare to FacebookShare to TwitterShare to Linkedin“I was shocked, angered and in disbelief,” Scarlett Johansson said about OpenAI's Sky voice for ChatGPT that sounds similar to her own.FilmMagic\\nThe Prompt is a weekly rundown of AI’s buzziest startups, biggest breakthroughs, and business deals. To get it in your inbox, subscribe here.\\n\\n\\nWelcome back to The Prompt.\\n\\nScarlett Johansson’s lawyers have demanded that OpenAI take down a voice for ChatGPT that sounds much like her own after she’d declined to work with the company to create it. The actress said in a statement provided to Forbes that her lawyers have asked the AI company to detail the “exact processes” it used to create the voice, which sounds eerily similar to Johansson’s voiceover work in the sci-fi movie Her. “I was shocked, angered and in disbelief,” she said.\"), Document(metadata={'source': 'https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/'}, page_content=\"The actress said in the statement that last September Sam Altman offered to hire her to voice ChatGPT, adding that her voice would be comforting to people. She turned down the offer, citing personal reasons. Two days before OpenAI launched its latest model, GPT-4o, Altman reached out again, asking her to reconsider. But before she could respond, the voice was used in a demo, where it flirted, laughed and sang on stage. (“Oh stop it! You’re making me blush,” the voice said to the employee presenting the demo.)\\n\\nOn Monday, OpenAI said it would take down the voice, while claiming that it is not “an imitation of Scarlett Johansson” and that it had partnered with professional voice actors to create it. But Altman’s one-word tweet – “Her” – posted after the demo last week only further fueled the connection between the AI’s voice and Johannson’s.\\nNow, let’s get into the headlines.\\nBIG PLAYSActor and filmmaker Donald Glover tests out Google's new AI video tools.GOOGLE\"), Document(metadata={'source': 'https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/'}, page_content='The departure of these researchers also shone a light on OpenAI’s strict and binding nondisclosure agreements and off-boarding documents. Employees who refused to sign them when they left the company risked losing their vested equity in the company, according to Vox. OpenAI CEO Sam Altman responded on X saying “there was a provision about potential equity cancellation in our previous exit docs; although we never clawed anything back, it should never have been something we had in any documents or communication.”\\nAI DEALS OF THE WEEKAlexandr Wang was just 19 when he started Scale. His cofounder, Lucy Guo, was 21.Scale AI'), Document(metadata={'source': 'https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/'}, page_content='TALENT RESHUFFLE\\nKey safety researchers at OpenAI, including cofounder and Chief Scientist Ilya Sutskever and machine learning researcher Jan Leike, have resigned. The two led the company’s efforts to develop ways to control AI systems that might become smarter than humans and prevent them from going rogue at the company’s superalignment team, which now no longer exists, according to Wired. In a thread on X, Leike wrote: “Over the past few months my team has been sailing against the wind. Sometimes we were struggling for compute and it was getting harder and harder to get this crucial research done. Over the past years, safety culture and processes have taken a backseat to shiny products.”')]\n"
     ]
    }
   ],
   "source": [
    "question = \"Why did OpenAI and Scarlett Johansson have a conflict?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "search_result = retriever.invoke(question)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e107dea5",
   "metadata": {
    "id": "e107dea5"
   },
   "source": [
    "The ```similarity_score_threshold``` returns only the results with a ```score_threshold``` or higher in similarity-based retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "067f05aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "067f05aa",
    "outputId": "ce4c0a2b-84da-416c-88fe-dd82ba5e7b1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_core.vectorstores.base:No relevant docs were retrieved using the relevance score threshold 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "question = \"Why did OpenAI and Scarlett Johansson have a conflict?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
    ")\n",
    "search_result = retriever.invoke(question)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a72fee8",
   "metadata": {
    "id": "6a72fee8"
   },
   "source": [
    "Search using the ```maximum marginal search result(mmr)``` .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "405337a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "405337a9",
    "outputId": "83bce79c-4f59-427a-d725-9ae4927f98cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 20 is greater than number of elements in index 12, updating n_results = 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/'}, page_content=\"ForbesInnovationEditors' PickThe Prompt: Scarlett Johansson Vs OpenAIPlus AI-generated kids draw predators on TikTok and Instagram. \\nShare to FacebookShare to TwitterShare to Linkedin“I was shocked, angered and in disbelief,” Scarlett Johansson said about OpenAI's Sky voice for ChatGPT that sounds similar to her own.FilmMagic\\nThe Prompt is a weekly rundown of AI’s buzziest startups, biggest breakthroughs, and business deals. To get it in your inbox, subscribe here.\\n\\n\\nWelcome back to The Prompt.\\n\\nScarlett Johansson’s lawyers have demanded that OpenAI take down a voice for ChatGPT that sounds much like her own after she’d declined to work with the company to create it. The actress said in a statement provided to Forbes that her lawyers have asked the AI company to detail the “exact processes” it used to create the voice, which sounds eerily similar to Johansson’s voiceover work in the sci-fi movie Her. “I was shocked, angered and in disbelief,” she said.\"), Document(metadata={'source': 'https://www.forbes.com/sites/rashishrivastava/2024/05/21/the-prompt-scarlett-johansson-vs-openai/'}, page_content='TALENT RESHUFFLE\\nKey safety researchers at OpenAI, including cofounder and Chief Scientist Ilya Sutskever and machine learning researcher Jan Leike, have resigned. The two led the company’s efforts to develop ways to control AI systems that might become smarter than humans and prevent them from going rogue at the company’s superalignment team, which now no longer exists, according to Wired. In a thread on X, Leike wrote: “Over the past few months my team has been sailing against the wind. Sometimes we were struggling for compute and it was getting harder and harder to get this crucial research done. Over the past years, safety culture and processes have taken a backseat to shiny products.”')]\n"
     ]
    }
   ],
   "source": [
    "question = \"Why did OpenAI and Scarlett Johansson have a conflict?\"\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 2})\n",
    "search_result = retriever.invoke(question)\n",
    "print(search_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bca75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9a96b86",
   "metadata": {
    "id": "e9a96b86"
   },
   "source": [
    "### Create a variety of queries\n",
    "With ```MultiQueryRetriever```, you can generate similar questions with equivalent meanings based on the original query. This helps diversify question expressions, which can enhance search performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3473f1af",
   "metadata": {
    "id": "3473f1af"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "question = \"Why did OpenAI and Scarlett Johansson have a conflict?\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")\n",
    "\n",
    "retriever_from_llm = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(), llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e743451f",
   "metadata": {
    "id": "e743451f"
   },
   "outputs": [],
   "source": [
    "# Set logging for the queries\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd0aed2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd0aed2a",
    "outputId": "503d99ee-fa99-43a4-8bb7-14eb826bac94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-43-1b4fb66403e0>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
      "INFO:langchain.retrievers.multi_query:Generated queries: ['What was the nature of the disagreement between OpenAI and Scarlett Johansson?  ', 'Can you explain the reasons behind the conflict involving OpenAI and Scarlett Johansson?  ', 'What led to the tensions between OpenAI and Scarlett Johansson?']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_docs = retriever_from_llm.get_relevant_documents(query=question)\n",
    "len(unique_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8185cf7",
   "metadata": {
    "id": "c8185cf7"
   },
   "source": [
    "### 集成檢索器\n",
    "**BM25 檢索器 + 基於嵌入的檢索器**\n",
    "\n",
    "- ```BM25 檢索器```（關鍵字搜索，稀疏檢索器）：基於 TF-IDF，考慮詞頻和文檔長度正規化。\n",
    "- ```基於嵌入的檢索器```（上下文搜索，密集檢索器）：將文本轉換為嵌入向量，並基於向量相似性檢索文檔（例如餘弦相似度、點積）。這反映了單詞的語義相似性。\n",
    "- ```集成檢索器```：結合 BM25 和基於嵌入的檢索器，將關鍵字搜索的詞頻與上下文搜索的語義相似性相結合。\n",
    "\n",
    "**注意**\n",
    "\n",
    "TF-IDF（詞頻-逆文檔頻率）：TF-IDF 將在特定文檔中頻繁出現的單詞評估為高度重要，而在所有文檔中頻繁出現的單詞則被認為不太重要。\n",
    "\n",
    "**重點解釋：**\n",
    "\n",
    "### 集成檢索的核心優勢\n",
    "\n",
    "**1. 互補性檢索策略**\n",
    "- **BM25**：擅長精確關鍵字匹配，處理專有名詞和術語\n",
    "- **嵌入檢索**：理解語義關係，處理同義詞和概念相關性\n",
    "- **集成效果**：結合兩者優勢，提高檢索準確性和召回率\n",
    "\n",
    "**2. TF-IDF 的重要性評估**\n",
    "- **高頻詞在特定文檔**：表示該詞對此文檔很重要\n",
    "- **高頻詞在所有文檔**：被視為常見詞，重要性降低\n",
    "- **實際應用**：「人工智能」在 AI 論文中重要，但「的」、「是」等虛詞重要性低\n",
    "\n",
    "**3. 實際應用場景**\n",
    "- **專業術語檢索**：BM25 精確匹配技術名詞\n",
    "- **概念理解檢索**：嵌入模型理解相關概念\n",
    "- **混合查詢**：同時滿足精確匹配和語義理解需求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd02b2b6",
   "metadata": {
    "id": "cd02b2b6"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52988fd9",
   "metadata": {
    "id": "52988fd9"
   },
   "outputs": [],
   "source": [
    "doc_list = [\n",
    "    \"We saw a seal swimming in the ocean.\",\n",
    "    \"The seal is clapping its flippers.\",\n",
    "    \"Make sure the envelope has a proper seal before sending it.\",\n",
    "    \"Every official document requires a seal to authenticate it.\",\n",
    "]\n",
    "\n",
    "# initialize the bm25 retriever and faiss retriever\n",
    "bm25_retriever = BM25Retriever.from_texts(doc_list)\n",
    "bm25_retriever.k = 4\n",
    "\n",
    "faiss_vectorstore = FAISS.from_texts(doc_list, OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6658f807",
   "metadata": {
    "id": "6658f807"
   },
   "outputs": [],
   "source": [
    "def pretty_print(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"[{i+1}] {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f046a5bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f046a5bf",
    "outputId": "90dae17d-6882-45be-f90d-ac11ae7cd5f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query]\n",
      "The seal rested on a rock.\n",
      "\n",
      "[BM25 Retriever]\n",
      "[1] The seal is clapping its flippers.\n",
      "[2] We saw a seal swimming in the ocean.\n",
      "[3] Every official document requires a seal to authenticate it.\n",
      "[4] Make sure the envelope has a proper seal before sending it.\n",
      "============================================================\n",
      "[FAISS Retriever]\n",
      "[1] The seal is clapping its flippers.\n",
      "[2] We saw a seal swimming in the ocean.\n",
      "[3] Every official document requires a seal to authenticate it.\n",
      "[4] Make sure the envelope has a proper seal before sending it.\n",
      "============================================================\n",
      "[Ensemble Retriever]\n",
      "[1] The seal is clapping its flippers.\n",
      "[2] We saw a seal swimming in the ocean.\n",
      "[3] Every official document requires a seal to authenticate it.\n",
      "[4] Make sure the envelope has a proper seal before sending it.\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"The seal rested on a rock.\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.invoke(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.invoke(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.invoke(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99d87210",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99d87210",
    "outputId": "b684a457-30d8-44d3-dfb4-b5da06a01622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query]\n",
      "Ensure the package is securely sealed before handing it to the courier.\n",
      "\n",
      "[BM25 Retriever]\n",
      "[1] The seal is clapping its flippers.\n",
      "[2] Every official document requires a seal to authenticate it.\n",
      "[3] Make sure the envelope has a proper seal before sending it.\n",
      "[4] We saw a seal swimming in the ocean.\n",
      "============================================================\n",
      "[FAISS Retriever]\n",
      "[1] Make sure the envelope has a proper seal before sending it.\n",
      "[2] Every official document requires a seal to authenticate it.\n",
      "[3] The seal is clapping its flippers.\n",
      "[4] We saw a seal swimming in the ocean.\n",
      "============================================================\n",
      "[Ensemble Retriever]\n",
      "[1] The seal is clapping its flippers.\n",
      "[2] Make sure the envelope has a proper seal before sending it.\n",
      "[3] Every official document requires a seal to authenticate it.\n",
      "[4] We saw a seal swimming in the ocean.\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"Ensure the package is securely sealed before handing it to the courier.\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.invoke(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.invoke(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.invoke(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "60a3345b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60a3345b",
    "outputId": "2044b74d-9d2b-43c7-c288-94e06b40cf11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query]\n",
      "The certificate must bear an official seal to be considered valid.\n",
      "\n",
      "[BM25 Retriever]\n",
      "[1] Every official document requires a seal to authenticate it.\n",
      "[2] The seal is clapping its flippers.\n",
      "[3] We saw a seal swimming in the ocean.\n",
      "[4] Make sure the envelope has a proper seal before sending it.\n",
      "============================================================\n",
      "[FAISS Retriever]\n",
      "[1] Every official document requires a seal to authenticate it.\n",
      "[2] Make sure the envelope has a proper seal before sending it.\n",
      "[3] The seal is clapping its flippers.\n",
      "[4] We saw a seal swimming in the ocean.\n",
      "============================================================\n",
      "[Ensemble Retriever]\n",
      "[1] Every official document requires a seal to authenticate it.\n",
      "[2] The seal is clapping its flippers.\n",
      "[3] Make sure the envelope has a proper seal before sending it.\n",
      "[4] We saw a seal swimming in the ocean.\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"The certificate must bear an official seal to be considered valid.\"\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.invoke(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.invoke(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.invoke(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2210c1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2210c1a",
    "outputId": "956bba62-58fc-4e24-c10c-93720eff71c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Query]\n",
      "animal\n",
      "\n",
      "[BM25 Retriever]\n",
      "[1] Every official document requires a seal to authenticate it.\n",
      "[2] Make sure the envelope has a proper seal before sending it.\n",
      "[3] The seal is clapping its flippers.\n",
      "[4] We saw a seal swimming in the ocean.\n",
      "============================================================\n",
      "[FAISS Retriever]\n",
      "[1] We saw a seal swimming in the ocean.\n",
      "[2] The seal is clapping its flippers.\n",
      "[3] Every official document requires a seal to authenticate it.\n",
      "[4] Make sure the envelope has a proper seal before sending it.\n",
      "============================================================\n",
      "[Ensemble Retriever]\n",
      "[1] Every official document requires a seal to authenticate it.\n",
      "[2] We saw a seal swimming in the ocean.\n",
      "[3] The seal is clapping its flippers.\n",
      "[4] Make sure the envelope has a proper seal before sending it.\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"animal\"\n",
    "\n",
    "print(f\"[Query]\\n{sample_query}\\n\")\n",
    "relevant_docs = bm25_retriever.invoke(sample_query)\n",
    "print(\"[BM25 Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = faiss_retriever.invoke(sample_query)\n",
    "print(\"[FAISS Retriever]\")\n",
    "pretty_print(relevant_docs)\n",
    "print(\"===\" * 20)\n",
    "relevant_docs = ensemble_retriever.invoke(sample_query)\n",
    "print(\"[Ensemble Retriever]\")\n",
    "pretty_print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9d842",
   "metadata": {
    "id": "56e9d842"
   },
   "source": [
    "## Step 6: Create Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d94fcc",
   "metadata": {
    "id": "b5d94fcc"
   },
   "source": [
    "提示工程在基於給定數據（```上下文```）獲得期望輸出方面發揮著關鍵作用。\n",
    "\n",
    "[提示1]\n",
    "\n",
    "1. 如果 ```檢索器``` 提供的結果中缺少重要信息，您應該修改 ```檢索器``` 邏輯。\n",
    "2. 如果 ```檢索器``` 的結果包含充足信息，但 llm 無法提取關鍵信息或無法產生期望格式的輸出，您應該調整提示。\n",
    "\n",
    "[提示2]\n",
    "\n",
    "1. LangSmith 的 **hub** 包含許多經過驗證的提示。\n",
    "2. 利用或稍微修改這些經過驗證的提示可以節省成本和時間。\n",
    "\n",
    "- https://smith.langchain.com/hub/search?q=rag\n",
    "\n",
    "**重點解釋：**\n",
    "\n",
    "### 提示工程的診斷策略\n",
    "\n",
    "**1. 問題定位方法**\n",
    "- **檢索問題**：相關文檔未被找到 → 調整檢索策略\n",
    "- **提取問題**：文檔存在但答案不準確 → 優化提示設計\n",
    "\n",
    "**2. LangSmith Hub 的價值**\n",
    "- **經過驗證**：社群測試並優化的提示模板\n",
    "- **快速起步**：避免從零開始設計提示\n",
    "- **成本效益**：減少試錯時間和 API 調用成本\n",
    "\n",
    "**3. 提示優化重點**\n",
    "- 明確指定輸出格式\n",
    "- 提供具體的角色設定\n",
    "- 包含處理不確定情況的指導"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "20486a6f",
   "metadata": {
    "id": "20486a6f"
   },
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61e05003",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61e05003",
    "outputId": "564bf650-e319-49cf-a495-fd4bca230d67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: \u001b[33;1m\u001b[1;3m{question}\u001b[0m \n",
      "Context: \u001b[33;1m\u001b[1;3m{context}\u001b[0m \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "prompt.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d8714",
   "metadata": {
    "id": "bc0d8714"
   },
   "source": [
    "## Step 7: Create LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f99381",
   "metadata": {
    "id": "37f99381"
   },
   "source": [
    "Select one of the OpenAI models:\n",
    "\n",
    "- ```gpt-4o``` : OpenAI GPT-4o model\n",
    "- ```gpt-4o-mini``` : OpenAI GPT-4o-mini model\n",
    "\n",
    "For detailed pricing information, please refer to the [OpenAI API Model List / Pricing](https://openai.com/api/pricing/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85dcaa69",
   "metadata": {
    "id": "85dcaa69"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e64e9a5",
   "metadata": {
    "id": "6e64e9a5"
   },
   "source": [
    "You can check token usage in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f087fd3f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f087fd3f",
    "outputId": "df782774-6dee-46ef-b5e1-7df697c82334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 24\n",
      "\tPrompt Tokens: 15\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 9\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $7.65e-06\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = model.invoke(\"Where is the capital of South Korea?\")\n",
    "print(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f6cd40",
   "metadata": {
    "id": "00f6cd40"
   },
   "source": [
    "### 使用 Huggingface\n",
    "\n",
    "您需要 Hugging Face 令牌來訪問 HuggingFace 上的 LLMs。\n",
    "\n",
    "您可以輕鬆下載並使用 HuggingFace 上提供的開源模型。\n",
    "\n",
    "您也可以在下面的連結查看每日性能改善的開源排行榜：\n",
    "\n",
    "- [HuggingFace LLM 排行榜](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
    "\n",
    "**注意**\n",
    "\n",
    "Hugging Face 的免費 API 有 10GB 大小限制。\n",
    "例如，microsoft/Phi-3-mini-4k-instruct 模型為 11GB，無法透過免費 API 訪問。\n",
    "\n",
    "選擇以下其中一個選項：\n",
    "\n",
    "1. 選項：使用 Hugging Face 推理端點\n",
    "\n",
    "透過付費計劃啟用推理端點來執行大規模模型推理。\n",
    "\n",
    "2. 選項：在本地運行模型\n",
    "\n",
    "使用 transformers 函式庫在本地環境中運行 microsoft/Phi-3-mini-4k-instruct 模型（建議使用 GPU）。\n",
    "\n",
    "3. 選項：使用較小的模型。\n",
    "\n",
    "將模型大小減少到免費 API 支援的大小並執行。\n",
    "\n",
    "**重點說明：**\n",
    "\n",
    "### HuggingFace 使用策略\n",
    "\n",
    "**1. 免費 API 限制**\n",
    "- **10GB 限制**：許多高性能模型超過此限制\n",
    "- **推理速度**：免費服務可能較慢\n",
    "- **使用配額**：每月有一定的調用限制\n",
    "\n",
    "**2. 模型選擇建議**\n",
    "- **小型高效模型**：如 microsoft/DialoGPT-medium（1.4GB）\n",
    "- **多語言模型**：考慮語言支援需求\n",
    "- **任務特化模型**：選擇針對特定任務優化的模型\n",
    "\n",
    "**3. 本地部署考量**\n",
    "- **硬體需求**：GPU 記憶體和計算能力\n",
    "- **環境配置**：CUDA、PyTorch 等依賴\n",
    "- **成本效益**：長期使用可能比付費 API 更經濟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba46d84d",
   "metadata": {
    "id": "ba46d84d"
   },
   "outputs": [],
   "source": [
    "# Creating a HuggingFaceEndpoint object\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "hugging_face_llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "628f91f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "628f91f5",
    "outputId": "93eaf7d6-e9c9-4808-a46d-c02314264e3e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\n# Answer\\nThe capital of South Korea is Seoul.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hugging_face_llm.invoke(\"Where is the capital of South Korea?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d74046f",
   "metadata": {
    "id": "0d74046f"
   },
   "source": [
    "## RAG Template Experiment\n",
    "This template is a structure for implementing a Retrieval-Augmented Generation (RAG) workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88c64211",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88c64211",
    "outputId": "7ebcf467-97b7-4959-dfa0-f402acc40a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF Path: data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf\n",
      "Number of documents: 86\n",
      "============================================================\n",
      "[HUMAN]\n",
      "Which region's approach to artificial intelligence is the focus of this document?\n",
      "\n",
      "[AI]\n",
      "The focus of this document is on the European approach to artificial intelligence. It discusses the strategies and policies implemented by the European Commission and EU Member States to enhance AI development and governance in Europe. The document emphasizes the importance of trust, data governance, and collaboration in fostering AI innovation within the region.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load Documents\n",
    "# Load the documents, split them into chunks, and index them.\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Load the PDF file. Enter the file path.\n",
    "file_path = \"data/A European Approach to Artificial Intelligence - A Policy Perspective.pdf\"\n",
    "loader = PyPDFLoader(file_path=file_path)\n",
    "\n",
    "# Step 2: Split Documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "split_docs = loader.load_and_split(text_splitter=text_splitter)\n",
    "\n",
    "# Step 3, 4: Embeding & Create Vectorstore\n",
    "embedding = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = FAISS.from_documents(documents=split_docs, embedding=embedding)\n",
    "\n",
    "# Step 5: Create Retriever\n",
    "# Search for documents that match the user's query.\n",
    "\n",
    "# Retrieve the top K documents with the highest similarity.\n",
    "k = 3\n",
    "\n",
    "# Initialize the (Sparse) BM25 retriever and (Dense) FAISS retriever.\n",
    "bm25_retriever = BM25Retriever.from_documents(split_docs)\n",
    "bm25_retriever.k = k\n",
    "\n",
    "faiss_vectorstore = FAISS.from_documents(split_docs, embedding)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Step 6: Create Prompt\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# Step 7: Create LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # Combine the retrieved document results into a single paragraph.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Step 8: Create Chain\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run Chain: Input a query about the document and output the answer.\n",
    "\n",
    "question = \"Which region's approach to artificial intelligence is the focus of this document?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# Get Output\n",
    "print(f\"PDF Path: {file_path}\")\n",
    "print(f\"Number of documents: {len(split_docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349c363",
   "metadata": {
    "id": "e349c363"
   },
   "source": [
    "Document: A European Approach to Artificial Intelligence - A Policy Perspective.pdf\n",
    "\n",
    "- LangSmith: https://smith.langchain.com/public/0951c102-de61-482b-b42a-6e7d78f02107/r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1bc2c56e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1bc2c56e",
    "outputId": "4eae6351-9e21-47cb-a3ac-6f2778cf6b66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The focus of this document is on the European approach to artificial intelligence. It discusses the strategies and policies implemented by the European Commission and EU Member States to enhance AI development and governance in Europe. The document emphasizes the importance of trust, data governance, and collaboration in fostering AI innovation within the region.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which region's approach to artificial intelligence is the focus of this document?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc31d23",
   "metadata": {
    "id": "9fc31d23"
   },
   "source": [
    "Document: A European Approach to Artificial Intelligence - A Policy Perspective.pdf\n",
    "\n",
    "- LangSmith: https://smith.langchain.com/public/c968bf7e-e22e-4eb1-a76a-b226eedc6c51/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "218d2974",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "218d2974",
    "outputId": "b0e3bba5-8d5d-41cd-c050-f218bf2e9a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary principle of the European AI approach is to place people at the center of AI development, often referred to as \"human-centric AI.\" This approach aims to support technological and industrial capacity, prepare for socio-economic changes, and ensure an appropriate ethical and legal framework. It emphasizes the need for AI to comply with the law, fulfill ethical principles, and be robust to achieve \"trustworthy AI.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the primary principle of the European AI approach?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b833cf",
   "metadata": {
    "id": "30b833cf"
   },
   "source": [
    "Ask a question unrelated to the document.\n",
    "\n",
    "- LangSmith: https://smith.langchain.com/public/d8a49d52-3a63-4206-9166-58605bd990a6/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "265b7d95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "265b7d95",
    "outputId": "af599e78-5e6d-469d-de6a-be483765c2d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The obligation of the United States in AI primarily involves ensuring ethical standards, transparency, and accountability in AI development and deployment. This includes addressing concerns related to privacy, data governance, and the societal impacts of AI technologies. Additionally, the U.S. may need to engage in international cooperation to establish norms and regulations that promote responsible AI use.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the obligation of the United States in AI?\"\n",
    "response = rag_chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1e153841",
   "metadata": {
    "id": "1e153841"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ec2358d",
   "metadata": {
    "id": "3ec2358d"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
